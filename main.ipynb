{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question answering on the SQuAD dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-12T15:55:40.359425Z",
     "iopub.status.busy": "2021-01-12T15:55:40.358980Z",
     "iopub.status.idle": "2021-01-12T15:55:40.453641Z",
     "shell.execute_reply": "2021-01-12T15:55:40.452491Z",
     "shell.execute_reply.started": "2021-01-12T15:55:40.359380Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import datetime\n",
    "import random\n",
    "from functools import partial\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import gensim\n",
    "import gensim.downloader as gloader\n",
    "import wandb\n",
    "import transformers\n",
    "import tokenizers\n",
    "from transformers.trainer_pt_utils import nested_detach\n",
    "from transformers.trainer_utils import EvalPrediction\n",
    "from tokenizers import Tokenizer\n",
    "from tokenizers.models import WordLevel\n",
    "from tokenizers.normalizers import Sequence, StripAccents, Lowercase, Strip\n",
    "from tokenizers.pre_tokenizers import Sequence as PreSequence\n",
    "from tokenizers.pre_tokenizers import Whitespace, Punctuation\n",
    "from IPython.display import display, HTML\n",
    "\n",
    "import dataset\n",
    "import model\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-12T15:55:43.359120Z",
     "iopub.status.busy": "2021-01-12T15:55:43.358699Z",
     "iopub.status.idle": "2021-01-12T15:55:43.439436Z",
     "shell.execute_reply": "2021-01-12T15:55:43.438201Z",
     "shell.execute_reply.started": "2021-01-12T15:55:43.359075Z"
    }
   },
   "outputs": [],
   "source": [
    "plt.rcParams['figure.figsize'] = [8, 6]\n",
    "plt.rcParams['figure.dpi'] = 100\n",
    "plt.rcParams['axes.xmargin'] = .05\n",
    "plt.rcParams['axes.ymargin'] = .05\n",
    "plt.style.use('ggplot')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-12T16:03:07.513839Z",
     "iopub.status.busy": "2021-01-12T16:03:07.513413Z",
     "iopub.status.idle": "2021-01-12T16:03:07.584951Z",
     "shell.execute_reply": "2021-01-12T16:03:07.583752Z",
     "shell.execute_reply.started": "2021-01-12T16:03:07.513794Z"
    }
   },
   "outputs": [],
   "source": [
    "WANDB_PROJECT = \"squad-qa\"\n",
    "WANDB_ENTITY = \"wadaboa\"\n",
    "WANDB_MODE = \"online\"\n",
    "WANDB_RESUME = \"never\"\n",
    "\n",
    "init_wandb = partial(\n",
    "    wandb.init,\n",
    "    project=WANDB_PROJECT,\n",
    "    entity=WANDB_ENTITY,\n",
    "    mode=WANDB_MODE,\n",
    "    resume=WANDB_RESUME,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preliminaries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data loading/preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-13T11:34:47.348691Z",
     "iopub.status.busy": "2021-01-13T11:34:47.348366Z",
     "iopub.status.idle": "2021-01-13T11:35:27.135301Z",
     "shell.execute_reply": "2021-01-13T11:35:27.133514Z",
     "shell.execute_reply.started": "2021-01-13T11:34:47.348649Z"
    }
   },
   "outputs": [],
   "source": [
    "squad_dataset = dataset.SquadDataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-13T11:35:38.861458Z",
     "iopub.status.busy": "2021-01-13T11:35:38.861028Z",
     "iopub.status.idle": "2021-01-13T11:35:38.958059Z",
     "shell.execute_reply": "2021-01-13T11:35:38.956941Z",
     "shell.execute_reply.started": "2021-01-13T11:35:38.861413Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question_id</th>\n",
       "      <th>question</th>\n",
       "      <th>title</th>\n",
       "      <th>context_id</th>\n",
       "      <th>context</th>\n",
       "      <th>answer</th>\n",
       "      <th>answer_start</th>\n",
       "      <th>answer_end</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5733be284776f41900661182</td>\n",
       "      <td>To whom did the Virgin Mary allegedly appear i...</td>\n",
       "      <td>University_of_Notre_Dame</td>\n",
       "      <td>0</td>\n",
       "      <td>Architecturally, the school has a Catholic cha...</td>\n",
       "      <td>Saint Bernadette Soubirous</td>\n",
       "      <td>515</td>\n",
       "      <td>541</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5733be284776f4190066117f</td>\n",
       "      <td>What is in front of the Notre Dame Main Building?</td>\n",
       "      <td>University_of_Notre_Dame</td>\n",
       "      <td>0</td>\n",
       "      <td>Architecturally, the school has a Catholic cha...</td>\n",
       "      <td>a copper statue of Christ</td>\n",
       "      <td>188</td>\n",
       "      <td>213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5733be284776f41900661180</td>\n",
       "      <td>The Basilica of the Sacred heart at Notre Dame...</td>\n",
       "      <td>University_of_Notre_Dame</td>\n",
       "      <td>0</td>\n",
       "      <td>Architecturally, the school has a Catholic cha...</td>\n",
       "      <td>the Main Building</td>\n",
       "      <td>279</td>\n",
       "      <td>296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5733be284776f41900661181</td>\n",
       "      <td>What is the Grotto at Notre Dame?</td>\n",
       "      <td>University_of_Notre_Dame</td>\n",
       "      <td>0</td>\n",
       "      <td>Architecturally, the school has a Catholic cha...</td>\n",
       "      <td>a Marian place of prayer and reflection</td>\n",
       "      <td>381</td>\n",
       "      <td>420</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5733be284776f4190066117e</td>\n",
       "      <td>What sits on top of the Main Building at Notre...</td>\n",
       "      <td>University_of_Notre_Dame</td>\n",
       "      <td>0</td>\n",
       "      <td>Architecturally, the school has a Catholic cha...</td>\n",
       "      <td>a golden statue of the Virgin Mary</td>\n",
       "      <td>92</td>\n",
       "      <td>126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87594</th>\n",
       "      <td>5735d259012e2f140011a09d</td>\n",
       "      <td>In what US state did Kathmandu first establish...</td>\n",
       "      <td>Kathmandu</td>\n",
       "      <td>18890</td>\n",
       "      <td>Kathmandu Metropolitan City (KMC), in order to...</td>\n",
       "      <td>Oregon</td>\n",
       "      <td>229</td>\n",
       "      <td>235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87595</th>\n",
       "      <td>5735d259012e2f140011a09e</td>\n",
       "      <td>What was Yangon previously known as?</td>\n",
       "      <td>Kathmandu</td>\n",
       "      <td>18890</td>\n",
       "      <td>Kathmandu Metropolitan City (KMC), in order to...</td>\n",
       "      <td>Rangoon</td>\n",
       "      <td>414</td>\n",
       "      <td>421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87596</th>\n",
       "      <td>5735d259012e2f140011a09f</td>\n",
       "      <td>With what Belorussian city does Kathmandu have...</td>\n",
       "      <td>Kathmandu</td>\n",
       "      <td>18890</td>\n",
       "      <td>Kathmandu Metropolitan City (KMC), in order to...</td>\n",
       "      <td>Minsk</td>\n",
       "      <td>476</td>\n",
       "      <td>481</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87597</th>\n",
       "      <td>5735d259012e2f140011a0a0</td>\n",
       "      <td>In what year did Kathmandu create its initial ...</td>\n",
       "      <td>Kathmandu</td>\n",
       "      <td>18890</td>\n",
       "      <td>Kathmandu Metropolitan City (KMC), in order to...</td>\n",
       "      <td>1975</td>\n",
       "      <td>199</td>\n",
       "      <td>203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87598</th>\n",
       "      <td>5735d259012e2f140011a0a1</td>\n",
       "      <td>What is KMC an initialism of?</td>\n",
       "      <td>Kathmandu</td>\n",
       "      <td>18890</td>\n",
       "      <td>Kathmandu Metropolitan City (KMC), in order to...</td>\n",
       "      <td>Kathmandu Metropolitan City</td>\n",
       "      <td>0</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>87599 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                    question_id  \\\n",
       "0      5733be284776f41900661182   \n",
       "1      5733be284776f4190066117f   \n",
       "2      5733be284776f41900661180   \n",
       "3      5733be284776f41900661181   \n",
       "4      5733be284776f4190066117e   \n",
       "...                         ...   \n",
       "87594  5735d259012e2f140011a09d   \n",
       "87595  5735d259012e2f140011a09e   \n",
       "87596  5735d259012e2f140011a09f   \n",
       "87597  5735d259012e2f140011a0a0   \n",
       "87598  5735d259012e2f140011a0a1   \n",
       "\n",
       "                                                question  \\\n",
       "0      To whom did the Virgin Mary allegedly appear i...   \n",
       "1      What is in front of the Notre Dame Main Building?   \n",
       "2      The Basilica of the Sacred heart at Notre Dame...   \n",
       "3                      What is the Grotto at Notre Dame?   \n",
       "4      What sits on top of the Main Building at Notre...   \n",
       "...                                                  ...   \n",
       "87594  In what US state did Kathmandu first establish...   \n",
       "87595               What was Yangon previously known as?   \n",
       "87596  With what Belorussian city does Kathmandu have...   \n",
       "87597  In what year did Kathmandu create its initial ...   \n",
       "87598                      What is KMC an initialism of?   \n",
       "\n",
       "                          title  context_id  \\\n",
       "0      University_of_Notre_Dame           0   \n",
       "1      University_of_Notre_Dame           0   \n",
       "2      University_of_Notre_Dame           0   \n",
       "3      University_of_Notre_Dame           0   \n",
       "4      University_of_Notre_Dame           0   \n",
       "...                         ...         ...   \n",
       "87594                 Kathmandu       18890   \n",
       "87595                 Kathmandu       18890   \n",
       "87596                 Kathmandu       18890   \n",
       "87597                 Kathmandu       18890   \n",
       "87598                 Kathmandu       18890   \n",
       "\n",
       "                                                 context  \\\n",
       "0      Architecturally, the school has a Catholic cha...   \n",
       "1      Architecturally, the school has a Catholic cha...   \n",
       "2      Architecturally, the school has a Catholic cha...   \n",
       "3      Architecturally, the school has a Catholic cha...   \n",
       "4      Architecturally, the school has a Catholic cha...   \n",
       "...                                                  ...   \n",
       "87594  Kathmandu Metropolitan City (KMC), in order to...   \n",
       "87595  Kathmandu Metropolitan City (KMC), in order to...   \n",
       "87596  Kathmandu Metropolitan City (KMC), in order to...   \n",
       "87597  Kathmandu Metropolitan City (KMC), in order to...   \n",
       "87598  Kathmandu Metropolitan City (KMC), in order to...   \n",
       "\n",
       "                                        answer  answer_start  answer_end  \n",
       "0                   Saint Bernadette Soubirous           515         541  \n",
       "1                    a copper statue of Christ           188         213  \n",
       "2                            the Main Building           279         296  \n",
       "3      a Marian place of prayer and reflection           381         420  \n",
       "4           a golden statue of the Virgin Mary            92         126  \n",
       "...                                        ...           ...         ...  \n",
       "87594                                   Oregon           229         235  \n",
       "87595                                  Rangoon           414         421  \n",
       "87596                                    Minsk           476         481  \n",
       "87597                                     1975           199         203  \n",
       "87598              Kathmandu Metropolitan City             0          27  \n",
       "\n",
       "[87599 rows x 8 columns]"
      ]
     },
     "execution_count": 195,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "squad_dataset.dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-13T11:35:41.874727Z",
     "iopub.status.busy": "2021-01-13T11:35:41.874372Z",
     "iopub.status.idle": "2021-01-13T11:35:41.969651Z",
     "shell.execute_reply": "2021-01-13T11:35:41.968545Z",
     "shell.execute_reply.started": "2021-01-13T11:35:41.874685Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question_id</th>\n",
       "      <th>question</th>\n",
       "      <th>title</th>\n",
       "      <th>context_id</th>\n",
       "      <th>context</th>\n",
       "      <th>answer</th>\n",
       "      <th>answer_start</th>\n",
       "      <th>answer_end</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5733be284776f41900661182</td>\n",
       "      <td>To whom did the Virgin Mary allegedly appear i...</td>\n",
       "      <td>University_of_Notre_Dame</td>\n",
       "      <td>0</td>\n",
       "      <td>Architecturally, the school has a Catholic cha...</td>\n",
       "      <td>Saint Bernadette Soubirous</td>\n",
       "      <td>515</td>\n",
       "      <td>541</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5733be284776f4190066117f</td>\n",
       "      <td>What is in front of the Notre Dame Main Building?</td>\n",
       "      <td>University_of_Notre_Dame</td>\n",
       "      <td>0</td>\n",
       "      <td>Architecturally, the school has a Catholic cha...</td>\n",
       "      <td>a copper statue of Christ</td>\n",
       "      <td>188</td>\n",
       "      <td>213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5733be284776f41900661180</td>\n",
       "      <td>The Basilica of the Sacred heart at Notre Dame...</td>\n",
       "      <td>University_of_Notre_Dame</td>\n",
       "      <td>0</td>\n",
       "      <td>Architecturally, the school has a Catholic cha...</td>\n",
       "      <td>the Main Building</td>\n",
       "      <td>279</td>\n",
       "      <td>296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5733be284776f41900661181</td>\n",
       "      <td>What is the Grotto at Notre Dame?</td>\n",
       "      <td>University_of_Notre_Dame</td>\n",
       "      <td>0</td>\n",
       "      <td>Architecturally, the school has a Catholic cha...</td>\n",
       "      <td>a Marian place of prayer and reflection</td>\n",
       "      <td>381</td>\n",
       "      <td>420</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5733be284776f4190066117e</td>\n",
       "      <td>What sits on top of the Main Building at Notre...</td>\n",
       "      <td>University_of_Notre_Dame</td>\n",
       "      <td>0</td>\n",
       "      <td>Architecturally, the school has a Catholic cha...</td>\n",
       "      <td>a golden statue of the Virgin Mary</td>\n",
       "      <td>92</td>\n",
       "      <td>126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70185</th>\n",
       "      <td>5735d259012e2f140011a09d</td>\n",
       "      <td>In what US state did Kathmandu first establish...</td>\n",
       "      <td>Kathmandu</td>\n",
       "      <td>18890</td>\n",
       "      <td>Kathmandu Metropolitan City (KMC), in order to...</td>\n",
       "      <td>Oregon</td>\n",
       "      <td>229</td>\n",
       "      <td>235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70186</th>\n",
       "      <td>5735d259012e2f140011a09e</td>\n",
       "      <td>What was Yangon previously known as?</td>\n",
       "      <td>Kathmandu</td>\n",
       "      <td>18890</td>\n",
       "      <td>Kathmandu Metropolitan City (KMC), in order to...</td>\n",
       "      <td>Rangoon</td>\n",
       "      <td>414</td>\n",
       "      <td>421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70187</th>\n",
       "      <td>5735d259012e2f140011a09f</td>\n",
       "      <td>With what Belorussian city does Kathmandu have...</td>\n",
       "      <td>Kathmandu</td>\n",
       "      <td>18890</td>\n",
       "      <td>Kathmandu Metropolitan City (KMC), in order to...</td>\n",
       "      <td>Minsk</td>\n",
       "      <td>476</td>\n",
       "      <td>481</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70188</th>\n",
       "      <td>5735d259012e2f140011a0a0</td>\n",
       "      <td>In what year did Kathmandu create its initial ...</td>\n",
       "      <td>Kathmandu</td>\n",
       "      <td>18890</td>\n",
       "      <td>Kathmandu Metropolitan City (KMC), in order to...</td>\n",
       "      <td>1975</td>\n",
       "      <td>199</td>\n",
       "      <td>203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70189</th>\n",
       "      <td>5735d259012e2f140011a0a1</td>\n",
       "      <td>What is KMC an initialism of?</td>\n",
       "      <td>Kathmandu</td>\n",
       "      <td>18890</td>\n",
       "      <td>Kathmandu Metropolitan City (KMC), in order to...</td>\n",
       "      <td>Kathmandu Metropolitan City</td>\n",
       "      <td>0</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>70190 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                    question_id  \\\n",
       "0      5733be284776f41900661182   \n",
       "1      5733be284776f4190066117f   \n",
       "2      5733be284776f41900661180   \n",
       "3      5733be284776f41900661181   \n",
       "4      5733be284776f4190066117e   \n",
       "...                         ...   \n",
       "70185  5735d259012e2f140011a09d   \n",
       "70186  5735d259012e2f140011a09e   \n",
       "70187  5735d259012e2f140011a09f   \n",
       "70188  5735d259012e2f140011a0a0   \n",
       "70189  5735d259012e2f140011a0a1   \n",
       "\n",
       "                                                question  \\\n",
       "0      To whom did the Virgin Mary allegedly appear i...   \n",
       "1      What is in front of the Notre Dame Main Building?   \n",
       "2      The Basilica of the Sacred heart at Notre Dame...   \n",
       "3                      What is the Grotto at Notre Dame?   \n",
       "4      What sits on top of the Main Building at Notre...   \n",
       "...                                                  ...   \n",
       "70185  In what US state did Kathmandu first establish...   \n",
       "70186               What was Yangon previously known as?   \n",
       "70187  With what Belorussian city does Kathmandu have...   \n",
       "70188  In what year did Kathmandu create its initial ...   \n",
       "70189                      What is KMC an initialism of?   \n",
       "\n",
       "                          title  context_id  \\\n",
       "0      University_of_Notre_Dame           0   \n",
       "1      University_of_Notre_Dame           0   \n",
       "2      University_of_Notre_Dame           0   \n",
       "3      University_of_Notre_Dame           0   \n",
       "4      University_of_Notre_Dame           0   \n",
       "...                         ...         ...   \n",
       "70185                 Kathmandu       18890   \n",
       "70186                 Kathmandu       18890   \n",
       "70187                 Kathmandu       18890   \n",
       "70188                 Kathmandu       18890   \n",
       "70189                 Kathmandu       18890   \n",
       "\n",
       "                                                 context  \\\n",
       "0      Architecturally, the school has a Catholic cha...   \n",
       "1      Architecturally, the school has a Catholic cha...   \n",
       "2      Architecturally, the school has a Catholic cha...   \n",
       "3      Architecturally, the school has a Catholic cha...   \n",
       "4      Architecturally, the school has a Catholic cha...   \n",
       "...                                                  ...   \n",
       "70185  Kathmandu Metropolitan City (KMC), in order to...   \n",
       "70186  Kathmandu Metropolitan City (KMC), in order to...   \n",
       "70187  Kathmandu Metropolitan City (KMC), in order to...   \n",
       "70188  Kathmandu Metropolitan City (KMC), in order to...   \n",
       "70189  Kathmandu Metropolitan City (KMC), in order to...   \n",
       "\n",
       "                                        answer  answer_start  answer_end  \n",
       "0                   Saint Bernadette Soubirous           515         541  \n",
       "1                    a copper statue of Christ           188         213  \n",
       "2                            the Main Building           279         296  \n",
       "3      a Marian place of prayer and reflection           381         420  \n",
       "4           a golden statue of the Virgin Mary            92         126  \n",
       "...                                        ...           ...         ...  \n",
       "70185                                   Oregon           229         235  \n",
       "70186                                  Rangoon           414         421  \n",
       "70187                                    Minsk           476         481  \n",
       "70188                                     1975           199         203  \n",
       "70189              Kathmandu Metropolitan City             0          27  \n",
       "\n",
       "[70190 rows x 8 columns]"
      ]
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "squad_dataset.train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-13T11:35:44.059879Z",
     "iopub.status.busy": "2021-01-13T11:35:44.059538Z",
     "iopub.status.idle": "2021-01-13T11:35:44.155739Z",
     "shell.execute_reply": "2021-01-13T11:35:44.154706Z",
     "shell.execute_reply.started": "2021-01-13T11:35:44.059837Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question_id</th>\n",
       "      <th>question</th>\n",
       "      <th>title</th>\n",
       "      <th>context_id</th>\n",
       "      <th>context</th>\n",
       "      <th>answer</th>\n",
       "      <th>answer_start</th>\n",
       "      <th>answer_end</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>56be85543aeaaa14008c9063</td>\n",
       "      <td>When did Beyonce start becoming popular?</td>\n",
       "      <td>Beyoncé</td>\n",
       "      <td>55</td>\n",
       "      <td>Beyoncé Giselle Knowles-Carter (/biːˈjɒnseɪ/ b...</td>\n",
       "      <td>in the late 1990s</td>\n",
       "      <td>269</td>\n",
       "      <td>286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>56be85543aeaaa14008c9065</td>\n",
       "      <td>What areas did Beyonce compete in when she was...</td>\n",
       "      <td>Beyoncé</td>\n",
       "      <td>55</td>\n",
       "      <td>Beyoncé Giselle Knowles-Carter (/biːˈjɒnseɪ/ b...</td>\n",
       "      <td>singing and dancing</td>\n",
       "      <td>207</td>\n",
       "      <td>226</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>56be85543aeaaa14008c9066</td>\n",
       "      <td>When did Beyonce leave Destiny's Child and bec...</td>\n",
       "      <td>Beyoncé</td>\n",
       "      <td>55</td>\n",
       "      <td>Beyoncé Giselle Knowles-Carter (/biːˈjɒnseɪ/ b...</td>\n",
       "      <td>2003</td>\n",
       "      <td>526</td>\n",
       "      <td>530</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>56bf6b0f3aeaaa14008c9601</td>\n",
       "      <td>In what city and state did Beyonce  grow up?</td>\n",
       "      <td>Beyoncé</td>\n",
       "      <td>55</td>\n",
       "      <td>Beyoncé Giselle Knowles-Carter (/biːˈjɒnseɪ/ b...</td>\n",
       "      <td>Houston, Texas</td>\n",
       "      <td>166</td>\n",
       "      <td>180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>56bf6b0f3aeaaa14008c9602</td>\n",
       "      <td>In which decade did Beyonce become famous?</td>\n",
       "      <td>Beyoncé</td>\n",
       "      <td>55</td>\n",
       "      <td>Beyoncé Giselle Knowles-Carter (/biːˈjɒnseɪ/ b...</td>\n",
       "      <td>late 1990s</td>\n",
       "      <td>276</td>\n",
       "      <td>286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17404</th>\n",
       "      <td>5732868bb3a91d1900202e0f</td>\n",
       "      <td>At what Augusta hole was the Eisenhower Pine l...</td>\n",
       "      <td>Dwight_D._Eisenhower</td>\n",
       "      <td>18592</td>\n",
       "      <td>A loblolly pine, known as the \"Eisenhower Pine...</td>\n",
       "      <td>17th</td>\n",
       "      <td>74</td>\n",
       "      <td>78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17405</th>\n",
       "      <td>5732868bb3a91d1900202e10</td>\n",
       "      <td>How many meters away from the Masters tee on A...</td>\n",
       "      <td>Dwight_D._Eisenhower</td>\n",
       "      <td>18592</td>\n",
       "      <td>A loblolly pine, known as the \"Eisenhower Pine...</td>\n",
       "      <td>192</td>\n",
       "      <td>110</td>\n",
       "      <td>113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17406</th>\n",
       "      <td>5732868bb3a91d1900202e11</td>\n",
       "      <td>What did Eisenhower want to be done to the Eis...</td>\n",
       "      <td>Dwight_D._Eisenhower</td>\n",
       "      <td>18592</td>\n",
       "      <td>A loblolly pine, known as the \"Eisenhower Pine...</td>\n",
       "      <td>cut down</td>\n",
       "      <td>279</td>\n",
       "      <td>287</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17407</th>\n",
       "      <td>5732868bb3a91d1900202e12</td>\n",
       "      <td>What damaged the Eisenhower Pine in February 2...</td>\n",
       "      <td>Dwight_D._Eisenhower</td>\n",
       "      <td>18592</td>\n",
       "      <td>A loblolly pine, known as the \"Eisenhower Pine...</td>\n",
       "      <td>ice storm</td>\n",
       "      <td>478</td>\n",
       "      <td>487</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17408</th>\n",
       "      <td>5732868bb3a91d1900202e13</td>\n",
       "      <td>In what year did Eisenhower propose that the p...</td>\n",
       "      <td>Dwight_D._Eisenhower</td>\n",
       "      <td>18592</td>\n",
       "      <td>A loblolly pine, known as the \"Eisenhower Pine...</td>\n",
       "      <td>1956</td>\n",
       "      <td>237</td>\n",
       "      <td>241</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>17409 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                    question_id  \\\n",
       "0      56be85543aeaaa14008c9063   \n",
       "1      56be85543aeaaa14008c9065   \n",
       "2      56be85543aeaaa14008c9066   \n",
       "3      56bf6b0f3aeaaa14008c9601   \n",
       "4      56bf6b0f3aeaaa14008c9602   \n",
       "...                         ...   \n",
       "17404  5732868bb3a91d1900202e0f   \n",
       "17405  5732868bb3a91d1900202e10   \n",
       "17406  5732868bb3a91d1900202e11   \n",
       "17407  5732868bb3a91d1900202e12   \n",
       "17408  5732868bb3a91d1900202e13   \n",
       "\n",
       "                                                question  \\\n",
       "0               When did Beyonce start becoming popular?   \n",
       "1      What areas did Beyonce compete in when she was...   \n",
       "2      When did Beyonce leave Destiny's Child and bec...   \n",
       "3          In what city and state did Beyonce  grow up?    \n",
       "4             In which decade did Beyonce become famous?   \n",
       "...                                                  ...   \n",
       "17404  At what Augusta hole was the Eisenhower Pine l...   \n",
       "17405  How many meters away from the Masters tee on A...   \n",
       "17406  What did Eisenhower want to be done to the Eis...   \n",
       "17407  What damaged the Eisenhower Pine in February 2...   \n",
       "17408  In what year did Eisenhower propose that the p...   \n",
       "\n",
       "                      title  context_id  \\\n",
       "0                   Beyoncé          55   \n",
       "1                   Beyoncé          55   \n",
       "2                   Beyoncé          55   \n",
       "3                   Beyoncé          55   \n",
       "4                   Beyoncé          55   \n",
       "...                     ...         ...   \n",
       "17404  Dwight_D._Eisenhower       18592   \n",
       "17405  Dwight_D._Eisenhower       18592   \n",
       "17406  Dwight_D._Eisenhower       18592   \n",
       "17407  Dwight_D._Eisenhower       18592   \n",
       "17408  Dwight_D._Eisenhower       18592   \n",
       "\n",
       "                                                 context               answer  \\\n",
       "0      Beyoncé Giselle Knowles-Carter (/biːˈjɒnseɪ/ b...    in the late 1990s   \n",
       "1      Beyoncé Giselle Knowles-Carter (/biːˈjɒnseɪ/ b...  singing and dancing   \n",
       "2      Beyoncé Giselle Knowles-Carter (/biːˈjɒnseɪ/ b...                 2003   \n",
       "3      Beyoncé Giselle Knowles-Carter (/biːˈjɒnseɪ/ b...       Houston, Texas   \n",
       "4      Beyoncé Giselle Knowles-Carter (/biːˈjɒnseɪ/ b...           late 1990s   \n",
       "...                                                  ...                  ...   \n",
       "17404  A loblolly pine, known as the \"Eisenhower Pine...                 17th   \n",
       "17405  A loblolly pine, known as the \"Eisenhower Pine...                  192   \n",
       "17406  A loblolly pine, known as the \"Eisenhower Pine...             cut down   \n",
       "17407  A loblolly pine, known as the \"Eisenhower Pine...            ice storm   \n",
       "17408  A loblolly pine, known as the \"Eisenhower Pine...                 1956   \n",
       "\n",
       "       answer_start  answer_end  \n",
       "0               269         286  \n",
       "1               207         226  \n",
       "2               526         530  \n",
       "3               166         180  \n",
       "4               276         286  \n",
       "...             ...         ...  \n",
       "17404            74          78  \n",
       "17405           110         113  \n",
       "17406           279         287  \n",
       "17407           478         487  \n",
       "17408           237         241  \n",
       "\n",
       "[17409 rows x 8 columns]"
      ]
     },
     "execution_count": 197,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "squad_dataset.val_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-13T11:35:47.378588Z",
     "iopub.status.busy": "2021-01-13T11:35:47.378213Z",
     "iopub.status.idle": "2021-01-13T11:35:47.473134Z",
     "shell.execute_reply": "2021-01-13T11:35:47.471975Z",
     "shell.execute_reply.started": "2021-01-13T11:35:47.378546Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question_id</th>\n",
       "      <th>question</th>\n",
       "      <th>title</th>\n",
       "      <th>context_id</th>\n",
       "      <th>context</th>\n",
       "      <th>answer</th>\n",
       "      <th>answer_start</th>\n",
       "      <th>answer_end</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>56be4db0acb8001400a502ec</td>\n",
       "      <td>Which NFL team represented the AFC at Super Bo...</td>\n",
       "      <td>Super_Bowl_50</td>\n",
       "      <td>0</td>\n",
       "      <td>Super Bowl 50 was an American football game to...</td>\n",
       "      <td>Denver Broncos</td>\n",
       "      <td>177</td>\n",
       "      <td>191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>56be4db0acb8001400a502ed</td>\n",
       "      <td>Which NFL team represented the NFC at Super Bo...</td>\n",
       "      <td>Super_Bowl_50</td>\n",
       "      <td>0</td>\n",
       "      <td>Super Bowl 50 was an American football game to...</td>\n",
       "      <td>Carolina Panthers</td>\n",
       "      <td>249</td>\n",
       "      <td>266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>56be4db0acb8001400a502ee</td>\n",
       "      <td>Where did Super Bowl 50 take place?</td>\n",
       "      <td>Super_Bowl_50</td>\n",
       "      <td>0</td>\n",
       "      <td>Super Bowl 50 was an American football game to...</td>\n",
       "      <td>Santa Clara, California</td>\n",
       "      <td>403</td>\n",
       "      <td>426</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>56be4db0acb8001400a502ee</td>\n",
       "      <td>Where did Super Bowl 50 take place?</td>\n",
       "      <td>Super_Bowl_50</td>\n",
       "      <td>0</td>\n",
       "      <td>Super Bowl 50 was an American football game to...</td>\n",
       "      <td>Levi's Stadium</td>\n",
       "      <td>355</td>\n",
       "      <td>369</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>56be4db0acb8001400a502ee</td>\n",
       "      <td>Where did Super Bowl 50 take place?</td>\n",
       "      <td>Super_Bowl_50</td>\n",
       "      <td>0</td>\n",
       "      <td>Super Bowl 50 was an American football game to...</td>\n",
       "      <td>Levi's Stadium in the San Francisco Bay Area a...</td>\n",
       "      <td>355</td>\n",
       "      <td>427</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34711</th>\n",
       "      <td>5737aafd1c456719005744fd</td>\n",
       "      <td>What is a very seldom used unit of mass in the...</td>\n",
       "      <td>Force</td>\n",
       "      <td>2066</td>\n",
       "      <td>The pound-force has a metric counterpart, less...</td>\n",
       "      <td>slug</td>\n",
       "      <td>274</td>\n",
       "      <td>278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34712</th>\n",
       "      <td>5737aafd1c456719005744fd</td>\n",
       "      <td>What is a very seldom used unit of mass in the...</td>\n",
       "      <td>Force</td>\n",
       "      <td>2066</td>\n",
       "      <td>The pound-force has a metric counterpart, less...</td>\n",
       "      <td>metric slug</td>\n",
       "      <td>267</td>\n",
       "      <td>278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34715</th>\n",
       "      <td>5737aafd1c456719005744fd</td>\n",
       "      <td>What is a very seldom used unit of mass in the...</td>\n",
       "      <td>Force</td>\n",
       "      <td>2066</td>\n",
       "      <td>The pound-force has a metric counterpart, less...</td>\n",
       "      <td>the metric slug</td>\n",
       "      <td>263</td>\n",
       "      <td>278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34716</th>\n",
       "      <td>5737aafd1c456719005744fe</td>\n",
       "      <td>What seldom used term of a unit of force equal...</td>\n",
       "      <td>Force</td>\n",
       "      <td>2066</td>\n",
       "      <td>The pound-force has a metric counterpart, less...</td>\n",
       "      <td>kip</td>\n",
       "      <td>712</td>\n",
       "      <td>715</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34721</th>\n",
       "      <td>5737aafd1c456719005744ff</td>\n",
       "      <td>What is the seldom used force unit equal to on...</td>\n",
       "      <td>Force</td>\n",
       "      <td>2066</td>\n",
       "      <td>The pound-force has a metric counterpart, less...</td>\n",
       "      <td>sthène</td>\n",
       "      <td>665</td>\n",
       "      <td>671</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>18216 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                    question_id  \\\n",
       "0      56be4db0acb8001400a502ec   \n",
       "3      56be4db0acb8001400a502ed   \n",
       "6      56be4db0acb8001400a502ee   \n",
       "7      56be4db0acb8001400a502ee   \n",
       "8      56be4db0acb8001400a502ee   \n",
       "...                         ...   \n",
       "34711  5737aafd1c456719005744fd   \n",
       "34712  5737aafd1c456719005744fd   \n",
       "34715  5737aafd1c456719005744fd   \n",
       "34716  5737aafd1c456719005744fe   \n",
       "34721  5737aafd1c456719005744ff   \n",
       "\n",
       "                                                question          title  \\\n",
       "0      Which NFL team represented the AFC at Super Bo...  Super_Bowl_50   \n",
       "3      Which NFL team represented the NFC at Super Bo...  Super_Bowl_50   \n",
       "6                    Where did Super Bowl 50 take place?  Super_Bowl_50   \n",
       "7                    Where did Super Bowl 50 take place?  Super_Bowl_50   \n",
       "8                    Where did Super Bowl 50 take place?  Super_Bowl_50   \n",
       "...                                                  ...            ...   \n",
       "34711  What is a very seldom used unit of mass in the...          Force   \n",
       "34712  What is a very seldom used unit of mass in the...          Force   \n",
       "34715  What is a very seldom used unit of mass in the...          Force   \n",
       "34716  What seldom used term of a unit of force equal...          Force   \n",
       "34721  What is the seldom used force unit equal to on...          Force   \n",
       "\n",
       "       context_id                                            context  \\\n",
       "0               0  Super Bowl 50 was an American football game to...   \n",
       "3               0  Super Bowl 50 was an American football game to...   \n",
       "6               0  Super Bowl 50 was an American football game to...   \n",
       "7               0  Super Bowl 50 was an American football game to...   \n",
       "8               0  Super Bowl 50 was an American football game to...   \n",
       "...           ...                                                ...   \n",
       "34711        2066  The pound-force has a metric counterpart, less...   \n",
       "34712        2066  The pound-force has a metric counterpart, less...   \n",
       "34715        2066  The pound-force has a metric counterpart, less...   \n",
       "34716        2066  The pound-force has a metric counterpart, less...   \n",
       "34721        2066  The pound-force has a metric counterpart, less...   \n",
       "\n",
       "                                                  answer  answer_start  \\\n",
       "0                                         Denver Broncos           177   \n",
       "3                                      Carolina Panthers           249   \n",
       "6                                Santa Clara, California           403   \n",
       "7                                         Levi's Stadium           355   \n",
       "8      Levi's Stadium in the San Francisco Bay Area a...           355   \n",
       "...                                                  ...           ...   \n",
       "34711                                               slug           274   \n",
       "34712                                        metric slug           267   \n",
       "34715                                    the metric slug           263   \n",
       "34716                                                kip           712   \n",
       "34721                                             sthène           665   \n",
       "\n",
       "       answer_end  \n",
       "0             191  \n",
       "3             266  \n",
       "6             426  \n",
       "7             369  \n",
       "8             427  \n",
       "...           ...  \n",
       "34711         278  \n",
       "34712         278  \n",
       "34715         278  \n",
       "34716         715  \n",
       "34721         671  \n",
       "\n",
       "[18216 rows x 8 columns]"
      ]
     },
     "execution_count": 198,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "squad_dataset.test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-12T16:16:37.934198Z",
     "iopub.status.busy": "2021-01-12T16:16:37.933893Z",
     "iopub.status.idle": "2021-01-12T16:16:38.002341Z",
     "shell.execute_reply": "2021-01-12T16:16:38.001182Z",
     "shell.execute_reply.started": "2021-01-12T16:16:37.934160Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('To whom did the Virgin Mary allegedly appear in 1858 in Lourdes France?',\n",
       " 'Architecturally, the school has a Catholic character. Atop the Main Building\\'s gold dome is a golden statue of the Virgin Mary. Immediately in front of the Main Building and facing it, is a copper statue of Christ with arms upraised with the legend \"Venite Ad Me Omnes\". Next to the Main Building is the Basilica of the Sacred Heart. Immediately behind the basilica is the Grotto, a Marian place of prayer and reflection. It is a replica of the grotto at Lourdes, France where the Virgin Mary reputedly appeared to Saint Bernadette Soubirous in 1858. At the end of the main drive (and in a direct line that connects through 3 statues and the Gold Dome), is a simple, modern stone statue of Mary.',\n",
       " 515,\n",
       " 541)"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "squad_dataset.train_dataset[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GloVe embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-12T15:33:10.376025Z",
     "iopub.status.busy": "2021-01-12T15:33:10.375687Z",
     "iopub.status.idle": "2021-01-12T15:33:10.436480Z",
     "shell.execute_reply": "2021-01-12T15:33:10.435354Z",
     "shell.execute_reply.started": "2021-01-12T15:33:10.375986Z"
    }
   },
   "outputs": [],
   "source": [
    "UNK_TOKEN = \"[UNK]\"\n",
    "PAD_TOKEN = \"[PAD]\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- FastText: \n",
    "    - _fasttext-wiki-news-subwords_ (dimensions: 300)\n",
    "- GloVe:\n",
    "    - _glove-twitter_ (dimensions: 25. 50, 100, 200)\n",
    "    - _glove-wiki-gigaword_ (dimensions: 50, 100, 200, 300)\n",
    "- Word2Vec:\n",
    "    - _word2vec-google-news_ (dimensions: 300)\n",
    "    - _word2vec-ruscorpora_ (dimensions: 300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-12T15:33:11.304855Z",
     "iopub.status.busy": "2021-01-12T15:33:11.304520Z",
     "iopub.status.idle": "2021-01-12T15:35:47.998165Z",
     "shell.execute_reply": "2021-01-12T15:35:47.996549Z",
     "shell.execute_reply.started": "2021-01-12T15:33:11.304816Z"
    }
   },
   "outputs": [],
   "source": [
    "def load_embedding_model(model_name, embedding_dimension=50):\n",
    "    \"\"\"\n",
    "    Loads a pre-trained word embedding model via gensim library\n",
    "    \"\"\"\n",
    "    model = f\"{model_name}-{embedding_dimension}\"\n",
    "    try:\n",
    "        return gloader.load(model)\n",
    "    except Exception as e:\n",
    "        print(\"Invalid embedding model name.\")\n",
    "        raise e\n",
    "\n",
    "\n",
    "# See https://github.com/RaRe-Technologies/gensim-data\n",
    "GLOVE_EMBEDDING_DIMENSION = 50\n",
    "GLOVE_MODEL_NAME = \"glove-twitter\"\n",
    "glove_embedding_model = load_embedding_model(\n",
    "    GLOVE_MODEL_NAME, embedding_dimension=GLOVE_EMBEDDING_DIMENSION\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-12T15:35:48.083118Z",
     "iopub.status.busy": "2021-01-12T15:35:48.082806Z",
     "iopub.status.idle": "2021-01-12T15:35:48.651671Z",
     "shell.execute_reply": "2021-01-12T15:35:48.650357Z",
     "shell.execute_reply.started": "2021-01-12T15:35:48.083080Z"
    }
   },
   "outputs": [],
   "source": [
    "glove_unk = np.mean(glove_embedding_model.vectors, axis=0)\n",
    "glove_embedding_model.add(UNK_TOKEN, glove_unk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-12T15:35:48.654181Z",
     "iopub.status.busy": "2021-01-12T15:35:48.653855Z",
     "iopub.status.idle": "2021-01-12T15:35:48.721489Z",
     "shell.execute_reply": "2021-01-12T15:35:48.720435Z",
     "shell.execute_reply.started": "2021-01-12T15:35:48.654140Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.21896735,  0.17269313, -0.05617283,  0.06307325,  0.00960657,\n",
       "       -0.23461065, -0.16731773, -0.25613925,  0.12990713, -0.34179848,\n",
       "       -0.07411992,  0.00533567,  0.7090377 , -0.1139018 ,  0.10613882,\n",
       "        0.09186497,  0.15880948,  0.03158554,  0.2241412 ,  0.20387109,\n",
       "        0.05305386,  0.04961218,  0.11807557, -0.10199773, -0.18345806,\n",
       "        0.56560194,  0.07183363,  0.04322447, -0.39442873,  0.06828266,\n",
       "        0.39542177,  0.08794834,  0.41605434, -0.27820984, -0.5106833 ,\n",
       "       -0.16443801,  0.0973425 ,  0.02233286,  0.19346187,  0.15909852,\n",
       "        0.886585  , -0.01498107,  0.10211241, -0.12959567, -0.328366  ,\n",
       "        0.13014658, -0.02061043,  0.05735753,  0.14008364,  0.22588447],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "glove_embedding_model[UNK_TOKEN]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-12T15:35:48.723312Z",
     "iopub.status.busy": "2021-01-12T15:35:48.722993Z",
     "iopub.status.idle": "2021-01-12T15:35:48.870764Z",
     "shell.execute_reply": "2021-01-12T15:35:48.869591Z",
     "shell.execute_reply.started": "2021-01-12T15:35:48.723274Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[UNK]'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(glove_embedding_model.vocab.keys())[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-12T15:35:48.873449Z",
     "iopub.status.busy": "2021-01-12T15:35:48.873023Z",
     "iopub.status.idle": "2021-01-12T15:35:49.165235Z",
     "shell.execute_reply": "2021-01-12T15:35:49.164039Z",
     "shell.execute_reply.started": "2021-01-12T15:35:48.873408Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "any(np.all(glove_embedding_model.vectors == 0, axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-12T15:35:49.168217Z",
     "iopub.status.busy": "2021-01-12T15:35:49.167086Z",
     "iopub.status.idle": "2021-01-12T15:35:49.499676Z",
     "shell.execute_reply": "2021-01-12T15:35:49.498566Z",
     "shell.execute_reply.started": "2021-01-12T15:35:49.168173Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "glove_embedding_model.add(PAD_TOKEN, np.zeros((1, GLOVE_EMBEDDING_DIMENSION)))\n",
    "glove_embedding_model[PAD_TOKEN]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-12T15:35:49.503950Z",
     "iopub.status.busy": "2021-01-12T15:35:49.503623Z",
     "iopub.status.idle": "2021-01-12T15:35:49.645851Z",
     "shell.execute_reply": "2021-01-12T15:35:49.644711Z",
     "shell.execute_reply.started": "2021-01-12T15:35:49.503909Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[PAD]'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(glove_embedding_model.vocab.keys())[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-12T15:35:49.648893Z",
     "iopub.status.busy": "2021-01-12T15:35:49.648537Z",
     "iopub.status.idle": "2021-01-12T15:35:49.715367Z",
     "shell.execute_reply": "2021-01-12T15:35:49.714090Z",
     "shell.execute_reply.started": "2021-01-12T15:35:49.648851Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1193516, 50)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "glove_embedding_model.vectors.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-12T15:35:49.717035Z",
     "iopub.status.busy": "2021-01-12T15:35:49.716723Z",
     "iopub.status.idle": "2021-01-12T15:35:50.334772Z",
     "shell.execute_reply": "2021-01-12T15:35:50.333393Z",
     "shell.execute_reply.started": "2021-01-12T15:35:49.716997Z"
    }
   },
   "outputs": [],
   "source": [
    "glove_vocab = dict(\n",
    "    zip(glove_embedding_model.index2word, range(len(glove_embedding_model.index2word)))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-12T15:35:50.336907Z",
     "iopub.status.busy": "2021-01-12T15:35:50.336580Z",
     "iopub.status.idle": "2021-01-12T15:35:52.974789Z",
     "shell.execute_reply": "2021-01-12T15:35:52.973412Z",
     "shell.execute_reply.started": "2021-01-12T15:35:50.336865Z"
    }
   },
   "outputs": [],
   "source": [
    "glove_embedding_layer = nn.Embedding(\n",
    "    glove_embedding_model.vectors.shape[0],\n",
    "    GLOVE_EMBEDDING_DIMENSION,\n",
    "    padding_idx=glove_vocab[PAD_TOKEN],\n",
    ")\n",
    "glove_embedding_layer.weight = nn.Parameter(\n",
    "    torch.from_numpy(glove_embedding_model.vectors)\n",
    ")\n",
    "glove_embedding_layer.weight.requires_grad = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Baseline tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-12T15:35:52.976798Z",
     "iopub.status.busy": "2021-01-12T15:35:52.976471Z",
     "iopub.status.idle": "2021-01-12T15:35:53.040509Z",
     "shell.execute_reply": "2021-01-12T15:35:53.039445Z",
     "shell.execute_reply.started": "2021-01-12T15:35:52.976757Z"
    }
   },
   "outputs": [],
   "source": [
    "MAX_CONTEXT_TOKENS = 300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-12T16:16:53.357615Z",
     "iopub.status.busy": "2021-01-12T16:16:53.357185Z",
     "iopub.status.idle": "2021-01-12T16:16:57.023356Z",
     "shell.execute_reply": "2021-01-12T16:16:57.021842Z",
     "shell.execute_reply.started": "2021-01-12T16:16:53.357570Z"
    }
   },
   "outputs": [],
   "source": [
    "baseline_question_tokenizer = Tokenizer(WordLevel(glove_vocab, unk_token=UNK_TOKEN))\n",
    "baseline_question_tokenizer.normalizer = Sequence([StripAccents(), Lowercase(), Strip()])\n",
    "baseline_question_tokenizer.pre_tokenizer = PreSequence([Whitespace(), Punctuation()])\n",
    "baseline_question_tokenizer.enable_padding(\n",
    "    direction=\"right\",\n",
    "    pad_id=glove_vocab[PAD_TOKEN],\n",
    "    pad_type_id=1,\n",
    "    pad_token=PAD_TOKEN\n",
    ")\n",
    "\n",
    "baseline_context_tokenizer = Tokenizer(WordLevel(glove_vocab, unk_token=UNK_TOKEN))\n",
    "baseline_context_tokenizer.normalizer = Sequence([StripAccents(), Lowercase(), Strip()])\n",
    "baseline_context_tokenizer.pre_tokenizer = PreSequence([Whitespace(), Punctuation()])\n",
    "baseline_context_tokenizer.enable_padding(\n",
    "    direction=\"right\",\n",
    "    pad_id=glove_vocab[PAD_TOKEN],\n",
    "    pad_type_id=1,\n",
    "    pad_token=PAD_TOKEN,\n",
    "    length=MAX_CONTEXT_TOKENS,\n",
    ")\n",
    "baseline_context_tokenizer.enable_truncation(MAX_CONTEXT_TOKENS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-12T16:17:01.356246Z",
     "iopub.status.busy": "2021-01-12T16:17:01.355876Z",
     "iopub.status.idle": "2021-01-12T16:17:49.223457Z",
     "shell.execute_reply": "2021-01-12T16:17:49.221723Z",
     "shell.execute_reply.started": "2021-01-12T16:17:01.356203Z"
    }
   },
   "outputs": [],
   "source": [
    "def lost_answers_indexes(df, tokenized_contexts):\n",
    "    whole_answers_start = df[\"answer_start\"].tolist()\n",
    "    whole_answers_end = df[\"answer_end\"].tolist()\n",
    "    lost_dirty, lost_truncated = [], []\n",
    "    for i, (c, s, e) in enumerate(\n",
    "        zip(tokenized_contexts, whole_answers_start, whole_answers_end)\n",
    "    ):\n",
    "        offsets = torch.tensor(c.offsets)[torch.tensor(c.attention_mask).bool()]\n",
    "        start_index = torch.nonzero(offsets[:, 0] == s)\n",
    "        end_index = torch.nonzero(offsets[:, 1] == e)\n",
    "        if len(start_index) == 0 or len(end_index) == 0:\n",
    "            if s > offsets[-1, 0] or e > offsets[-1, 1]:\n",
    "                lost_truncated.append(i)\n",
    "            else:\n",
    "                lost_dirty.append(i)\n",
    "\n",
    "    return lost_truncated, lost_dirty\n",
    "\n",
    "\n",
    "tokenized_contexts = baseline_context_tokenizer.encode_batch(\n",
    "    squad_dataset.dataframe[\"context\"].tolist()\n",
    ")\n",
    "lost_truncated, lost_dirty = lost_answers_indexes(\n",
    "    squad_dataset.dataframe, tokenized_contexts\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-12T16:17:51.464269Z",
     "iopub.status.busy": "2021-01-12T16:17:51.463947Z",
     "iopub.status.idle": "2021-01-12T16:17:51.535128Z",
     "shell.execute_reply": "2021-01-12T16:17:51.534013Z",
     "shell.execute_reply.started": "2021-01-12T16:17:51.464228Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lost 183/87599 (0.21%) answers, because of truncation\n",
      "Lost 260/87599 (0.30%) answers, because of dirtyness\n"
     ]
    }
   ],
   "source": [
    "lost_truncated_perc = len(lost_truncated) / len(squad_dataset.dataframe)\n",
    "lost_dirty_perc = len(lost_dirty) / len(squad_dataset.dataframe)\n",
    "print(\n",
    "    f\"Lost {len(lost_truncated)}/{len(squad_dataset.dataframe)} ({lost_truncated_perc:.2%}) answers, because of truncation\"\n",
    ")\n",
    "print(\n",
    "    f\"Lost {len(lost_dirty)}/{len(squad_dataset.dataframe)} ({lost_dirty_perc:.2%}) answers, because of dirtyness\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-12T16:17:55.506217Z",
     "iopub.status.busy": "2021-01-12T16:17:55.505787Z",
     "iopub.status.idle": "2021-01-12T16:17:55.588617Z",
     "shell.execute_reply": "2021-01-12T16:17:55.587391Z",
     "shell.execute_reply.started": "2021-01-12T16:17:55.506173Z"
    }
   },
   "outputs": [],
   "source": [
    "def show_df_row(df, index):\n",
    "    row = df.iloc[index]\n",
    "    display(HTML(pd.DataFrame([row]).to_html()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-12T16:17:57.573971Z",
     "iopub.status.busy": "2021-01-12T16:17:57.573646Z",
     "iopub.status.idle": "2021-01-12T16:17:57.665174Z",
     "shell.execute_reply": "2021-01-12T16:17:57.663885Z",
     "shell.execute_reply.started": "2021-01-12T16:17:57.573930Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>question</th>\n",
       "      <th>title</th>\n",
       "      <th>context_id</th>\n",
       "      <th>context</th>\n",
       "      <th>answer</th>\n",
       "      <th>answer_start</th>\n",
       "      <th>answer_end</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>455</th>\n",
       "      <td>56bf97aba10cfb14005511a1</td>\n",
       "      <td>How much did the second world tour make in dollars?</td>\n",
       "      <td>Beyoncé</td>\n",
       "      <td>69</td>\n",
       "      <td>On April 4, 2008, Beyoncé married Jay Z. She publicly revealed their marriage in a video montage at the listening party for her third studio album, I Am... Sasha Fierce, in Manhattan's Sony Club on October 22, 2008. I Am... Sasha Fierce was released on November 18, 2008 in the United States. The album formally introduces Beyoncé's alter ego Sasha Fierce, conceived during the making of her 2003 single \"Crazy in Love\", selling 482,000 copies in its first week, debuting atop the Billboard 200, and giving Beyoncé her third consecutive number-one album in the US. The album featured the number-one song \"Single Ladies (Put a Ring on It)\" and the top-five songs \"If I Were a Boy\" and \"Halo\". Achieving the accomplishment of becoming her longest-running Hot 100 single in her career, \"Halo\"'s success in the US helped Beyoncé attain more top-ten singles on the list than any other woman during the 2000s. It also included the successful \"Sweet Dreams\", and singles \"Diva\", \"Ego\", \"Broken-Hearted Girl\" and \"Video Phone\". The music video for \"Single Ladies\" has been parodied and imitated around the world, spawning the \"first major dance craze\" of the Internet age according to the Toronto Star. The video has won several awards, including Best Video at the 2009 MTV Europe Music Awards, the 2009 Scottish MOBO Awards, and the 2009 BET Awards. At the 2009 MTV Video Music Awards, the video was nominated for nine awards, ultimately winning three including Video of the Year. Its failure to win the Best Female Video category, which went to American country pop singer Taylor Swift's \"You Belong with Me\", led to Kanye West interrupting the ceremony and Beyoncé improvising a re-presentation of Swift's award during her own acceptance speech. In March 2009, Beyoncé embarked on the I Am... World Tour, her second headlining worldwide concert tour, consisting of 108 shows, grossing $119.5 million.</td>\n",
       "      <td>119.5 million</td>\n",
       "      <td>1881</td>\n",
       "      <td>1894</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "random_trunc_index = random.choice(lost_truncated)\n",
    "show_df_row(squad_dataset.dataframe, random_trunc_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-12T16:18:40.356985Z",
     "iopub.status.busy": "2021-01-12T16:18:40.356560Z",
     "iopub.status.idle": "2021-01-12T16:18:40.434894Z",
     "shell.execute_reply": "2021-01-12T16:18:40.433676Z",
     "shell.execute_reply.started": "2021-01-12T16:18:40.356940Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>question</th>\n",
       "      <th>title</th>\n",
       "      <th>context_id</th>\n",
       "      <th>context</th>\n",
       "      <th>answer</th>\n",
       "      <th>answer_start</th>\n",
       "      <th>answer_end</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>14434</th>\n",
       "      <td>56e080dc231d4119001ac20d</td>\n",
       "      <td>How many satellites provide the link to the internet?</td>\n",
       "      <td>Saint_Helena</td>\n",
       "      <td>3142</td>\n",
       "      <td>Saint Helena has a 10/3.6 Mbit/s internet link via Intelsat 707 provided by SURE. Serving a population of more than 4,000, this single satellite link is considered inadequate in terms of bandwidth.</td>\n",
       "      <td>1</td>\n",
       "      <td>19</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "random_dirty_index = random.choice(lost_dirty)\n",
    "show_df_row(squad_dataset.dataframe, random_dirty_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-12T16:22:06.356857Z",
     "iopub.status.busy": "2021-01-12T16:22:06.356432Z",
     "iopub.status.idle": "2021-01-12T16:22:06.475642Z",
     "shell.execute_reply": "2021-01-12T16:22:06.474162Z",
     "shell.execute_reply.started": "2021-01-12T16:22:06.356812Z"
    }
   },
   "outputs": [],
   "source": [
    "to_remove = lost_truncated + lost_dirty\n",
    "df = squad_dataset.dataframe.drop(to_remove)\n",
    "assert len(df) == len(squad_dataset.dataframe) - len(to_remove), (\n",
    "    f\"Before {len(squad_dataset.dataframe)}, \"\n",
    "    f\"after {len(df)}, \"\n",
    "    f\"removed {len(to_remove)}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-12T16:22:08.528091Z",
     "iopub.status.busy": "2021-01-12T16:22:08.527773Z",
     "iopub.status.idle": "2021-01-12T16:22:08.712521Z",
     "shell.execute_reply": "2021-01-12T16:22:08.711391Z",
     "shell.execute_reply.started": "2021-01-12T16:22:08.528050Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>question</th>\n",
       "      <th>title</th>\n",
       "      <th>context_id</th>\n",
       "      <th>context</th>\n",
       "      <th>answer</th>\n",
       "      <th>answer_start</th>\n",
       "      <th>answer_end</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5733be284776f41900661182</td>\n",
       "      <td>To whom did the Virgin Mary allegedly appear i...</td>\n",
       "      <td>University_of_Notre_Dame</td>\n",
       "      <td>0</td>\n",
       "      <td>Architecturally, the school has a Catholic cha...</td>\n",
       "      <td>Saint Bernadette Soubirous</td>\n",
       "      <td>515</td>\n",
       "      <td>541</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5733be284776f4190066117f</td>\n",
       "      <td>What is in front of the Notre Dame Main Building?</td>\n",
       "      <td>University_of_Notre_Dame</td>\n",
       "      <td>0</td>\n",
       "      <td>Architecturally, the school has a Catholic cha...</td>\n",
       "      <td>a copper statue of Christ</td>\n",
       "      <td>188</td>\n",
       "      <td>213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5733be284776f41900661180</td>\n",
       "      <td>The Basilica of the Sacred heart at Notre Dame...</td>\n",
       "      <td>University_of_Notre_Dame</td>\n",
       "      <td>0</td>\n",
       "      <td>Architecturally, the school has a Catholic cha...</td>\n",
       "      <td>the Main Building</td>\n",
       "      <td>279</td>\n",
       "      <td>296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5733be284776f41900661181</td>\n",
       "      <td>What is the Grotto at Notre Dame?</td>\n",
       "      <td>University_of_Notre_Dame</td>\n",
       "      <td>0</td>\n",
       "      <td>Architecturally, the school has a Catholic cha...</td>\n",
       "      <td>a Marian place of prayer and reflection</td>\n",
       "      <td>381</td>\n",
       "      <td>420</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5733be284776f4190066117e</td>\n",
       "      <td>What sits on top of the Main Building at Notre...</td>\n",
       "      <td>University_of_Notre_Dame</td>\n",
       "      <td>0</td>\n",
       "      <td>Architecturally, the school has a Catholic cha...</td>\n",
       "      <td>a golden statue of the Virgin Mary</td>\n",
       "      <td>92</td>\n",
       "      <td>126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87594</th>\n",
       "      <td>5735d259012e2f140011a09d</td>\n",
       "      <td>In what US state did Kathmandu first establish...</td>\n",
       "      <td>Kathmandu</td>\n",
       "      <td>18890</td>\n",
       "      <td>Kathmandu Metropolitan City (KMC), in order to...</td>\n",
       "      <td>Oregon</td>\n",
       "      <td>229</td>\n",
       "      <td>235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87595</th>\n",
       "      <td>5735d259012e2f140011a09e</td>\n",
       "      <td>What was Yangon previously known as?</td>\n",
       "      <td>Kathmandu</td>\n",
       "      <td>18890</td>\n",
       "      <td>Kathmandu Metropolitan City (KMC), in order to...</td>\n",
       "      <td>Rangoon</td>\n",
       "      <td>414</td>\n",
       "      <td>421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87596</th>\n",
       "      <td>5735d259012e2f140011a09f</td>\n",
       "      <td>With what Belorussian city does Kathmandu have...</td>\n",
       "      <td>Kathmandu</td>\n",
       "      <td>18890</td>\n",
       "      <td>Kathmandu Metropolitan City (KMC), in order to...</td>\n",
       "      <td>Minsk</td>\n",
       "      <td>476</td>\n",
       "      <td>481</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87597</th>\n",
       "      <td>5735d259012e2f140011a0a0</td>\n",
       "      <td>In what year did Kathmandu create its initial ...</td>\n",
       "      <td>Kathmandu</td>\n",
       "      <td>18890</td>\n",
       "      <td>Kathmandu Metropolitan City (KMC), in order to...</td>\n",
       "      <td>1975</td>\n",
       "      <td>199</td>\n",
       "      <td>203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87598</th>\n",
       "      <td>5735d259012e2f140011a0a1</td>\n",
       "      <td>What is KMC an initialism of?</td>\n",
       "      <td>Kathmandu</td>\n",
       "      <td>18890</td>\n",
       "      <td>Kathmandu Metropolitan City (KMC), in order to...</td>\n",
       "      <td>Kathmandu Metropolitan City</td>\n",
       "      <td>0</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>87156 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                          index  \\\n",
       "0      5733be284776f41900661182   \n",
       "1      5733be284776f4190066117f   \n",
       "2      5733be284776f41900661180   \n",
       "3      5733be284776f41900661181   \n",
       "4      5733be284776f4190066117e   \n",
       "...                         ...   \n",
       "87594  5735d259012e2f140011a09d   \n",
       "87595  5735d259012e2f140011a09e   \n",
       "87596  5735d259012e2f140011a09f   \n",
       "87597  5735d259012e2f140011a0a0   \n",
       "87598  5735d259012e2f140011a0a1   \n",
       "\n",
       "                                                question  \\\n",
       "0      To whom did the Virgin Mary allegedly appear i...   \n",
       "1      What is in front of the Notre Dame Main Building?   \n",
       "2      The Basilica of the Sacred heart at Notre Dame...   \n",
       "3                      What is the Grotto at Notre Dame?   \n",
       "4      What sits on top of the Main Building at Notre...   \n",
       "...                                                  ...   \n",
       "87594  In what US state did Kathmandu first establish...   \n",
       "87595               What was Yangon previously known as?   \n",
       "87596  With what Belorussian city does Kathmandu have...   \n",
       "87597  In what year did Kathmandu create its initial ...   \n",
       "87598                      What is KMC an initialism of?   \n",
       "\n",
       "                          title  context_id  \\\n",
       "0      University_of_Notre_Dame           0   \n",
       "1      University_of_Notre_Dame           0   \n",
       "2      University_of_Notre_Dame           0   \n",
       "3      University_of_Notre_Dame           0   \n",
       "4      University_of_Notre_Dame           0   \n",
       "...                         ...         ...   \n",
       "87594                 Kathmandu       18890   \n",
       "87595                 Kathmandu       18890   \n",
       "87596                 Kathmandu       18890   \n",
       "87597                 Kathmandu       18890   \n",
       "87598                 Kathmandu       18890   \n",
       "\n",
       "                                                 context  \\\n",
       "0      Architecturally, the school has a Catholic cha...   \n",
       "1      Architecturally, the school has a Catholic cha...   \n",
       "2      Architecturally, the school has a Catholic cha...   \n",
       "3      Architecturally, the school has a Catholic cha...   \n",
       "4      Architecturally, the school has a Catholic cha...   \n",
       "...                                                  ...   \n",
       "87594  Kathmandu Metropolitan City (KMC), in order to...   \n",
       "87595  Kathmandu Metropolitan City (KMC), in order to...   \n",
       "87596  Kathmandu Metropolitan City (KMC), in order to...   \n",
       "87597  Kathmandu Metropolitan City (KMC), in order to...   \n",
       "87598  Kathmandu Metropolitan City (KMC), in order to...   \n",
       "\n",
       "                                        answer  answer_start  answer_end  \n",
       "0                   Saint Bernadette Soubirous           515         541  \n",
       "1                    a copper statue of Christ           188         213  \n",
       "2                            the Main Building           279         296  \n",
       "3      a Marian place of prayer and reflection           381         420  \n",
       "4           a golden statue of the Virgin Mary            92         126  \n",
       "...                                        ...           ...         ...  \n",
       "87594                                   Oregon           229         235  \n",
       "87595                                  Rangoon           414         421  \n",
       "87596                                    Minsk           476         481  \n",
       "87597                                     1975           199         203  \n",
       "87598              Kathmandu Metropolitan City             0          27  \n",
       "\n",
       "[87156 rows x 8 columns]"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "squad_dataset.update_df(df)\n",
    "squad_dataset.dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Metrics and logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-12T15:37:18.261027Z",
     "iopub.status.busy": "2021-01-12T15:37:18.260707Z",
     "iopub.status.idle": "2021-01-12T15:37:18.326166Z",
     "shell.execute_reply": "2021-01-12T15:37:18.325085Z",
     "shell.execute_reply.started": "2021-01-12T15:37:18.260986Z"
    }
   },
   "outputs": [],
   "source": [
    "def exact_match(labels, preds):\n",
    "    assert labels.shape == preds.shape\n",
    "    total = labels.shape[0]\n",
    "    matches = np.count_nonzero((labels == preds).all(axis=1))\n",
    "    return matches / total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-12T15:47:27.520181Z",
     "iopub.status.busy": "2021-01-12T15:47:27.519759Z",
     "iopub.status.idle": "2021-01-12T15:47:27.595137Z",
     "shell.execute_reply": "2021-01-12T15:47:27.593932Z",
     "shell.execute_reply.started": "2021-01-12T15:47:27.520136Z"
    }
   },
   "outputs": [],
   "source": [
    "def compute_metrics(eval_prediction):\n",
    "    # Labels are stored as a tuple of tensors\n",
    "    # (one for answer start and one for answer end)\n",
    "    labels = torch.cat(\n",
    "        [\n",
    "            eval_prediction.label_ids[0].view(-1, 1),\n",
    "            eval_prediction.label_ids[1].view(-1, 1),\n",
    "        ],\n",
    "        dim=1,\n",
    "    ).numpy()\n",
    "    preds = eval_prediction.predictions.numpy()\n",
    "    f_labels, f_preds = labels.flatten(), preds.flatten()\n",
    "    return {\n",
    "        \"f1\": sklearn.metrics.f1_score(f_labels, f_preds, average=\"macro\"),\n",
    "        \"accuracy\": sklearn.metrics.accuracy_score(f_labels, f_preds),\n",
    "        \"em\": exact_match(labels, preds),\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-12T16:09:09.408471Z",
     "iopub.status.busy": "2021-01-12T16:09:09.408004Z",
     "iopub.status.idle": "2021-01-12T16:09:09.493151Z",
     "shell.execute_reply": "2021-01-12T16:09:09.491817Z",
     "shell.execute_reply.started": "2021-01-12T16:09:09.408423Z"
    }
   },
   "outputs": [],
   "source": [
    "class SquadTrainer(transformers.Trainer):\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        super(SquadTrainer, self).__init__(*args, **kwargs)\n",
    "\n",
    "    def compute_loss(self, model, inputs):\n",
    "        \"\"\"\n",
    "        How the loss is computed by Trainer. By default, all models return the loss in the first element.\n",
    "\n",
    "        Subclass and override for custom behavior.\n",
    "        \"\"\"\n",
    "        outputs = model(**inputs)\n",
    "\n",
    "        if (self.state.global_step == 1 and self.args.logging_first_step) or (\n",
    "            self.args.logging_steps > 0\n",
    "            and self.state.global_step > 0\n",
    "            and self.state.global_step % self.args.logging_steps == 0\n",
    "        ):\n",
    "            has_labels = all(inputs.get(k) is not None for k in self.label_names)\n",
    "            if has_labels:\n",
    "                labels = nested_detach(\n",
    "                    tuple(inputs.get(name) for name in self.label_names)\n",
    "                )\n",
    "                if len(labels) == 1:\n",
    "                    labels = labels[0]\n",
    "            else:\n",
    "                labels = None\n",
    "\n",
    "            if labels is not None:\n",
    "                metrics = self.compute_metrics(\n",
    "                    EvalPrediction(predictions=outputs[\"outputs\"], label_ids=labels)\n",
    "                )\n",
    "                self.log(metrics)\n",
    "\n",
    "        # Save past state if it exists\n",
    "        # TODO: this needs to be fixed and made cleaner later.\n",
    "        if self.args.past_index >= 0:\n",
    "            self._past = outputs[self.args.past_index]\n",
    "        # We don't use .loss here since the model may return tuples instead of ModelOutput.\n",
    "        return outputs[\"loss\"] if isinstance(outputs, dict) else outputs[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-12T16:09:11.569274Z",
     "iopub.status.busy": "2021-01-12T16:09:11.568950Z",
     "iopub.status.idle": "2021-01-12T16:09:11.664843Z",
     "shell.execute_reply": "2021-01-12T16:09:11.663511Z",
     "shell.execute_reply.started": "2021-01-12T16:09:11.569232Z"
    }
   },
   "outputs": [],
   "source": [
    "class BaselineDataCollatorWithPadding:\n",
    "    \"\"\"\n",
    "    Data collator that will dynamically pad the inputs received\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, question_tokenizer, context_tokenizer):\n",
    "        self.question_tokenizer = question_tokenizer\n",
    "        self.context_tokenizer = context_tokenizer\n",
    "\n",
    "    def find_tokenized_answer_indexes(self, offsets, query, dim):\n",
    "        index = torch.nonzero(offsets[:, dim] == query)\n",
    "        assert len(index) in (0, 1)\n",
    "        return index.item() if len(index) > 0 else -1\n",
    "\n",
    "    def __call__(self, inputs):\n",
    "        (questions, contexts, answers_start, answers_end) = zip(*inputs)\n",
    "        tokenized_questions = self.question_tokenizer.encode_batch(questions)\n",
    "        tokenized_contexts = self.context_tokenizer.encode_batch(contexts)\n",
    "        batch_size = len(tokenized_questions)\n",
    "        questions_shape = (batch_size, len(tokenized_questions[0].ids))\n",
    "        contexts_shape = (batch_size, len(tokenized_contexts[0].ids))\n",
    "\n",
    "        batch = {\n",
    "            \"question_ids\": torch.empty(questions_shape, dtype=torch.long),\n",
    "            \"question_type_ids\": torch.empty(questions_shape, dtype=torch.long),\n",
    "            \"question_attention_mask\": torch.empty(questions_shape, dtype=torch.bool),\n",
    "            \"question_special_tokens_mask\": torch.empty(\n",
    "                questions_shape, dtype=torch.bool\n",
    "            ),\n",
    "            \"question_lenghts\": torch.empty((batch_size,), dtype=torch.long),\n",
    "            \"context_ids\": torch.empty(contexts_shape, dtype=torch.long),\n",
    "            \"context_type_ids\": torch.empty(contexts_shape, dtype=torch.long),\n",
    "            \"context_attention_mask\": torch.empty(contexts_shape, dtype=torch.bool),\n",
    "            \"context_special_tokens_mask\": torch.empty(\n",
    "                contexts_shape, dtype=torch.bool\n",
    "            ),\n",
    "            \"context_offsets\": torch.empty((*contexts_shape, 2), dtype=torch.long),\n",
    "            \"context_lenghts\": torch.empty((batch_size,), dtype=torch.long),\n",
    "            # \"answer_start\": torch.tensor(answers_start, dtype=torch.long),\n",
    "            # \"answer_end\": torch.tensor(answers_end, dtype=torch.long),\n",
    "            \"answer_start\": torch.empty((batch_size,), dtype=torch.long),\n",
    "            \"answer_end\": torch.empty((batch_size,), dtype=torch.long),\n",
    "        }\n",
    "        for i in range(batch_size):\n",
    "            batch[\"question_ids\"][i] = torch.tensor(tokenized_questions[i].ids)\n",
    "            batch[\"question_type_ids\"][i] = torch.tensor(\n",
    "                tokenized_questions[i].type_ids\n",
    "            )\n",
    "            batch[\"question_attention_mask\"][i] = torch.tensor(\n",
    "                tokenized_questions[i].attention_mask\n",
    "            )\n",
    "            batch[\"question_special_tokens_mask\"][i] = torch.tensor(\n",
    "                tokenized_questions[i].special_tokens_mask\n",
    "            )\n",
    "            batch[\"question_lenghts\"][i] = torch.count_nonzero(\n",
    "                ~batch[\"question_special_tokens_mask\"][i]\n",
    "            )\n",
    "            batch[\"context_ids\"][i] = torch.tensor(tokenized_contexts[i].ids)\n",
    "            batch[\"context_type_ids\"][i] = torch.tensor(tokenized_contexts[i].type_ids)\n",
    "            batch[\"context_attention_mask\"][i] = torch.tensor(\n",
    "                tokenized_contexts[i].attention_mask\n",
    "            )\n",
    "            batch[\"context_special_tokens_mask\"][i] = torch.tensor(\n",
    "                tokenized_contexts[i].special_tokens_mask\n",
    "            )\n",
    "            batch[\"context_offsets\"][i] = torch.tensor(tokenized_contexts[i].offsets)\n",
    "            batch[\"context_lenghts\"][i] = torch.count_nonzero(\n",
    "                ~batch[\"context_special_tokens_mask\"][i]\n",
    "            )\n",
    "            masked_offsets = batch[\"context_offsets\"][i][batch[\"context_attention_mask\"][i]]\n",
    "            batch[\"answer_start\"][i] = self.find_tokenized_answer_indexes(\n",
    "                masked_offsets, answers_start[i], 0\n",
    "            )\n",
    "            batch[\"answer_end\"][i] = self.find_tokenized_answer_indexes(\n",
    "                masked_offsets, answers_end[i], 1\n",
    "            )\n",
    "\n",
    "        return batch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Baseline model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-12T16:09:11.667233Z",
     "iopub.status.busy": "2021-01-12T16:09:11.666895Z",
     "iopub.status.idle": "2021-01-12T16:09:11.744908Z",
     "shell.execute_reply": "2021-01-12T16:09:11.743784Z",
     "shell.execute_reply.started": "2021-01-12T16:09:11.667191Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "101400"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "baseline_model = model.QABaselineModel(glove_embedding_layer, MAX_CONTEXT_TOKENS)\n",
    "baseline_model.count_parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-12T16:09:15.927044Z",
     "iopub.status.busy": "2021-01-12T16:09:15.926671Z",
     "iopub.status.idle": "2021-01-12T16:09:15.997593Z",
     "shell.execute_reply": "2021-01-12T16:09:15.996554Z",
     "shell.execute_reply.started": "2021-01-12T16:09:15.927002Z"
    }
   },
   "outputs": [],
   "source": [
    "baseline_args = transformers.TrainingArguments(\n",
    "    output_dir=\"./checkpoints\",\n",
    "    logging_dir=\"./runs\",\n",
    "    logging_first_step=True,\n",
    "    logging_steps=5,\n",
    "    overwrite_output_dir=True,\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    learning_rate=1e-3,\n",
    "    num_train_epochs=10,\n",
    "    remove_unused_columns=False,\n",
    "    per_device_train_batch_size=256,\n",
    "    per_device_eval_batch_size=64,\n",
    "    label_names=[\"answer_start\", \"answer_end\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-12T16:09:15.999336Z",
     "iopub.status.busy": "2021-01-12T16:09:15.999020Z",
     "iopub.status.idle": "2021-01-12T16:09:16.066994Z",
     "shell.execute_reply": "2021-01-12T16:09:16.065713Z",
     "shell.execute_reply.started": "2021-01-12T16:09:15.999298Z"
    }
   },
   "outputs": [],
   "source": [
    "baseline_trainer = SquadTrainer(\n",
    "    model=baseline_model,\n",
    "    args=baseline_args,\n",
    "    data_collator=BaselineDataCollatorWithPadding(\n",
    "        baseline_question_tokenizer, baseline_context_tokenizer\n",
    "    ),\n",
    "    train_dataset=squad_dataset.train_dataset,\n",
    "    eval_dataset=squad_dataset.val_dataset,\n",
    "    compute_metrics=compute_metrics,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-12T16:09:33.858947Z",
     "iopub.status.busy": "2021-01-12T16:09:33.858513Z",
     "iopub.status.idle": "2021-01-12T16:09:36.380312Z",
     "shell.execute_reply": "2021-01-12T16:09:36.378944Z",
     "shell.execute_reply.started": "2021-01-12T16:09:33.858903Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "                Tracking run with wandb version 0.10.13<br/>\n",
       "                Syncing run <strong style=\"color:#cdcd00\">2021-01-12 16:09:33</strong> to <a href=\"https://wandb.ai\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://wandb.ai/wadaboa/squad-qa\" target=\"_blank\">https://wandb.ai/wadaboa/squad-qa</a><br/>\n",
       "                Run page: <a href=\"https://wandb.ai/wadaboa/squad-qa/runs/ojtj5lbn\" target=\"_blank\">https://wandb.ai/wadaboa/squad-qa/runs/ojtj5lbn</a><br/>\n",
       "                Run data is saved locally in <code>/root/jupyter/squad-question-answering/wandb/run-20210112_160933-ojtj5lbn</code><br/><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "run_name = datetime.datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "wandb_logger = init_wandb(name=run_name, group=\"baseline\", reinit=True,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-12T16:09:38.609566Z",
     "iopub.status.busy": "2021-01-12T16:09:38.609230Z",
     "iopub.status.idle": "2021-01-12T16:11:29.487621Z",
     "shell.execute_reply": "2021-01-12T16:11:29.485660Z",
     "shell.execute_reply.started": "2021-01-12T16:09:38.609524Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./checkpoints\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "        </style>\n",
       "      \n",
       "      <progress value='15' max='2730' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [  15/2730 01:37 < 5:39:52, 0.13 it/s, Epoch 0.05/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-86-a28822d33159>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mbaseline_trainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/transformers/trainer.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, model_path, trial)\u001b[0m\n\u001b[1;32m    797\u001b[0m                         \u001b[0mtr_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    798\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 799\u001b[0;31m                     \u001b[0mtr_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    800\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_total_flos\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloating_point_ops\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    801\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/transformers/trainer.py\u001b[0m in \u001b[0;36mtraining_step\u001b[0;34m(self, model, inputs)\u001b[0m\n\u001b[1;32m   1151\u001b[0m                 \u001b[0mscaled_loss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1152\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1153\u001b[0;31m             \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1154\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1155\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    219\u001b[0m                 \u001b[0mretain_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    220\u001b[0m                 create_graph=create_graph)\n\u001b[0;32m--> 221\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    222\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    223\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m    128\u001b[0m         \u001b[0mretain_graph\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 130\u001b[0;31m     Variable._execution_engine.run_backward(\n\u001b[0m\u001b[1;32m    131\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    132\u001b[0m         allow_unreachable=True)  # allow_unreachable flag\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/wandb/wandb_torch.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(grad)\u001b[0m\n\u001b[1;32m    283\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog_tensor_stats\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    284\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 285\u001b[0;31m         \u001b[0mhandle\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvar\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mgrad\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0m_callback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlog_track\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    286\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_hook_handles\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    287\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "baseline_trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-12T16:11:32.407489Z",
     "iopub.status.busy": "2021-01-12T16:11:32.407047Z",
     "iopub.status.idle": "2021-01-12T16:11:36.294290Z",
     "shell.execute_reply": "2021-01-12T16:11:36.293103Z",
     "shell.execute_reply.started": "2021-01-12T16:11:32.407437Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 64782<br/>Program ended successfully."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value=' 0.00MB of 0.00MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=1.0, max=1.0)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find user logs for this run at: <code>/root/jupyter/squad-question-answering/wandb/run-20210112_160933-ojtj5lbn/logs/debug.log</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find internal logs for this run at: <code>/root/jupyter/squad-question-answering/wandb/run-20210112_160933-ojtj5lbn/logs/debug-internal.log</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h3>Run summary:</h3><br/><style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    </style><table class=\"wandb\">\n",
       "<tr><td>train/loss</td><td>11.31863</td></tr><tr><td>train/learning_rate</td><td>0.001</td></tr><tr><td>train/epoch</td><td>0.03663</td></tr><tr><td>train/f1</td><td>0.0</td></tr><tr><td>train/accuracy</td><td>0.0</td></tr><tr><td>train/em</td><td>0.0</td></tr><tr><td>_step</td><td>10</td></tr><tr><td>_runtime</td><td>118</td></tr><tr><td>_timestamp</td><td>1610467892</td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h3>Run history:</h3><br/><style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    </style><table class=\"wandb\">\n",
       "<tr><td>train/loss</td><td>█▆▁</td></tr><tr><td>train/learning_rate</td><td>█▅▁</td></tr><tr><td>train/epoch</td><td>▁▄█</td></tr><tr><td>train/f1</td><td>█▇▁</td></tr><tr><td>train/accuracy</td><td>█▃▁</td></tr><tr><td>train/em</td><td>▁▁▁</td></tr><tr><td>_step</td><td>▁▄█</td></tr><tr><td>_runtime</td><td>▁▅█</td></tr><tr><td>_timestamp</td><td>▁▅█</td></tr></table><br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced 5 W&B file(s), 1 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    <br/>Synced <strong style=\"color:#cdcd00\">2021-01-12 16:09:33</strong>: <a href=\"https://wandb.ai/wadaboa/squad-qa/runs/ojtj5lbn\" target=\"_blank\">https://wandb.ai/wadaboa/squad-qa/runs/ojtj5lbn</a><br/>\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "wandb_logger.finish()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BiDAF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-10T16:45:21.848643Z",
     "iopub.status.busy": "2021-01-10T16:45:21.848207Z",
     "iopub.status.idle": "2021-01-10T16:45:21.934780Z",
     "shell.execute_reply": "2021-01-10T16:45:21.933493Z",
     "shell.execute_reply.started": "2021-01-10T16:45:21.848598Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "314350"
      ]
     },
     "execution_count": 354,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bidaf_model = model.BiDAFModel(glove_embedding_layer)\n",
    "bidaf_model.count_parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 355,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-10T16:45:22.629608Z",
     "iopub.status.busy": "2021-01-10T16:45:22.629295Z",
     "iopub.status.idle": "2021-01-10T16:45:22.699341Z",
     "shell.execute_reply": "2021-01-10T16:45:22.697571Z",
     "shell.execute_reply.started": "2021-01-10T16:45:22.629567Z"
    }
   },
   "outputs": [],
   "source": [
    "bidaf_args = transformers.TrainingArguments(\n",
    "    output_dir=\"./checkpoints\",\n",
    "    logging_dir=\"./runs\",\n",
    "    overwrite_output_dir=True,\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    num_train_epochs=3,\n",
    "    remove_unused_columns=False,\n",
    "    per_device_train_batch_size=256,\n",
    "    per_device_eval_batch_size=64,\n",
    "    label_names=[\"answer_start\", \"answer_end\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-10T16:45:22.851387Z",
     "iopub.status.busy": "2021-01-10T16:45:22.851019Z",
     "iopub.status.idle": "2021-01-10T16:45:22.918908Z",
     "shell.execute_reply": "2021-01-10T16:45:22.917726Z",
     "shell.execute_reply.started": "2021-01-10T16:45:22.851346Z"
    }
   },
   "outputs": [],
   "source": [
    "bidaf_optimizer = optim.Adadelta(bidaf_model.parameters(), lr=0.5)\n",
    "bidaf_lr_scheduler = optim.lr_scheduler.ExponentialLR(bidaf_optimizer, gamma=.999)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-10T16:45:24.289358Z",
     "iopub.status.busy": "2021-01-10T16:45:24.289042Z",
     "iopub.status.idle": "2021-01-10T16:45:24.363955Z",
     "shell.execute_reply": "2021-01-10T16:45:24.362912Z",
     "shell.execute_reply.started": "2021-01-10T16:45:24.289318Z"
    }
   },
   "outputs": [],
   "source": [
    "bidaf_trainer = transformers.Trainer(\n",
    "    model=bidaf_model,\n",
    "    args=bidaf_args,\n",
    "    data_collator=BaselineDataCollatorWithPadding(baseline_question_tokenizer, baseline_context_tokenizer),\n",
    "    train_dataset=squad_dataset.train_dataset,\n",
    "    eval_dataset=squad_dataset.val_dataset,\n",
    "    optimizers=(bidaf_optimizer, bidaf_lr_scheduler),\n",
    "    #callbacks=[transformers.integrations.WandbCallback]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 358,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-10T16:45:33.062428Z",
     "iopub.status.busy": "2021-01-10T16:45:33.061976Z",
     "iopub.status.idle": "2021-01-10T16:46:34.743864Z",
     "shell.execute_reply": "2021-01-10T16:46:34.741691Z",
     "shell.execute_reply.started": "2021-01-10T16:45:33.062384Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([256, 300, 1]) torch.Size([256, 300, 1])\n",
      "tensor(15.0205, grad_fn=<NllLossBackward>) tensor(13.8060, grad_fn=<NllLossBackward>)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-358-a28822d33159>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mbaseline_trainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/transformers/trainer.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, model_path, trial)\u001b[0m\n\u001b[1;32m    797\u001b[0m                         \u001b[0mtr_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    798\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 799\u001b[0;31m                     \u001b[0mtr_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    800\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_total_flos\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloating_point_ops\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    801\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/transformers/trainer.py\u001b[0m in \u001b[0;36mtraining_step\u001b[0;34m(self, model, inputs)\u001b[0m\n\u001b[1;32m   1151\u001b[0m                 \u001b[0mscaled_loss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1152\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1153\u001b[0;31m             \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1154\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1155\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    219\u001b[0m                 \u001b[0mretain_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    220\u001b[0m                 create_graph=create_graph)\n\u001b[0;32m--> 221\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    222\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    223\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m    128\u001b[0m         \u001b[0mretain_graph\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 130\u001b[0;31m     Variable._execution_engine.run_backward(\n\u001b[0m\u001b[1;32m    131\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    132\u001b[0m         allow_unreachable=True)  # allow_unreachable flag\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "baseline_trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-05T16:35:27.908837Z",
     "iopub.status.busy": "2021-01-05T16:35:27.908413Z",
     "iopub.status.idle": "2021-01-05T16:35:37.556426Z",
     "shell.execute_reply": "2021-01-05T16:35:37.555013Z",
     "shell.execute_reply.started": "2021-01-05T16:35:27.908792Z"
    }
   },
   "outputs": [],
   "source": [
    "tokenizer = transformers.BertTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "model = transformers.BertModel.from_pretrained(\"bert-base-uncased\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-09T15:11:43.846188Z",
     "iopub.status.busy": "2021-01-09T15:11:43.845741Z",
     "iopub.status.idle": "2021-01-09T15:11:43.917117Z",
     "shell.execute_reply": "2021-01-09T15:11:43.915835Z",
     "shell.execute_reply.started": "2021-01-09T15:11:43.846141Z"
    }
   },
   "outputs": [],
   "source": [
    "args = transformers.TrainingArguments(\n",
    "    output_dir=\"./checkpoints\",\n",
    "    logging_dir=\"./runs\",\n",
    "    overwrite_output_dir=True,\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    learning_rate=2e-5,\n",
    "    num_train_epochs=3,\n",
    "    remove_unused_columns=False,\n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=64,\n",
    "    label_names=[\"answer_start\", \"answer_end\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-09T15:11:43.919760Z",
     "iopub.status.busy": "2021-01-09T15:11:43.919407Z",
     "iopub.status.idle": "2021-01-09T15:11:43.983226Z",
     "shell.execute_reply": "2021-01-09T15:11:43.982049Z",
     "shell.execute_reply.started": "2021-01-09T15:11:43.919720Z"
    }
   },
   "outputs": [],
   "source": [
    "class DataCollatorWithPadding:\n",
    "    \"\"\"\n",
    "    Data collator that will dynamically pad the inputs received\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, tokenizer, padding=True, max_lenght=None):\n",
    "        self.tokenizer = tokenizer\n",
    "        self.padding = True\n",
    "        self.max_length = None\n",
    "\n",
    "    def __call__(self, inputs):\n",
    "        (questions, contexts, _, _) = zip(*inputs)\n",
    "        tokenized = self.tokenizer(questions, contexts)\n",
    "        batch = self.tokenizer.pad(\n",
    "            tokenized,\n",
    "            padding=self.padding,\n",
    "            max_length=self.max_length,\n",
    "            return_tensors=\"pt\",\n",
    "        )\n",
    "        return batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-09T15:11:45.132472Z",
     "iopub.status.busy": "2021-01-09T15:11:45.132147Z",
     "iopub.status.idle": "2021-01-09T15:11:45.212777Z",
     "shell.execute_reply": "2021-01-09T15:11:45.210886Z",
     "shell.execute_reply.started": "2021-01-09T15:11:45.132429Z"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'tokenizer' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-60-a9a753d614d6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdata_collator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDataCollatorWithPadding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtokenizer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'tokenizer' is not defined"
     ]
    }
   ],
   "source": [
    "data_collator = DataCollatorWithPadding(tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-01-09T15:11:45.214014Z",
     "iopub.status.idle": "2021-01-09T15:11:45.214520Z"
    }
   },
   "outputs": [],
   "source": [
    "trainer = transformers.Trainer(\n",
    "    model=model,\n",
    "    args=args,\n",
    "    data_collator=data_collator,\n",
    "    train_dataset=squad_dataset.train_dataset,\n",
    "    eval_dataset=squad_dataset.val_dataset\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-05T16:37:10.984314Z",
     "iopub.status.busy": "2021-01-05T16:37:10.983997Z",
     "iopub.status.idle": "2021-01-05T16:37:23.456420Z",
     "shell.execute_reply": "2021-01-05T16:37:23.454650Z",
     "shell.execute_reply.started": "2021-01-05T16:37:10.984273Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['input_ids', 'token_type_ids', 'attention_mask'])\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'loss'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-288-3435b262f1ae>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/transformers/trainer.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, model_path, trial)\u001b[0m\n\u001b[1;32m    797\u001b[0m                         \u001b[0mtr_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    798\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 799\u001b[0;31m                     \u001b[0mtr_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    800\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_total_flos\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloating_point_ops\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    801\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/transformers/trainer.py\u001b[0m in \u001b[0;36mtraining_step\u001b[0;34m(self, model, inputs)\u001b[0m\n\u001b[1;32m   1137\u001b[0m                 \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1138\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1139\u001b[0;31m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1140\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1141\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_gpu\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/transformers/trainer.py\u001b[0m in \u001b[0;36mcompute_loss\u001b[0;34m(self, model, inputs)\u001b[0m\n\u001b[1;32m   1167\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_past\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpast_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1168\u001b[0m         \u001b[0;31m# We don't use .loss here since the model may return tuples instead of ModelOutput.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1169\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"loss\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1170\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1171\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mis_local_process_zero\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mbool\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/transformers/file_utils.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, k)\u001b[0m\n\u001b[1;32m   1443\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1444\u001b[0m             \u001b[0minner_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1445\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0minner_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1446\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1447\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_tuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'loss'"
     ]
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
