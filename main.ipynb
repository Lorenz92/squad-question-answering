{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SQuAD Q&A"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook contains training scripts for models to be used for the question answering problem on the SQuAD v1.1 dataset, which consists on selecting a possible answer to the given question as a span of words in the given context paragraph. The newest version (v2.0) of the dataset also contains unanswerable questions, but the one on which we worked on (v1.1) does not."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Colab requirements"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-18T15:12:30.609774Z",
     "iopub.status.busy": "2021-01-18T15:12:30.609319Z",
     "iopub.status.idle": "2021-01-18T15:12:30.701692Z"
    }
   },
   "source": [
    "Before restarting runtime (remember to select GPU runtime)$\\dots$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!git clone https://github.com/Wadaboa/squad-question-answering.git\n",
    "!pip install -r squad-question-answering/init/base_requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After restarting runtime$\\dots$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "\n",
    "sys.path.insert(0, \"squad-question-answering\")\n",
    "os.chdir(\"squad-question-answering\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to import source files, we have to add the `src` folder to the Python path$\\dots$ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-26T10:39:06.198196Z",
     "iopub.status.busy": "2021-01-26T10:39:06.197756Z",
     "iopub.status.idle": "2021-01-26T10:39:06.203324Z",
     "shell.execute_reply": "2021-01-26T10:39:06.202184Z",
     "shell.execute_reply.started": "2021-01-26T10:39:06.198150Z"
    }
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "sys.path.insert(0, \"src\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, we can import packages as usual$\\dots$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-26T10:39:07.972593Z",
     "iopub.status.busy": "2021-01-26T10:39:07.972254Z",
     "iopub.status.idle": "2021-01-26T10:39:09.230448Z",
     "shell.execute_reply": "2021-01-26T10:39:09.229169Z",
     "shell.execute_reply.started": "2021-01-26T10:39:07.972553Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from functools import partial\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import wandb\n",
    "import transformers\n",
    "from transformers.trainer_utils import set_seed\n",
    "\n",
    "import dataset\n",
    "import model\n",
    "import training\n",
    "import tokenizer\n",
    "import utils\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section we are going to perform some initialization stuff for all the libraries to be used throughout the notebook$\\dots$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Weights & biases"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training and evaluation metrics, along with model checkpoints and results, are directly logged into a [W&B](https://wandb.ai/) project, which is openly accessible [here](https://wandb.ai/wadaboa/squad-qa). Logging abilities are only granted to members of the team, so that if you want to launch your training run, you would have to disable wandb, by setting the environment variable `WANDB_DISABLED` to an empty value in the following block (`%env WANDB_DISABLED=`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-24T17:19:26.955252Z",
     "iopub.status.busy": "2021-01-24T17:19:26.954942Z",
     "iopub.status.idle": "2021-01-24T17:19:27.024560Z",
     "shell.execute_reply": "2021-01-24T17:19:27.023299Z",
     "shell.execute_reply.started": "2021-01-24T17:19:26.955215Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: WANDB_PROJECT=squad-qa\n",
      "env: WANDB_ENTITY=wadaboa\n",
      "env: WANDB_MODE=online\n",
      "env: WANDB_RESUME=never\n",
      "env: WANDB_WATCH=false\n",
      "env: WANDB_SILENT=true\n"
     ]
    }
   ],
   "source": [
    "%env WANDB_PROJECT=squad-qa\n",
    "%env WANDB_ENTITY=wadaboa\n",
    "%env WANDB_MODE=online\n",
    "%env WANDB_RESUME=never\n",
    "%env WANDB_WATCH=false\n",
    "%env WANDB_SILENT=true"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Be sure to be logged in: if the system prompts you to insert a key, head over to [W&B](https://wandb.ai/authorize), login and the key should appear on the web page$\\dots$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-24T17:19:29.550536Z",
     "iopub.status.busy": "2021-01-24T17:19:29.550147Z",
     "iopub.status.idle": "2021-01-24T17:19:31.670186Z",
     "shell.execute_reply": "2021-01-24T17:19:31.668397Z",
     "shell.execute_reply.started": "2021-01-24T17:19:29.550499Z"
    }
   },
   "outputs": [],
   "source": [
    "!wandb login"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-26T10:54:28.223155Z",
     "iopub.status.busy": "2021-01-26T10:54:28.222723Z",
     "iopub.status.idle": "2021-01-26T10:54:28.289198Z",
     "shell.execute_reply": "2021-01-26T10:54:28.287720Z",
     "shell.execute_reply.started": "2021-01-26T10:54:28.223110Z"
    }
   },
   "source": [
    "Be sure to have `wandb` enabled system-wise$\\dots$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-24T17:19:31.751590Z",
     "iopub.status.busy": "2021-01-24T17:19:31.751275Z",
     "iopub.status.idle": "2021-01-24T17:19:33.504344Z",
     "shell.execute_reply": "2021-01-24T17:19:33.502567Z",
     "shell.execute_reply.started": "2021-01-24T17:19:31.751553Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "W&B enabled.\n"
     ]
    }
   ],
   "source": [
    "!wandb enabled"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PyTorch and numpy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set the random seed to a fixed number for reproducible results$\\dots$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-26T10:40:35.012320Z",
     "iopub.status.busy": "2021-01-26T10:40:35.011873Z",
     "iopub.status.idle": "2021-01-26T10:40:35.079783Z",
     "shell.execute_reply": "2021-01-26T10:40:35.078528Z",
     "shell.execute_reply.started": "2021-01-26T10:40:35.012273Z"
    }
   },
   "outputs": [],
   "source": [
    "RANDOM_SEED = 42\n",
    "set_seed(RANDOM_SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get the fastest device (GPU if available, else CPU as a fallback) to be used for training neural models in `PyTorch`$\\dots$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-26T10:40:35.193754Z",
     "iopub.status.busy": "2021-01-26T10:40:35.193409Z",
     "iopub.status.idle": "2021-01-26T10:40:35.261642Z",
     "shell.execute_reply": "2021-01-26T10:40:35.260291Z",
     "shell.execute_reply.started": "2021-01-26T10:40:35.193711Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/anaconda3/lib/python3.8/site-packages/torch/cuda/__init__.py:52: UserWarning: CUDA initialization: Found no NVIDIA driver on your system. Please check that you have an NVIDIA GPU and installed a driver from http://www.nvidia.com/Download/index.aspx (Triggered internally at  /pytorch/c10/cuda/CUDAFunctions.cpp:100.)\n",
      "  return torch._C._cuda_getDeviceCount() > 0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DEVICE = utils.get_device()\n",
    "DEVICE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If a GPU device is available, print related info like GPU type, current usage$\\dots$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-26T10:40:35.330332Z",
     "iopub.status.busy": "2021-01-26T10:40:35.329927Z",
     "iopub.status.idle": "2021-01-26T10:40:35.387645Z",
     "shell.execute_reply": "2021-01-26T10:40:35.386500Z",
     "shell.execute_reply.started": "2021-01-26T10:40:35.330214Z"
    }
   },
   "outputs": [],
   "source": [
    "if DEVICE.type != \"cpu\":\n",
    "    !nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preliminaries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section we are going to perform some preliminary steps, like data loading and common variables definition$\\dots$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Raw data loading"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `SquadDataset` class holds a \"raw\" copy of the training set and the test set (if given). By \"raw\", we simply mean that questions and contexts are not pre-processed in this stage, but they are simply loaded from the given `JSON` files into appropriate `Pandas` `DataFrame`s."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-26T10:40:48.014270Z",
     "iopub.status.busy": "2021-01-26T10:40:48.013823Z",
     "iopub.status.idle": "2021-01-26T10:40:48.079821Z",
     "shell.execute_reply": "2021-01-26T10:40:48.078656Z",
     "shell.execute_reply.started": "2021-01-26T10:40:48.014208Z"
    }
   },
   "outputs": [],
   "source": [
    "DATA_FOLDER = os.path.join(os.getcwd(), \"data\")\n",
    "TRAIN_DATA_FOLDER = os.path.join(DATA_FOLDER, \"training\")\n",
    "TRAIN_SET_PATH = os.path.join(TRAIN_DATA_FOLDER, \"training_set.json\")\n",
    "TEST_DATA_FOLDER = os.path.join(DATA_FOLDER, \"testing\")\n",
    "TEST_SET_PATH = os.path.join(TEST_DATA_FOLDER, \"test_set.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remember that the `subset` variable is used to load a random subset of both the training and testing dataset. This is to be used only for debugging purposes, so that `subset` should be set to $1.0$ when performing real training runs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-26T10:40:49.234721Z",
     "iopub.status.busy": "2021-01-26T10:40:49.234370Z",
     "iopub.status.idle": "2021-01-26T10:40:49.497731Z",
     "shell.execute_reply": "2021-01-26T10:40:49.496410Z",
     "shell.execute_reply.started": "2021-01-26T10:40:49.234680Z"
    }
   },
   "outputs": [],
   "source": [
    "squad_dataset = dataset.SquadDataset(\n",
    "    train_set_path=TRAIN_SET_PATH, test_set_path=TEST_SET_PATH, subset=0.00005\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's visualize the \"raw\" training set$\\dots$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-26T10:40:50.377470Z",
     "iopub.status.busy": "2021-01-26T10:40:50.377029Z",
     "iopub.status.idle": "2021-01-26T10:40:50.460670Z",
     "shell.execute_reply": "2021-01-26T10:40:50.459572Z",
     "shell.execute_reply.started": "2021-01-26T10:40:50.377424Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>answer_start</th>\n",
       "      <th>answer</th>\n",
       "      <th>title</th>\n",
       "      <th>context</th>\n",
       "      <th>question_id</th>\n",
       "      <th>question</th>\n",
       "      <th>context_id</th>\n",
       "      <th>answer_end</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>167</td>\n",
       "      <td>1735</td>\n",
       "      <td>Institute_of_technology</td>\n",
       "      <td>The world's first institution of technology or...</td>\n",
       "      <td>56de4d9ecffd8e1900b4b7e2</td>\n",
       "      <td>What year was the Banská Akadémia founded?</td>\n",
       "      <td>1860</td>\n",
       "      <td>171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>793</td>\n",
       "      <td>SOS-based speed</td>\n",
       "      <td>Film_speed</td>\n",
       "      <td>The standard specifies how speed ratings shoul...</td>\n",
       "      <td>572674a05951b619008f7319</td>\n",
       "      <td>What is another speed that can also be reporte...</td>\n",
       "      <td>9354</td>\n",
       "      <td>808</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>421</td>\n",
       "      <td>Sumerian temples and palaces</td>\n",
       "      <td>Sumer</td>\n",
       "      <td>The most impressive and famous of Sumerian bui...</td>\n",
       "      <td>5730bb058ab72b1400f9c72c</td>\n",
       "      <td>Where were the use of advanced materials and t...</td>\n",
       "      <td>17505</td>\n",
       "      <td>449</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>192</td>\n",
       "      <td>mayor</td>\n",
       "      <td>Ann_Arbor,_Michigan</td>\n",
       "      <td>Ann Arbor has a council-manager form of govern...</td>\n",
       "      <td>572781a5f1498d1400e8fa1f</td>\n",
       "      <td>Who is elected every even numbered year?</td>\n",
       "      <td>10585</td>\n",
       "      <td>197</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   answer_start                        answer                    title  \\\n",
       "0           167                          1735  Institute_of_technology   \n",
       "1           793               SOS-based speed               Film_speed   \n",
       "2           421  Sumerian temples and palaces                    Sumer   \n",
       "3           192                         mayor      Ann_Arbor,_Michigan   \n",
       "\n",
       "                                             context  \\\n",
       "0  The world's first institution of technology or...   \n",
       "1  The standard specifies how speed ratings shoul...   \n",
       "2  The most impressive and famous of Sumerian bui...   \n",
       "3  Ann Arbor has a council-manager form of govern...   \n",
       "\n",
       "                question_id  \\\n",
       "0  56de4d9ecffd8e1900b4b7e2   \n",
       "1  572674a05951b619008f7319   \n",
       "2  5730bb058ab72b1400f9c72c   \n",
       "3  572781a5f1498d1400e8fa1f   \n",
       "\n",
       "                                            question  context_id  answer_end  \n",
       "0         What year was the Banská Akadémia founded?        1860         171  \n",
       "1  What is another speed that can also be reporte...        9354         808  \n",
       "2  Where were the use of advanced materials and t...       17505         449  \n",
       "3           Who is elected every even numbered year?       10585         197  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "squad_dataset.raw_train_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's visualize the \"raw\" test set$\\dots$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-24T17:19:35.681869Z",
     "iopub.status.busy": "2021-01-24T17:19:35.681557Z",
     "iopub.status.idle": "2021-01-24T17:19:35.745430Z",
     "shell.execute_reply": "2021-01-24T17:19:35.744394Z",
     "shell.execute_reply.started": "2021-01-24T17:19:35.681831Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>answer_start</th>\n",
       "      <th>answer</th>\n",
       "      <th>title</th>\n",
       "      <th>context</th>\n",
       "      <th>question_id</th>\n",
       "      <th>question</th>\n",
       "      <th>context_id</th>\n",
       "      <th>answer_end</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [answer_start, answer, title, context, question_id, question, context_id, answer_end]\n",
       "Index: []"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "squad_dataset.raw_test_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Utils"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This section contains common variables and functions to be used when training all the subsequent models$\\dots$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following cell is tasked to load the default training parameters, such as the batch size, the logging frequency, where model checkpoints should be saved and more$\\dots$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-24T17:27:54.895386Z",
     "iopub.status.busy": "2021-01-24T17:27:54.894937Z",
     "iopub.status.idle": "2021-01-24T17:27:54.960671Z",
     "shell.execute_reply": "2021-01-24T17:27:54.959522Z",
     "shell.execute_reply.started": "2021-01-24T17:27:54.895342Z"
    }
   },
   "outputs": [],
   "source": [
    "TRAINER_ARGS = utils.get_default_trainer_args()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recurrent models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This section contains blocks of code that are used to train question answering models, which are based on recurrent modules (`LSTM`s in our case). The models that we implemented are the following:\n",
    "- Baseline\n",
    "- BiDAF (Bi-Directional Attention Flow)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section we are going to load an embedding matrix using the `Gensim` API and use the corresponding matrix as the weight block of an `nn.Embedding` `PyTorch` module$\\dots$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First of all, we have to define one token for padding values. Then, OOV words are handled by a single unknown token, which is estimated as the mean of all the embedding vectors (if this mean vector is already present in the model, then a random embedding with suitable ranges is computed)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-24T14:12:19.839930Z",
     "iopub.status.busy": "2021-01-24T14:12:19.839508Z",
     "iopub.status.idle": "2021-01-24T14:12:19.903664Z",
     "shell.execute_reply": "2021-01-24T14:12:19.902424Z",
     "shell.execute_reply.started": "2021-01-24T14:12:19.839885Z"
    }
   },
   "outputs": [],
   "source": [
    "UNK_TOKEN = \"[UNK]\"\n",
    "PAD_TOKEN = \"[PAD]\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "List of available embedding models (see [here](https://github.com/RaRe-Technologies/gensim-data)):\n",
    "- FastText: \n",
    "    - _fasttext-wiki-news-subwords_ (dimensions: 300)\n",
    "- GloVe:\n",
    "    - _glove-twitter_ (dimensions: 25. 50, 100, 200)\n",
    "    - _glove-wiki-gigaword_ (dimensions: 50, 100, 200, 300)\n",
    "- Word2Vec:\n",
    "    - _word2vec-google-news_ (dimensions: 300)\n",
    "    - _word2vec-ruscorpora_ (dimensions: 300)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note**: The following cell could take a while (depending on the embedding dimension), since embedding models are pretty large$\\dots$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-24T14:12:20.103853Z",
     "iopub.status.busy": "2021-01-24T14:12:20.103539Z",
     "iopub.status.idle": "2021-01-24T14:13:53.857469Z",
     "shell.execute_reply": "2021-01-24T14:13:53.855954Z",
     "shell.execute_reply.started": "2021-01-24T14:12:20.103815Z"
    }
   },
   "outputs": [],
   "source": [
    "EMBEDDING_DIMENSION = 25\n",
    "EMBEDDING_MODEL_NAME = \"glove-twitter\"\n",
    "embedding_model, vocab = utils.load_embedding_model(\n",
    "    EMBEDDING_MODEL_NAME,\n",
    "    embedding_dimension=EMBEDDING_DIMENSION,\n",
    "    unk_token=UNK_TOKEN,\n",
    "    pad_token=PAD_TOKEN,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following cell is tasked to load the embedding model into a `PyTorch` `nn.Embedding` layer, with freezed weights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-24T14:13:55.754045Z",
     "iopub.status.busy": "2021-01-24T14:13:55.753702Z",
     "iopub.status.idle": "2021-01-24T14:13:57.104246Z",
     "shell.execute_reply": "2021-01-24T14:13:57.102800Z",
     "shell.execute_reply.started": "2021-01-24T14:13:55.754003Z"
    }
   },
   "outputs": [],
   "source": [
    "embedding_layer = model.get_embedding_module(embedding_model, pad_id=vocab[PAD_TOKEN])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data loading"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `SquadDataManager` class acts as both a data collator (i.e. bringing together multiple examples in the dataset with the help of `PyTorch`'s `DataLoader`s) and a tokenizer. In particular, tokenization happens on the fly at the batch level, thus enabling us to perform dynamic padding (based on the longest sequence in a batch) and avoiding the pre-tokenization overhead."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The tokenizer that we are using for recurrent modules splits words by whitespaces and punctuations, removes accents and applies a lowercasing function to all the tokens. Moreover, questions are padded (not truncated), while contexts are truncated to a maximum number of tokens and padded."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-24T14:29:31.956770Z",
     "iopub.status.busy": "2021-01-24T14:29:31.956414Z",
     "iopub.status.idle": "2021-01-24T14:29:32.051325Z",
     "shell.execute_reply": "2021-01-24T14:29:32.049565Z",
     "shell.execute_reply.started": "2021-01-24T14:29:31.956725Z"
    }
   },
   "outputs": [],
   "source": [
    "MAX_CONTEXT_TOKENS = 300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-24T14:29:33.984498Z",
     "iopub.status.busy": "2021-01-24T14:29:33.984162Z",
     "iopub.status.idle": "2021-01-24T14:29:37.771714Z",
     "shell.execute_reply": "2021-01-24T14:29:37.769812Z",
     "shell.execute_reply.started": "2021-01-24T14:29:33.984454Z"
    }
   },
   "outputs": [],
   "source": [
    "recurrent_tokenizer = tokenizer.get_recurrent_tokenizer(\n",
    "    vocab, MAX_CONTEXT_TOKENS, unk_token=UNK_TOKEN, pad_token=PAD_TOKEN, device=DEVICE,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `SquadDataManager` class also acts as a pre-processor, with the following steps:\n",
    "- Removes rows that contain wrong answers (e.g. answers that do not start and end at word boundaries)\n",
    "- Removes rows that contain answers that would be lost due to tokenization (truncation in particular)\n",
    "- Groups answers to the same question and context pair into a single row (thus producing lists in the `answer`, `answer_start` and `answer_end` columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-24T14:30:52.264624Z",
     "iopub.status.busy": "2021-01-24T14:30:52.264282Z",
     "iopub.status.idle": "2021-01-24T14:30:52.417062Z",
     "shell.execute_reply": "2021-01-24T14:30:52.415804Z",
     "shell.execute_reply.started": "2021-01-24T14:30:52.264581Z"
    }
   },
   "outputs": [],
   "source": [
    "recurrent_dm = dataset.SquadDataManager(\n",
    "    squad_dataset, recurrent_tokenizer, device=DEVICE\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The last task assigned to the `SquadDataManager` class is that of train/validation splitting, with the given ratio ($80\\%$ for the training set by default)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's have a look at the final training dataset$\\dots$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-24T14:30:54.309129Z",
     "iopub.status.busy": "2021-01-24T14:30:54.308807Z",
     "iopub.status.idle": "2021-01-24T14:30:54.402504Z",
     "shell.execute_reply": "2021-01-24T14:30:54.401223Z",
     "shell.execute_reply.started": "2021-01-24T14:30:54.309087Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question_id</th>\n",
       "      <th>question</th>\n",
       "      <th>title</th>\n",
       "      <th>context_id</th>\n",
       "      <th>context</th>\n",
       "      <th>answer</th>\n",
       "      <th>answer_start</th>\n",
       "      <th>answer_end</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>56de4d9ecffd8e1900b4b7e2</td>\n",
       "      <td>What year was the Banská Akadémia founded?</td>\n",
       "      <td>Institute_of_technology</td>\n",
       "      <td>1860</td>\n",
       "      <td>The world's first institution of technology or...</td>\n",
       "      <td>[1735]</td>\n",
       "      <td>[167]</td>\n",
       "      <td>[171]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>572781a5f1498d1400e8fa1f</td>\n",
       "      <td>Who is elected every even numbered year?</td>\n",
       "      <td>Ann_Arbor,_Michigan</td>\n",
       "      <td>10585</td>\n",
       "      <td>Ann Arbor has a council-manager form of govern...</td>\n",
       "      <td>[mayor]</td>\n",
       "      <td>[192]</td>\n",
       "      <td>[197]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5730bb058ab72b1400f9c72c</td>\n",
       "      <td>Where were the use of advanced materials and t...</td>\n",
       "      <td>Sumer</td>\n",
       "      <td>17505</td>\n",
       "      <td>The most impressive and famous of Sumerian bui...</td>\n",
       "      <td>[Sumerian temples and palaces]</td>\n",
       "      <td>[421]</td>\n",
       "      <td>[449]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                question_id  \\\n",
       "0  56de4d9ecffd8e1900b4b7e2   \n",
       "1  572781a5f1498d1400e8fa1f   \n",
       "2  5730bb058ab72b1400f9c72c   \n",
       "\n",
       "                                            question                    title  \\\n",
       "0         What year was the Banská Akadémia founded?  Institute_of_technology   \n",
       "1           Who is elected every even numbered year?      Ann_Arbor,_Michigan   \n",
       "2  Where were the use of advanced materials and t...                    Sumer   \n",
       "\n",
       "   context_id                                            context  \\\n",
       "0        1860  The world's first institution of technology or...   \n",
       "1       10585  Ann Arbor has a council-manager form of govern...   \n",
       "2       17505  The most impressive and famous of Sumerian bui...   \n",
       "\n",
       "                           answer answer_start answer_end  \n",
       "0                          [1735]        [167]      [171]  \n",
       "1                         [mayor]        [192]      [197]  \n",
       "2  [Sumerian temples and palaces]        [421]      [449]  "
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recurrent_dm.train_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's have a look at the final validation dataset$\\dots$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-24T14:30:56.265144Z",
     "iopub.status.busy": "2021-01-24T14:30:56.264818Z",
     "iopub.status.idle": "2021-01-24T14:30:56.349907Z",
     "shell.execute_reply": "2021-01-24T14:30:56.348553Z",
     "shell.execute_reply.started": "2021-01-24T14:30:56.265102Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question_id</th>\n",
       "      <th>question</th>\n",
       "      <th>title</th>\n",
       "      <th>context_id</th>\n",
       "      <th>context</th>\n",
       "      <th>answer</th>\n",
       "      <th>answer_start</th>\n",
       "      <th>answer_end</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>572674a05951b619008f7319</td>\n",
       "      <td>What is another speed that can also be reporte...</td>\n",
       "      <td>Film_speed</td>\n",
       "      <td>9354</td>\n",
       "      <td>The standard specifies how speed ratings shoul...</td>\n",
       "      <td>[SOS-based speed]</td>\n",
       "      <td>[793]</td>\n",
       "      <td>[808]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                question_id  \\\n",
       "0  572674a05951b619008f7319   \n",
       "\n",
       "                                            question       title  context_id  \\\n",
       "0  What is another speed that can also be reporte...  Film_speed        9354   \n",
       "\n",
       "                                             context             answer  \\\n",
       "0  The standard specifies how speed ratings shoul...  [SOS-based speed]   \n",
       "\n",
       "  answer_start answer_end  \n",
       "0        [793]      [808]  "
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recurrent_dm.val_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And let's do the same for the testing dataset$\\dots$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-24T14:30:58.211732Z",
     "iopub.status.busy": "2021-01-24T14:30:58.211407Z",
     "iopub.status.idle": "2021-01-24T14:30:58.287197Z",
     "shell.execute_reply": "2021-01-24T14:30:58.285658Z",
     "shell.execute_reply.started": "2021-01-24T14:30:58.211690Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>answer</th>\n",
       "      <th>answer_start</th>\n",
       "      <th>answer_end</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [index, answer, answer_start, answer_end]\n",
       "Index: []"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recurrent_dm.test_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Baseline model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-24T15:01:59.464500Z",
     "iopub.status.busy": "2021-01-24T15:01:59.464022Z",
     "iopub.status.idle": "2021-01-24T15:01:59.559181Z",
     "shell.execute_reply": "2021-01-24T15:01:59.558066Z",
     "shell.execute_reply.started": "2021-01-24T15:01:59.464453Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: WANDB_RUN_GROUP=baseline\n"
     ]
    }
   ],
   "source": [
    "%env WANDB_RUN_GROUP=baseline\n",
    "baseline_run_name = utils.get_run_name()\n",
    "baseline_args = partial(\n",
    "    TRAINER_ARGS,\n",
    "    output_dir=f\"./checkpoints/{os.getenv('WANDB_RUN_GROUP')}/{baseline_run_name}\",\n",
    "    num_train_epochs=30,\n",
    "    per_device_train_batch_size=128,\n",
    "    per_device_eval_batch_size=128,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training and validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-24T15:27:07.544196Z",
     "iopub.status.busy": "2021-01-24T15:27:07.543743Z",
     "iopub.status.idle": "2021-01-24T15:27:07.624540Z",
     "shell.execute_reply": "2021-01-24T15:27:07.623338Z",
     "shell.execute_reply.started": "2021-01-24T15:27:07.544143Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The baseline model has 245202 parameters\n"
     ]
    }
   ],
   "source": [
    "baseline_model = model.QABaselineModel(\n",
    "    embedding_layer, MAX_CONTEXT_TOKENS, device=DEVICE\n",
    ")\n",
    "print(f\"The baseline model has {baseline_model.count_parameters()} parameters\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-24T15:27:09.548831Z",
     "iopub.status.busy": "2021-01-24T15:27:09.548448Z",
     "iopub.status.idle": "2021-01-24T15:27:09.642479Z",
     "shell.execute_reply": "2021-01-24T15:27:09.641404Z",
     "shell.execute_reply.started": "2021-01-24T15:27:09.548789Z"
    }
   },
   "outputs": [],
   "source": [
    "baseline_optimizer = optim.Adam(baseline_model.parameters(), lr=1e-3)\n",
    "baseline_lr_scheduler = transformers.get_constant_schedule(baseline_optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-24T15:27:09.645648Z",
     "iopub.status.busy": "2021-01-24T15:27:09.645328Z",
     "iopub.status.idle": "2021-01-24T15:27:09.718856Z",
     "shell.execute_reply": "2021-01-24T15:27:09.717721Z",
     "shell.execute_reply.started": "2021-01-24T15:27:09.645608Z"
    }
   },
   "outputs": [],
   "source": [
    "baseline_trainer = training.SquadTrainer(\n",
    "    model=baseline_model,\n",
    "    args=baseline_args(run_name=baseline_run_name),\n",
    "    data_collator=recurrent_dm.tokenizer,\n",
    "    train_dataset=recurrent_dm.train_dataset,\n",
    "    eval_dataset=recurrent_dm.val_dataset,\n",
    "    optimizers=(baseline_optimizer, baseline_lr_scheduler),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-24T15:27:09.720844Z",
     "iopub.status.busy": "2021-01-24T15:27:09.720536Z",
     "iopub.status.idle": "2021-01-24T15:27:21.085916Z",
     "shell.execute_reply": "2021-01-24T15:27:21.083897Z",
     "shell.execute_reply.started": "2021-01-24T15:27:09.720805Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 172, 100]) torch.Size([3, 172, 100]) torch.Size([3, 100])\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "        </style>\n",
       "      \n",
       "      <progress value='8' max='30' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [ 8/30 00:04 < 00:16, 1.33 it/s, Epoch 7/30]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "      <th>Em</th>\n",
       "      <th>Runtime</th>\n",
       "      <th>Samples Per Second</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>6.015200</td>\n",
       "      <td>7.586694</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.118400</td>\n",
       "      <td>8.444000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>6.015200</td>\n",
       "      <td>7.584815</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.119000</td>\n",
       "      <td>8.400000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>6.015200</td>\n",
       "      <td>7.581810</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.109200</td>\n",
       "      <td>9.161000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>6.015200</td>\n",
       "      <td>7.576920</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.108900</td>\n",
       "      <td>9.184000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>7.369100</td>\n",
       "      <td>7.570308</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.108400</td>\n",
       "      <td>9.223000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>7.369100</td>\n",
       "      <td>7.560383</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.111200</td>\n",
       "      <td>8.989000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>7.369100</td>\n",
       "      <td>7.546800</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.111800</td>\n",
       "      <td>8.941000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 194, 100]) torch.Size([1, 194, 100]) torch.Size([1, 100])\n",
      "torch.Size([3, 172, 100]) torch.Size([3, 172, 100]) torch.Size([3, 100])\n",
      "torch.Size([1, 194, 100]) torch.Size([1, 194, 100]) torch.Size([1, 100])\n",
      "torch.Size([3, 172, 100]) torch.Size([3, 172, 100]) torch.Size([3, 100])\n",
      "torch.Size([1, 194, 100]) torch.Size([1, 194, 100]) torch.Size([1, 100])\n",
      "torch.Size([3, 172, 100]) torch.Size([3, 172, 100]) torch.Size([3, 100])\n",
      "torch.Size([1, 194, 100]) torch.Size([1, 194, 100]) torch.Size([1, 100])\n",
      "torch.Size([3, 172, 100]) torch.Size([3, 172, 100]) torch.Size([3, 100])\n",
      "torch.Size([1, 194, 100]) torch.Size([1, 194, 100]) torch.Size([1, 100])\n",
      "torch.Size([3, 172, 100]) torch.Size([3, 172, 100]) torch.Size([3, 100])\n",
      "torch.Size([1, 194, 100]) torch.Size([1, 194, 100]) torch.Size([1, 100])\n",
      "torch.Size([3, 172, 100]) torch.Size([3, 172, 100]) torch.Size([3, 100])\n",
      "torch.Size([1, 194, 100]) torch.Size([1, 194, 100]) torch.Size([1, 100])\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-90-a28822d33159>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mbaseline_trainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/transformers/trainer.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, model_path, trial)\u001b[0m\n\u001b[1;32m    886\u001b[0m                         \u001b[0mtr_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    887\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 888\u001b[0;31m                     \u001b[0mtr_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    889\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_total_flos\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloating_point_ops\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    890\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/transformers/trainer.py\u001b[0m in \u001b[0;36mtraining_step\u001b[0;34m(self, model, inputs)\u001b[0m\n\u001b[1;32m   1248\u001b[0m                 \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1249\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1250\u001b[0;31m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1251\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1252\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_gpu\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/jupyter/squad-question-answering/training.py\u001b[0m in \u001b[0;36mcompute_loss\u001b[0;34m(self, model, inputs)\u001b[0m\n\u001b[1;32m     39\u001b[0m         \u001b[0mduring\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m         \"\"\"\n\u001b[0;32m---> 41\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     42\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0;31m# Custom logging steps (to log training metrics)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/jupyter/squad-question-answering/model.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, **inputs)\u001b[0m\n\u001b[1;32m    267\u001b[0m             \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadded_contexts\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    268\u001b[0m         )\n\u001b[0;32m--> 269\u001b[0;31m         \u001b[0mend_input\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mout_lstm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstart_input\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"context_lenghts\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    270\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    271\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstart_input\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend_input\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maverage_questions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/jupyter/squad-question-answering/model.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, lenghts)\u001b[0m\n\u001b[1;32m     87\u001b[0m             \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlenghts\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_first\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlstm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_first\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0menforce_sorted\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m         )\n\u001b[0;32m---> 89\u001b[0;31m         \u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhidden\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcell\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlstm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpacked_inputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     90\u001b[0m         padded_outputs, padded_output_lenghts = pad_packed_sequence(\n\u001b[1;32m     91\u001b[0m             \u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_first\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlstm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_first\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/torch/nn/modules/rnn.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, hx)\u001b[0m\n\u001b[1;32m    582\u001b[0m                               self.dropout, self.training, self.bidirectional, self.batch_first)\n\u001b[1;32m    583\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 584\u001b[0;31m             result = _VF.lstm(input, batch_sizes, hx, self._flat_weights, self.bias,\n\u001b[0m\u001b[1;32m    585\u001b[0m                               self.num_layers, self.dropout, self.training, self.bidirectional)\n\u001b[1;32m    586\u001b[0m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "baseline_trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-24T09:58:34.597944Z",
     "iopub.status.busy": "2021-01-24T09:58:34.597582Z",
     "iopub.status.idle": "2021-01-24T09:58:34.676414Z",
     "shell.execute_reply": "2021-01-24T09:58:34.675144Z",
     "shell.execute_reply.started": "2021-01-24T09:58:34.597901Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The baseline model has 41000 parameters\n"
     ]
    }
   ],
   "source": [
    "baseline_model = model.QABaselineModel(\n",
    "    embedding_layer, MAX_CONTEXT_TOKENS, device=DEVICE\n",
    ")\n",
    "print(f\"The baseline model has {baseline_model.count_parameters()} parameters\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline_optimizer = optim.Adam(baseline_model.parameters(), lr=1e-3)\n",
    "baseline_lr_scheduler = transformers.get_constant_schedule(baseline_optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-24T09:58:36.906188Z",
     "iopub.status.busy": "2021-01-24T09:58:36.905856Z",
     "iopub.status.idle": "2021-01-24T09:58:36.988918Z",
     "shell.execute_reply": "2021-01-24T09:58:36.987625Z",
     "shell.execute_reply.started": "2021-01-24T09:58:36.906146Z"
    }
   },
   "outputs": [],
   "source": [
    "baseline_trainer = training.SquadTrainer(\n",
    "    model=baseline_model,\n",
    "    args=baseline_args(run_name=f\"{baseline_run_name}-whole\", evaluation_strategy=\"no\"),\n",
    "    data_collator=recurrent_dm.tokenizer,\n",
    "    train_dataset=recurrent_dm.whole_dataset,\n",
    "    optimizers=(baseline_optimizer, baseline_lr_scheduler),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-24T09:58:39.273472Z",
     "iopub.status.busy": "2021-01-24T09:58:39.273136Z",
     "iopub.status.idle": "2021-01-24T09:59:58.619170Z",
     "shell.execute_reply": "2021-01-24T09:59:58.617543Z",
     "shell.execute_reply.started": "2021-01-24T09:58:39.273430Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "        </style>\n",
       "      \n",
       "      <progress value='35' max='35' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [35/35 01:11, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>5.984300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>6.331100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>6.195200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>6.259200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>6.214700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>6.151500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>6.280500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>35</td>\n",
       "      <td>6.277100</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=35, training_loss=6.234272003173828, metrics={'train_runtime': 79.2375, 'train_samples_per_second': 0.442, 'total_flos': 0, 'epoch': 5.0})"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "baseline_trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-24T10:04:44.938352Z",
     "iopub.status.busy": "2021-01-24T10:04:44.937884Z",
     "iopub.status.idle": "2021-01-24T10:04:46.894165Z",
     "shell.execute_reply": "2021-01-24T10:04:46.892891Z",
     "shell.execute_reply.started": "2021-01-24T10:04:44.938307Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "        </style>\n",
       "      \n",
       "      <progress value='2' max='2' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2/2 00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'test_loss': 6.0533928871154785,\n",
       " 'test_accuracy': 0.048774934275635486,\n",
       " 'test_precision': 0.04997091627749208,\n",
       " 'test_recall': 0.539648141845944,\n",
       " 'test_f1': 0.08496900937695989,\n",
       " 'test_em': 0.0,\n",
       " 'test_runtime': 1.8771,\n",
       " 'test_samples_per_second': 96.959}"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "baseline_test_output = baseline_trainer.predict(recurrent_dm.test_dataset)\n",
    "baseline_test_output.metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-24T10:04:58.240993Z",
     "iopub.status.busy": "2021-01-24T10:04:58.240640Z",
     "iopub.status.idle": "2021-01-24T10:05:16.055426Z",
     "shell.execute_reply": "2021-01-24T10:05:16.053922Z",
     "shell.execute_reply.started": "2021-01-24T10:04:58.240950Z"
    }
   },
   "outputs": [],
   "source": [
    "baseline_answers_path = \"results/answers/baseline.json\"\n",
    "utils.save_answers(baseline_answers_path, baseline_test_output.predictions[-1])\n",
    "wandb.save(baseline_answers_path);\n",
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BiDAF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-26T11:52:15.838690Z",
     "iopub.status.busy": "2021-01-26T11:52:15.838204Z",
     "iopub.status.idle": "2021-01-26T11:52:15.905398Z",
     "shell.execute_reply": "2021-01-26T11:52:15.903846Z",
     "shell.execute_reply.started": "2021-01-26T11:52:15.838644Z"
    }
   },
   "source": [
    "> The Bi-Directional Attention Flow (BIDAF) network is a hierarchical\n",
    "multi-stage architecture for modeling the representations of the context paragraph at different levels\n",
    "of granularity. BIDAF includes character-level, word-level, and contextual embeddings,\n",
    "and uses bi-directional attention flow to obtain a query-aware context representation.\n",
    "Our attention mechanism offers following improvements to the previously popular attention paradigms. \n",
    "First, the attention layer is not used to summarize the context paragraph into a fixed-size vector. Instead, the\n",
    "attention is computed for every time step, and the attended vector at each time step, along with the\n",
    "representations from previous layers, is allowed to flow through to the subsequent modeling layer.\n",
    "This reduces the information loss caused by early summarization. Second, we use a memory-less\n",
    "attention mechanism. That is, while we iteratively compute attention through time, the attention at each time step is a function of only the query and the context paragraph at the current time step and does not directly depend on the attention at the previous time step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-24T14:31:09.693611Z",
     "iopub.status.busy": "2021-01-24T14:31:09.693249Z",
     "iopub.status.idle": "2021-01-24T14:31:09.785595Z",
     "shell.execute_reply": "2021-01-24T14:31:09.784353Z",
     "shell.execute_reply.started": "2021-01-24T14:31:09.693567Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: WANDB_RUN_GROUP=bidaf\n"
     ]
    }
   ],
   "source": [
    "%env WANDB_RUN_GROUP=bidaf\n",
    "bidaf_run_name = utils.get_run_name()\n",
    "bidaf_args = partial(\n",
    "    TRAINER_ARGS,\n",
    "    output_dir=f\"./checkpoints/{os.getenv('WANDB_RUN_GROUP')}/{bidaf_run_name}\",\n",
    "    num_train_epochs=18,\n",
    "    per_device_train_batch_size=60,\n",
    "    per_device_eval_batch_size=60,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training and validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-24T14:31:11.816561Z",
     "iopub.status.busy": "2021-01-24T14:31:11.816231Z",
     "iopub.status.idle": "2021-01-24T14:31:11.940213Z",
     "shell.execute_reply": "2021-01-24T14:31:11.938956Z",
     "shell.execute_reply.started": "2021-01-24T14:31:11.816520Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The BiDAF model has 2052700 parameters\n"
     ]
    }
   ],
   "source": [
    "bidaf_model = model.QABiDAFModel(embedding_layer, device=DEVICE)\n",
    "print(f\"The BiDAF model has {bidaf_model.count_parameters()} parameters\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-24T14:31:14.109815Z",
     "iopub.status.busy": "2021-01-24T14:31:14.109485Z",
     "iopub.status.idle": "2021-01-24T14:31:14.179729Z",
     "shell.execute_reply": "2021-01-24T14:31:14.178558Z",
     "shell.execute_reply.started": "2021-01-24T14:31:14.109772Z"
    }
   },
   "outputs": [],
   "source": [
    "bidaf_optimizer = optim.Adadelta(bidaf_model.parameters(), lr=0.5)\n",
    "bidaf_lr_scheduler = transformers.get_constant_schedule(bidaf_optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-24T14:31:16.104244Z",
     "iopub.status.busy": "2021-01-24T14:31:16.103907Z",
     "iopub.status.idle": "2021-01-24T14:31:16.187474Z",
     "shell.execute_reply": "2021-01-24T14:31:16.186315Z",
     "shell.execute_reply.started": "2021-01-24T14:31:16.104201Z"
    }
   },
   "outputs": [],
   "source": [
    "bidaf_trainer = training.SquadTrainer(\n",
    "    model=bidaf_model,\n",
    "    args=bidaf_args(run_name=bidaf_run_name),\n",
    "    data_collator=recurrent_dm.tokenizer,\n",
    "    train_dataset=recurrent_dm.train_dataset,\n",
    "    eval_dataset=recurrent_dm.val_dataset,\n",
    "    optimizers=(bidaf_optimizer, bidaf_lr_scheduler),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-24T14:31:16.189751Z",
     "iopub.status.busy": "2021-01-24T14:31:16.189429Z",
     "iopub.status.idle": "2021-01-24T14:31:26.097175Z",
     "shell.execute_reply": "2021-01-24T14:31:26.094953Z",
     "shell.execute_reply.started": "2021-01-24T14:31:16.189712Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 172, 100])\n",
      "torch.Size([3, 172, 200])\n",
      "torch.Size([3, 172, 14]) torch.Size([3, 14])\n",
      "torch.Size([3, 172, 200]) torch.Size([3, 172, 1]) torch.Size([3, 172])\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "        </style>\n",
       "      \n",
       "      <progress value='3' max='18' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [ 3/18 00:02 < 00:30, 0.49 it/s, Epoch 2/18]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "      <th>Em</th>\n",
       "      <th>Runtime</th>\n",
       "      <th>Samples Per Second</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>6.141500</td>\n",
       "      <td>7.783813</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.281600</td>\n",
       "      <td>3.551000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 194, 100])\n",
      "torch.Size([1, 194, 200])\n",
      "torch.Size([1, 194, 13]) torch.Size([1, 13])\n",
      "torch.Size([1, 194, 200]) torch.Size([1, 194, 1]) torch.Size([1, 194])\n",
      "torch.Size([3, 172, 100])\n",
      "torch.Size([3, 172, 200])\n",
      "torch.Size([3, 172, 14]) torch.Size([3, 14])\n",
      "torch.Size([3, 172, 200]) torch.Size([3, 172, 1]) torch.Size([3, 172])\n",
      "torch.Size([1, 194, 100])\n",
      "torch.Size([1, 194, 200])\n",
      "torch.Size([1, 194, 13]) torch.Size([1, 13])\n",
      "torch.Size([1, 194, 200]) torch.Size([1, 194, 1]) torch.Size([1, 194])\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-50-aca95db80ac7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mbidaf_trainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/transformers/trainer.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, model_path, trial)\u001b[0m\n\u001b[1;32m    933\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    934\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrol\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallback_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_epoch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrol\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 935\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_log_save_evaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtr_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrial\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    936\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    937\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtpu_metrics_debug\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdebug\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/transformers/trainer.py\u001b[0m in \u001b[0;36m_maybe_log_save_evaluate\u001b[0;34m(self, tr_loss, model, trial, epoch)\u001b[0m\n\u001b[1;32m   1002\u001b[0m         \u001b[0mmetrics\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1003\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrol\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_evaluate\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1004\u001b[0;31m             \u001b[0mmetrics\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1005\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_report_to_hp_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1006\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/transformers/trainer.py\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(self, eval_dataset, ignore_keys, metric_key_prefix)\u001b[0m\n\u001b[1;32m   1440\u001b[0m         \u001b[0mstart_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1441\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1442\u001b[0;31m         output = self.prediction_loop(\n\u001b[0m\u001b[1;32m   1443\u001b[0m             \u001b[0meval_dataloader\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1444\u001b[0m             \u001b[0mdescription\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"Evaluation\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/transformers/trainer.py\u001b[0m in \u001b[0;36mprediction_loop\u001b[0;34m(self, dataloader, description, prediction_loss_only, ignore_keys, metric_key_prefix)\u001b[0m\n\u001b[1;32m   1564\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1565\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataloader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1566\u001b[0;31m             \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogits\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprediction_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprediction_loss_only\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mignore_keys\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mignore_keys\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1567\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mloss\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1568\u001b[0m                 \u001b[0mlosses\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrepeat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/transformers/trainer.py\u001b[0m in \u001b[0;36mprediction_step\u001b[0;34m(self, model, inputs, prediction_loss_only, ignore_keys)\u001b[0m\n\u001b[1;32m   1670\u001b[0m                     \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1671\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1672\u001b[0;31m                 \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1673\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhas_labels\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1674\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlabel_smoother\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m\"labels\"\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/jupyter/squad-question-answering/model.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, **inputs)\u001b[0m\n\u001b[1;32m    503\u001b[0m         )\n\u001b[1;32m    504\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 505\u001b[0;31m         \u001b[0mmodeling\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodeling_layer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquery_aware_contexts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontexts_lenght\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    506\u001b[0m         \u001b[0mm2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mout_lstm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodeling\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontexts_lenght\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    507\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/jupyter/squad-question-answering/model.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, lenghts)\u001b[0m\n\u001b[1;32m     87\u001b[0m             \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlenghts\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_first\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlstm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_first\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0menforce_sorted\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m         )\n\u001b[0;32m---> 89\u001b[0;31m         \u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhidden\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcell\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlstm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpacked_inputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     90\u001b[0m         padded_outputs, padded_output_lenghts = pad_packed_sequence(\n\u001b[1;32m     91\u001b[0m             \u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_first\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlstm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_first\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/torch/nn/modules/rnn.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, hx)\u001b[0m\n\u001b[1;32m    582\u001b[0m                               self.dropout, self.training, self.bidirectional, self.batch_first)\n\u001b[1;32m    583\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 584\u001b[0;31m             result = _VF.lstm(input, batch_sizes, hx, self._flat_weights, self.bias,\n\u001b[0m\u001b[1;32m    585\u001b[0m                               self.num_layers, self.dropout, self.training, self.bidirectional)\n\u001b[1;32m    586\u001b[0m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "bidaf_trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bidaf_model = model.QABiDAFModel(embedding_layer, device=DEVICE)\n",
    "print(f\"The BiDAF model has {bidaf_model.count_parameters()} parameters\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bidaf_optimizer = optim.Adadelta(bidaf_model.parameters(), lr=0.5)\n",
    "bidaf_lr_scheduler = transformers.get_constant_schedule(bidaf_optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bidaf_trainer = training.SquadTrainer(\n",
    "    model=bidaf_model,\n",
    "    args=bidaf_args(run_name=f\"{bidaf_run_name}-whole\", evaluation_strategy=\"no\"),\n",
    "    data_collator=recurrent_dm.tokenizer,\n",
    "    train_dataset=recurrent_dm.whole_dataset,\n",
    "    optimizers=(bidaf_optimizer, bidaf_lr_scheduler),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bidaf_trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-21T18:02:35.254192Z",
     "iopub.status.busy": "2021-01-21T18:02:35.253869Z",
     "iopub.status.idle": "2021-01-21T18:02:35.599943Z",
     "shell.execute_reply": "2021-01-21T18:02:35.598889Z",
     "shell.execute_reply.started": "2021-01-21T18:02:35.254152Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "        </style>\n",
       "      \n",
       "      <progress value='1' max='1' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1/1 : < :]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'test_loss': 8.894977569580078,\n",
       " 'test_f1': 0.0,\n",
       " 'test_accuracy': 0.0,\n",
       " 'test_em': 0.0,\n",
       " 'test_runtime': 0.2739,\n",
       " 'test_samples_per_second': 3.651}"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bidaf_test_output = bidaf_trainer.predict(recurrent_dm.test_dataset)\n",
    "bidaf_test_output.metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-21T18:02:35.601859Z",
     "iopub.status.busy": "2021-01-21T18:02:35.601360Z",
     "iopub.status.idle": "2021-01-21T18:02:44.909008Z",
     "shell.execute_reply": "2021-01-21T18:02:44.907592Z",
     "shell.execute_reply.started": "2021-01-21T18:02:35.601819Z"
    }
   },
   "outputs": [],
   "source": [
    "bidaf_answers_path = \"results/answers/bidaf.json\"\n",
    "utils.save_answers(bidaf_answers_path, bidaf_test_output.predictions[-1])\n",
    "wandb.save(bidaf_answers_path);\n",
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transformer networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-24T17:19:48.838503Z",
     "iopub.status.busy": "2021-01-24T17:19:48.838039Z",
     "iopub.status.idle": "2021-01-24T17:19:48.905072Z",
     "shell.execute_reply": "2021-01-24T17:19:48.904168Z",
     "shell.execute_reply.started": "2021-01-24T17:19:48.838457Z"
    }
   },
   "outputs": [],
   "source": [
    "MAX_BERT_TOKENS = 512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-24T17:19:48.996797Z",
     "iopub.status.busy": "2021-01-24T17:19:48.996482Z",
     "iopub.status.idle": "2021-01-24T17:19:49.082133Z",
     "shell.execute_reply": "2021-01-24T17:19:49.081032Z",
     "shell.execute_reply.started": "2021-01-24T17:19:48.996759Z"
    }
   },
   "outputs": [],
   "source": [
    "transformer_tokenizer = tokenizer.get_transformer_tokenizer(\n",
    "    max_tokens=MAX_BERT_TOKENS, device=DEVICE\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-24T17:19:49.219590Z",
     "iopub.status.busy": "2021-01-24T17:19:49.219262Z",
     "iopub.status.idle": "2021-01-24T17:19:49.333487Z",
     "shell.execute_reply": "2021-01-24T17:19:49.332291Z",
     "shell.execute_reply.started": "2021-01-24T17:19:49.219552Z"
    }
   },
   "outputs": [],
   "source": [
    "transformer_dm = dataset.SquadDataManager(\n",
    "    squad_dataset, transformer_tokenizer, device=DEVICE\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-24T17:19:50.393325Z",
     "iopub.status.busy": "2021-01-24T17:19:50.392999Z",
     "iopub.status.idle": "2021-01-24T17:19:50.470597Z",
     "shell.execute_reply": "2021-01-24T17:19:50.469490Z",
     "shell.execute_reply.started": "2021-01-24T17:19:50.393287Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question_id</th>\n",
       "      <th>question</th>\n",
       "      <th>title</th>\n",
       "      <th>context_id</th>\n",
       "      <th>context</th>\n",
       "      <th>answer</th>\n",
       "      <th>answer_start</th>\n",
       "      <th>answer_end</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>56de4d9ecffd8e1900b4b7e2</td>\n",
       "      <td>What year was the Banská Akadémia founded?</td>\n",
       "      <td>Institute_of_technology</td>\n",
       "      <td>1860</td>\n",
       "      <td>The world's first institution of technology or...</td>\n",
       "      <td>[1735]</td>\n",
       "      <td>[167]</td>\n",
       "      <td>[171]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>572781a5f1498d1400e8fa1f</td>\n",
       "      <td>Who is elected every even numbered year?</td>\n",
       "      <td>Ann_Arbor,_Michigan</td>\n",
       "      <td>10585</td>\n",
       "      <td>Ann Arbor has a council-manager form of govern...</td>\n",
       "      <td>[mayor]</td>\n",
       "      <td>[192]</td>\n",
       "      <td>[197]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5730bb058ab72b1400f9c72c</td>\n",
       "      <td>Where were the use of advanced materials and t...</td>\n",
       "      <td>Sumer</td>\n",
       "      <td>17505</td>\n",
       "      <td>The most impressive and famous of Sumerian bui...</td>\n",
       "      <td>[Sumerian temples and palaces]</td>\n",
       "      <td>[421]</td>\n",
       "      <td>[449]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                question_id  \\\n",
       "0  56de4d9ecffd8e1900b4b7e2   \n",
       "1  572781a5f1498d1400e8fa1f   \n",
       "2  5730bb058ab72b1400f9c72c   \n",
       "\n",
       "                                            question                    title  \\\n",
       "0         What year was the Banská Akadémia founded?  Institute_of_technology   \n",
       "1           Who is elected every even numbered year?      Ann_Arbor,_Michigan   \n",
       "2  Where were the use of advanced materials and t...                    Sumer   \n",
       "\n",
       "   context_id                                            context  \\\n",
       "0        1860  The world's first institution of technology or...   \n",
       "1       10585  Ann Arbor has a council-manager form of govern...   \n",
       "2       17505  The most impressive and famous of Sumerian bui...   \n",
       "\n",
       "                           answer answer_start answer_end  \n",
       "0                          [1735]        [167]      [171]  \n",
       "1                         [mayor]        [192]      [197]  \n",
       "2  [Sumerian temples and palaces]        [421]      [449]  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transformer_dm.train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-24T17:19:50.684113Z",
     "iopub.status.busy": "2021-01-24T17:19:50.683802Z",
     "iopub.status.idle": "2021-01-24T17:19:50.754943Z",
     "shell.execute_reply": "2021-01-24T17:19:50.753846Z",
     "shell.execute_reply.started": "2021-01-24T17:19:50.684075Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question_id</th>\n",
       "      <th>question</th>\n",
       "      <th>title</th>\n",
       "      <th>context_id</th>\n",
       "      <th>context</th>\n",
       "      <th>answer</th>\n",
       "      <th>answer_start</th>\n",
       "      <th>answer_end</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>572674a05951b619008f7319</td>\n",
       "      <td>What is another speed that can also be reporte...</td>\n",
       "      <td>Film_speed</td>\n",
       "      <td>9354</td>\n",
       "      <td>The standard specifies how speed ratings shoul...</td>\n",
       "      <td>[SOS-based speed]</td>\n",
       "      <td>[793]</td>\n",
       "      <td>[808]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                question_id  \\\n",
       "0  572674a05951b619008f7319   \n",
       "\n",
       "                                            question       title  context_id  \\\n",
       "0  What is another speed that can also be reporte...  Film_speed        9354   \n",
       "\n",
       "                                             context             answer  \\\n",
       "0  The standard specifies how speed ratings shoul...  [SOS-based speed]   \n",
       "\n",
       "  answer_start answer_end  \n",
       "0        [793]      [808]  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transformer_dm.val_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-24T17:19:51.479187Z",
     "iopub.status.busy": "2021-01-24T17:19:51.478866Z",
     "iopub.status.idle": "2021-01-24T17:19:51.545725Z",
     "shell.execute_reply": "2021-01-24T17:19:51.544640Z",
     "shell.execute_reply.started": "2021-01-24T17:19:51.479149Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>answer</th>\n",
       "      <th>answer_start</th>\n",
       "      <th>answer_end</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [index, answer, answer_start, answer_end]\n",
       "Index: []"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transformer_dm.test_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BERT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The BERT model is a bidirectional transformer pretrained using a combination of masked language modeling objective and next sentence prediction on a large corpus comprising the Toronto Book Corpus and Wikipedia.\n",
    "\n",
    "The abstract from the paper is the following:\n",
    "\n",
    "> We introduce a new language representation model called BERT, which stands for Bidirectional Encoder Representations from Transformers. Unlike recent language representation models, BERT is designed to pre-train deep bidirectional representations from unlabeled text by jointly conditioning on both left and right context in all layers. As a result, the pre-trained BERT model can be fine-tuned with just one additional output layer to create state-of-the-art models for a wide range of tasks, such as question answering and language inference, without substantial task-specific architecture modifications."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-24T17:28:00.099393Z",
     "iopub.status.busy": "2021-01-24T17:28:00.098954Z",
     "iopub.status.idle": "2021-01-24T17:28:00.175819Z",
     "shell.execute_reply": "2021-01-24T17:28:00.174666Z",
     "shell.execute_reply.started": "2021-01-24T17:28:00.099349Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: WANDB_RUN_GROUP=bert\n"
     ]
    }
   ],
   "source": [
    "%env WANDB_RUN_GROUP=bert\n",
    "bert_run_name = utils.get_run_name()\n",
    "bert_args = partial(\n",
    "    TRAINER_ARGS,\n",
    "    output_dir=f\"./checkpoints/{os.getenv('WANDB_RUN_GROUP')}/{bert_run_name}\",\n",
    "    num_train_epochs=3,\n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=16,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training and validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-24T17:32:06.138865Z",
     "iopub.status.busy": "2021-01-24T17:32:06.138421Z",
     "iopub.status.idle": "2021-01-24T17:32:15.988652Z",
     "shell.execute_reply": "2021-01-24T17:32:15.987012Z",
     "shell.execute_reply.started": "2021-01-24T17:32:06.138820Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The BERT model has 114208512 parameters\n"
     ]
    }
   ],
   "source": [
    "bert_model = model.QABertModel(device=DEVICE)\n",
    "print(f\"The BERT model has {bert_model.count_parameters()} parameters\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-24T17:32:16.101977Z",
     "iopub.status.busy": "2021-01-24T17:32:16.101668Z",
     "iopub.status.idle": "2021-01-24T17:32:16.169743Z",
     "shell.execute_reply": "2021-01-24T17:32:16.168517Z",
     "shell.execute_reply.started": "2021-01-24T17:32:16.101939Z"
    }
   },
   "outputs": [],
   "source": [
    "bert_optimizer = optim.Adam(bert_model.parameters(), lr=5e-5)\n",
    "bert_lr_scheduler = transformers.get_constant_schedule(bert_optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-24T17:32:16.172085Z",
     "iopub.status.busy": "2021-01-24T17:32:16.171773Z",
     "iopub.status.idle": "2021-01-24T17:32:16.256158Z",
     "shell.execute_reply": "2021-01-24T17:32:16.254702Z",
     "shell.execute_reply.started": "2021-01-24T17:32:16.172047Z"
    }
   },
   "outputs": [],
   "source": [
    "bert_trainer = training.SquadTrainer(\n",
    "    model=bert_model,\n",
    "    args=bert_args(run_name=bert_run_name),\n",
    "    data_collator=transformer_dm.tokenizer,\n",
    "    train_dataset=transformer_dm.train_dataset,\n",
    "    eval_dataset=transformer_dm.val_dataset,\n",
    "    optimizers=(bert_optimizer, bert_lr_scheduler),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-24T17:34:09.164389Z",
     "iopub.status.busy": "2021-01-24T17:34:09.164063Z",
     "iopub.status.idle": "2021-01-24T17:34:49.096623Z",
     "shell.execute_reply": "2021-01-24T17:34:49.095205Z",
     "shell.execute_reply.started": "2021-01-24T17:34:09.164347Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "        </style>\n",
       "      \n",
       "      <progress value='3' max='3' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3/3 00:32, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "      <th>Em</th>\n",
       "      <th>Runtime</th>\n",
       "      <th>Samples Per Second</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>4.450900</td>\n",
       "      <td>5.148665</td>\n",
       "      <td>0.013514</td>\n",
       "      <td>0.013699</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.026667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.637500</td>\n",
       "      <td>1.569000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>4.450900</td>\n",
       "      <td>5.117357</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>0.052632</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.095238</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.597100</td>\n",
       "      <td>1.675000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>4.450900</td>\n",
       "      <td>5.088964</td>\n",
       "      <td>0.047619</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.565400</td>\n",
       "      <td>1.769000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=3, training_loss=4.086720943450928, metrics={'train_runtime': 39.8523, 'train_samples_per_second': 0.075, 'total_flos': 0, 'epoch': 3.0})"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bert_trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_model = model.QABertModel(device=DEVICE)\n",
    "print(f\"The BERT model has {bert_model.count_parameters()} parameters\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_optimizer = optim.Adam(bert_model.parameters(), lr=5e-5)\n",
    "bert_lr_scheduler = transformers.get_constant_schedule(bert_optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_trainer = training.SquadTrainer(\n",
    "    model=bert_model,\n",
    "    args=bert_args(run_name=f\"{bert_run_name}-whole\", evaluation_strategy=\"no\"),\n",
    "    data_collator=transformer_dm.tokenizer,\n",
    "    train_dataset=transformer_dm.whole_dataset,\n",
    "    optimizers=(bert_optimizer, bert_lr_scheduler),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-21T17:56:55.805141Z",
     "iopub.status.busy": "2021-01-21T17:56:55.804703Z",
     "iopub.status.idle": "2021-01-21T17:56:56.481031Z",
     "shell.execute_reply": "2021-01-21T17:56:56.479925Z",
     "shell.execute_reply.started": "2021-01-21T17:56:55.805097Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "        </style>\n",
       "      \n",
       "      <progress value='1' max='1' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1/1 : < :]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'test_loss': 9.000775337219238,\n",
       " 'test_f1': 0.0,\n",
       " 'test_accuracy': 0.0,\n",
       " 'test_em': 0.0,\n",
       " 'test_runtime': 0.6044,\n",
       " 'test_samples_per_second': 1.655}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bert_test_output = bert_trainer.predict(transformer_dm.test_dataset)\n",
    "bert_test_output.metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-21T17:57:02.820786Z",
     "iopub.status.busy": "2021-01-21T17:57:02.820061Z",
     "iopub.status.idle": "2021-01-21T17:58:58.223064Z",
     "shell.execute_reply": "2021-01-21T17:58:58.221615Z",
     "shell.execute_reply.started": "2021-01-21T17:57:02.820720Z"
    }
   },
   "outputs": [],
   "source": [
    "bert_answers_path = \"results/answers/bert.json\"\n",
    "utils.save_answers(bert_answers_path, bert_test_output.predictions[-1])\n",
    "wandb.save(bert_answers_path);\n",
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DistilBERT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DistilBERT is a small, fast, cheap and light Transformer model trained by distilling BERT base. It has 40% less parameters than _bert-base-uncased_, runs 60% faster while preserving over 95% of BERT’s performances as measured on the GLUE language understanding benchmark.\n",
    "\n",
    "The abstract from the paper is the following:\n",
    "\n",
    "> As Transfer Learning from large-scale pre-trained models becomes more prevalent in Natural Language Processing (NLP), operating these large models in on-the-edge and/or under constrained computational training or inference budgets remains challenging. In this work, we propose a method to pre-train a smaller general-purpose language representation model, called DistilBERT, which can then be fine-tuned with good performances on a wide range of tasks like its larger counterparts. While most prior work investigated the use of distillation for building task-specific models, we leverage knowledge distillation during the pretraining phase and show that it is possible to reduce the size of a BERT model by 40%, while retaining 97% of its language understanding capabilities and being 60% faster. To leverage the inductive biases learned by larger models during pretraining, we introduce a triple loss combining language modeling, distillation and cosine-distance losses. Our smaller, faster and lighter model is cheaper to pre-train and we demonstrate its capabilities for on-device computations in a proof-of-concept experiment and a comparative on-device study."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-21T17:56:05.140129Z",
     "iopub.status.busy": "2021-01-21T17:56:05.139775Z",
     "iopub.status.idle": "2021-01-21T17:56:05.227681Z",
     "shell.execute_reply": "2021-01-21T17:56:05.226548Z",
     "shell.execute_reply.started": "2021-01-21T17:56:05.140090Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: WANDB_RUN_GROUP=bert\n"
     ]
    }
   ],
   "source": [
    "%env WANDB_RUN_GROUP=distilbert\n",
    "distilbert_run_name = utils.get_run_name()\n",
    "distilbert_args = partial(\n",
    "    TRAINER_ARGS,\n",
    "    output_dir=f\"./checkpoints/{os.getenv('WANDB_RUN_GROUP')}/{distilbert_run_name}\",\n",
    "    num_train_epochs=3,\n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=16,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training and validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-21T17:55:53.705471Z",
     "iopub.status.busy": "2021-01-21T17:55:53.705021Z",
     "iopub.status.idle": "2021-01-21T17:56:03.103337Z",
     "shell.execute_reply": "2021-01-21T17:56:03.101497Z",
     "shell.execute_reply.started": "2021-01-21T17:55:53.705426Z"
    }
   },
   "outputs": [],
   "source": [
    "distilbert_model = model.QADistilBertModel(device=DEVICE)\n",
    "print(f\"The DistilBERT model has {distilbert_model.count_parameters()} parameters\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "distilbert_optimizer = optim.Adam(distilbert_model.parameters(), lr=5e-5)\n",
    "distilbert_lr_scheduler = transformers.get_constant_schedule(distilbert_optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "distilbert_trainer = training.SquadTrainer(\n",
    "    model=distilbert_model,\n",
    "    args=distilbert_args(run_name=distilbert_run_name),\n",
    "    data_collator=transformer_dm.tokenizer,\n",
    "    train_dataset=transformer_dm.train_dataset,\n",
    "    eval_dataset=transformer_dm.val_dataset,\n",
    "    optimizers=(distilbert_optimizer, distilbert_lr_scheduler),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-21T17:56:06.270781Z",
     "iopub.status.busy": "2021-01-21T17:56:06.270324Z",
     "iopub.status.idle": "2021-01-21T17:56:51.413490Z",
     "shell.execute_reply": "2021-01-21T17:56:51.412115Z",
     "shell.execute_reply.started": "2021-01-21T17:56:06.270736Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "        </style>\n",
       "      \n",
       "      <progress value='3' max='3' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3/3 00:30, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>F1</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Em</th>\n",
       "      <th>Runtime</th>\n",
       "      <th>Samples Per Second</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>6.527200</td>\n",
       "      <td>6.653205</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.042400</td>\n",
       "      <td>1.919000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>6.527200</td>\n",
       "      <td>7.183872</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.067100</td>\n",
       "      <td>1.874000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>6.527200</td>\n",
       "      <td>7.202362</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.952700</td>\n",
       "      <td>2.099000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=3, training_loss=5.523826281229655, metrics={'train_runtime': 45.0591, 'train_samples_per_second': 0.067, 'total_flos': 0, 'epoch': 3.0})"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "distilbert_trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "distilbert_model = model.QADistilBertModel(device=DEVICE)\n",
    "print(f\"The DistilBERT model has {distilbert_model.count_parameters()} parameters\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "distilbert_optimizer = optim.Adam(distilbert_model.parameters(), lr=5e-5)\n",
    "distilbert_lr_scheduler = transformers.get_constant_schedule(distilbert_optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "distilbert_trainer = training.SquadTrainer(\n",
    "    model=distilbert_model,\n",
    "    args=distilbert_args(run_name=f\"{distilbert_run_name}-whole\", evaluation_strategy=\"no\"),\n",
    "    data_collator=transformer_dm.tokenizer,\n",
    "    train_dataset=transformer_dm.whole_dataset,\n",
    "    optimizers=(distilbert_optimizer, distilbert_lr_scheduler),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "distilbert_trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-21T17:56:55.805141Z",
     "iopub.status.busy": "2021-01-21T17:56:55.804703Z",
     "iopub.status.idle": "2021-01-21T17:56:56.481031Z",
     "shell.execute_reply": "2021-01-21T17:56:56.479925Z",
     "shell.execute_reply.started": "2021-01-21T17:56:55.805097Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "        </style>\n",
       "      \n",
       "      <progress value='1' max='1' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1/1 : < :]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'test_loss': 9.000775337219238,\n",
       " 'test_f1': 0.0,\n",
       " 'test_accuracy': 0.0,\n",
       " 'test_em': 0.0,\n",
       " 'test_runtime': 0.6044,\n",
       " 'test_samples_per_second': 1.655}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "distilbert_test_output = distilbert_trainer.predict(transformer_dm.test_dataset)\n",
    "distilbert_test_output.metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-21T17:57:02.820786Z",
     "iopub.status.busy": "2021-01-21T17:57:02.820061Z",
     "iopub.status.idle": "2021-01-21T17:58:58.223064Z",
     "shell.execute_reply": "2021-01-21T17:58:58.221615Z",
     "shell.execute_reply.started": "2021-01-21T17:57:02.820720Z"
    }
   },
   "outputs": [],
   "source": [
    "distilbert_answers_path = \"results/answers/distilbert.json\"\n",
    "utils.save_answers(distilbert_answers_path, distilbert_test_output.predictions[-1])\n",
    "wandb.save(distilbert_answers_path);\n",
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ELECTRA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ELECTRA is a new pretraining approach which trains two transformer models: the generator and the discriminator. The generator’s role is to replace tokens in a sequence, and is therefore trained as a masked language model. The discriminator, which is the model we’re interested in, tries to identify which tokens were replaced by the generator in the sequence.\n",
    "\n",
    "The abstract from the paper is the following:\n",
    "\n",
    "> Masked language modeling (MLM) pretraining methods such as BERT corrupt the input by replacing some tokens with [MASK] and then train a model to reconstruct the original tokens. While they produce good results when transferred to downstream NLP tasks, they generally require large amounts of compute to be effective. As an alternative, we propose a more sample-efficient pretraining task called replaced token detection. Instead of masking the input, our approach corrupts it by replacing some tokens with plausible alternatives sampled from a small generator network. Then, instead of training a model that predicts the original identities of the corrupted tokens, we train a discriminative model that predicts whether each token in the corrupted input was replaced by a generator sample or not. Thorough experiments demonstrate this new pretraining task is more efficient than MLM because the task is defined over all input tokens rather than just the small subset that was masked out. As a result, the contextual representations learned by our approach substantially outperform the ones learned by BERT given the same model size, data, and compute. The gains are particularly strong for small models; for example, we train a model on one GPU for 4 days that outperforms GPT (trained using 30x more compute) on the GLUE natural language understanding benchmark. Our approach also works well at scale, where it performs comparably to RoBERTa and XLNet while using less than 1/4 of their compute and outperforms them when using the same amount of compute."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-21T17:56:05.140129Z",
     "iopub.status.busy": "2021-01-21T17:56:05.139775Z",
     "iopub.status.idle": "2021-01-21T17:56:05.227681Z",
     "shell.execute_reply": "2021-01-21T17:56:05.226548Z",
     "shell.execute_reply.started": "2021-01-21T17:56:05.140090Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: WANDB_RUN_GROUP=bert\n"
     ]
    }
   ],
   "source": [
    "%env WANDB_RUN_GROUP=electra\n",
    "electra_run_name = utils.get_run_name()\n",
    "electra_args = partial(\n",
    "    TRAINER_ARGS,\n",
    "    output_dir=f\"./checkpoints/{os.getenv('WANDB_RUN_GROUP')}/{electra_run_name}\",\n",
    "    num_train_epochs=3,\n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=16,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training and validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-21T17:55:53.705471Z",
     "iopub.status.busy": "2021-01-21T17:55:53.705021Z",
     "iopub.status.idle": "2021-01-21T17:56:03.103337Z",
     "shell.execute_reply": "2021-01-21T17:56:03.101497Z",
     "shell.execute_reply.started": "2021-01-21T17:55:53.705426Z"
    }
   },
   "outputs": [],
   "source": [
    "electra_model = model.QAElectraModel(device=DEVICE)\n",
    "print(f\"The ELECTRA model has {electra_model.count_parameters()} parameters\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "electra_optimizer = optim.Adam(electra_model.parameters(), lr=5e-5)\n",
    "electra_lr_scheduler = transformers.get_constant_schedule(electra_optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "electra_trainer = training.SquadTrainer(\n",
    "    model=electra_model,\n",
    "    args=electra_args(run_name=electra_run_name),\n",
    "    data_collator=transformer_dm.tokenizer,\n",
    "    train_dataset=transformer_dm.train_dataset,\n",
    "    eval_dataset=transformer_dm.val_dataset,\n",
    "    optimizers=(electra_optimizer, electra_lr_scheduler),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-21T17:56:06.270781Z",
     "iopub.status.busy": "2021-01-21T17:56:06.270324Z",
     "iopub.status.idle": "2021-01-21T17:56:51.413490Z",
     "shell.execute_reply": "2021-01-21T17:56:51.412115Z",
     "shell.execute_reply.started": "2021-01-21T17:56:06.270736Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "        </style>\n",
       "      \n",
       "      <progress value='3' max='3' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3/3 00:30, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>F1</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Em</th>\n",
       "      <th>Runtime</th>\n",
       "      <th>Samples Per Second</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>6.527200</td>\n",
       "      <td>6.653205</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.042400</td>\n",
       "      <td>1.919000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>6.527200</td>\n",
       "      <td>7.183872</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.067100</td>\n",
       "      <td>1.874000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>6.527200</td>\n",
       "      <td>7.202362</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.952700</td>\n",
       "      <td>2.099000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=3, training_loss=5.523826281229655, metrics={'train_runtime': 45.0591, 'train_samples_per_second': 0.067, 'total_flos': 0, 'epoch': 3.0})"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "electra_trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "electra_model = model.QAElectraModel(device=DEVICE)\n",
    "print(f\"The ELECTRA model has {electra_model.count_parameters()} parameters\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "electra_optimizer = optim.Adam(electra_model.parameters(), lr=5e-5)\n",
    "electra_lr_scheduler = transformers.get_constant_schedule(electra_optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "electra_trainer = training.SquadTrainer(\n",
    "    model=electra_model,\n",
    "    args=electra_args(run_name=f\"{electra_run_name}-whole\", evaluation_strategy=\"no\"),\n",
    "    data_collator=transformer_dm.tokenizer,\n",
    "    train_dataset=transformer_dm.whole_dataset,\n",
    "    optimizers=(electra_optimizer, electra_lr_scheduler),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "electra_trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-21T17:56:55.805141Z",
     "iopub.status.busy": "2021-01-21T17:56:55.804703Z",
     "iopub.status.idle": "2021-01-21T17:56:56.481031Z",
     "shell.execute_reply": "2021-01-21T17:56:56.479925Z",
     "shell.execute_reply.started": "2021-01-21T17:56:55.805097Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "        </style>\n",
       "      \n",
       "      <progress value='1' max='1' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1/1 : < :]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'test_loss': 9.000775337219238,\n",
       " 'test_f1': 0.0,\n",
       " 'test_accuracy': 0.0,\n",
       " 'test_em': 0.0,\n",
       " 'test_runtime': 0.6044,\n",
       " 'test_samples_per_second': 1.655}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "electra_test_output = electra_trainer.predict(transformer_dm.test_dataset)\n",
    "electra_test_output.metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-21T17:57:02.820786Z",
     "iopub.status.busy": "2021-01-21T17:57:02.820061Z",
     "iopub.status.idle": "2021-01-21T17:58:58.223064Z",
     "shell.execute_reply": "2021-01-21T17:58:58.221615Z",
     "shell.execute_reply.started": "2021-01-21T17:57:02.820720Z"
    }
   },
   "outputs": [],
   "source": [
    "electra_answers_path = \"results/answers/electra.json\"\n",
    "utils.save_answers(electra_answers_path, electra_test_output.predictions[-1])\n",
    "wandb.save(electra_answers_path);\n",
    "wandb.finish()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
