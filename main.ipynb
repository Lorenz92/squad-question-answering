{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question answering on the SQuAD dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-05T17:59:03.344705Z",
     "iopub.status.busy": "2021-01-05T17:59:03.344277Z",
     "iopub.status.idle": "2021-01-05T17:59:03.767423Z",
     "shell.execute_reply": "2021-01-05T17:59:03.766334Z",
     "shell.execute_reply.started": "2021-01-05T17:59:03.344660Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "import dataset\n",
    "import model\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-05T13:45:45.064110Z",
     "iopub.status.busy": "2021-01-05T13:45:45.063769Z",
     "iopub.status.idle": "2021-01-05T13:45:45.118675Z",
     "shell.execute_reply": "2021-01-05T13:45:45.117442Z",
     "shell.execute_reply.started": "2021-01-05T13:45:45.064068Z"
    }
   },
   "outputs": [],
   "source": [
    "plt.rcParams['figure.figsize'] = [8, 6]\n",
    "plt.rcParams['figure.dpi'] = 100\n",
    "plt.rcParams['axes.xmargin'] = .05\n",
    "plt.rcParams['axes.ymargin'] = .05\n",
    "plt.style.use('ggplot')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data loading/preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-05T13:45:45.901666Z",
     "iopub.status.busy": "2021-01-05T13:45:45.901358Z",
     "iopub.status.idle": "2021-01-05T13:45:45.957682Z",
     "shell.execute_reply": "2021-01-05T13:45:45.956386Z",
     "shell.execute_reply.started": "2021-01-05T13:45:45.901627Z"
    }
   },
   "outputs": [],
   "source": [
    "def preprocess_question(text):\n",
    "    \"\"\"\n",
    "    Preprocess the given question text from the SQuAD dataset\n",
    "    \"\"\"\n",
    "    return text.lower()\n",
    "\n",
    "\n",
    "def preprocess_context(text):\n",
    "    \"\"\"\n",
    "    Preprocess the given context text from the SQuAD dataset\n",
    "    \"\"\"\n",
    "    return text.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-05T13:45:46.416297Z",
     "iopub.status.busy": "2021-01-05T13:45:46.415995Z",
     "iopub.status.idle": "2021-01-05T13:46:15.639554Z",
     "shell.execute_reply": "2021-01-05T13:46:15.638366Z",
     "shell.execute_reply.started": "2021-01-05T13:45:46.416259Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>question</th>\n",
       "      <th>title</th>\n",
       "      <th>context_id</th>\n",
       "      <th>context</th>\n",
       "      <th>answer</th>\n",
       "      <th>answer_start</th>\n",
       "      <th>answer_end</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5733be284776f41900661182</td>\n",
       "      <td>To whom did the Virgin Mary allegedly appear i...</td>\n",
       "      <td>University_of_Notre_Dame</td>\n",
       "      <td>0</td>\n",
       "      <td>Architecturally, the school has a Catholic cha...</td>\n",
       "      <td>Saint Bernadette Soubirous</td>\n",
       "      <td>515</td>\n",
       "      <td>541</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5733be284776f4190066117f</td>\n",
       "      <td>What is in front of the Notre Dame Main Building?</td>\n",
       "      <td>University_of_Notre_Dame</td>\n",
       "      <td>0</td>\n",
       "      <td>Architecturally, the school has a Catholic cha...</td>\n",
       "      <td>a copper statue of Christ</td>\n",
       "      <td>188</td>\n",
       "      <td>213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5733be284776f41900661180</td>\n",
       "      <td>The Basilica of the Sacred heart at Notre Dame...</td>\n",
       "      <td>University_of_Notre_Dame</td>\n",
       "      <td>0</td>\n",
       "      <td>Architecturally, the school has a Catholic cha...</td>\n",
       "      <td>the Main Building</td>\n",
       "      <td>279</td>\n",
       "      <td>296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5733be284776f41900661181</td>\n",
       "      <td>What is the Grotto at Notre Dame?</td>\n",
       "      <td>University_of_Notre_Dame</td>\n",
       "      <td>0</td>\n",
       "      <td>Architecturally, the school has a Catholic cha...</td>\n",
       "      <td>a Marian place of prayer and reflection</td>\n",
       "      <td>381</td>\n",
       "      <td>420</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5733be284776f4190066117e</td>\n",
       "      <td>What sits on top of the Main Building at Notre...</td>\n",
       "      <td>University_of_Notre_Dame</td>\n",
       "      <td>0</td>\n",
       "      <td>Architecturally, the school has a Catholic cha...</td>\n",
       "      <td>a golden statue of the Virgin Mary</td>\n",
       "      <td>92</td>\n",
       "      <td>126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87594</th>\n",
       "      <td>5735d259012e2f140011a09d</td>\n",
       "      <td>In what US state did Kathmandu first establish...</td>\n",
       "      <td>Kathmandu</td>\n",
       "      <td>18890</td>\n",
       "      <td>Kathmandu Metropolitan City (KMC), in order to...</td>\n",
       "      <td>Oregon</td>\n",
       "      <td>229</td>\n",
       "      <td>235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87595</th>\n",
       "      <td>5735d259012e2f140011a09e</td>\n",
       "      <td>What was Yangon previously known as?</td>\n",
       "      <td>Kathmandu</td>\n",
       "      <td>18890</td>\n",
       "      <td>Kathmandu Metropolitan City (KMC), in order to...</td>\n",
       "      <td>Rangoon</td>\n",
       "      <td>414</td>\n",
       "      <td>421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87596</th>\n",
       "      <td>5735d259012e2f140011a09f</td>\n",
       "      <td>With what Belorussian city does Kathmandu have...</td>\n",
       "      <td>Kathmandu</td>\n",
       "      <td>18890</td>\n",
       "      <td>Kathmandu Metropolitan City (KMC), in order to...</td>\n",
       "      <td>Minsk</td>\n",
       "      <td>476</td>\n",
       "      <td>481</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87597</th>\n",
       "      <td>5735d259012e2f140011a0a0</td>\n",
       "      <td>In what year did Kathmandu create its initial ...</td>\n",
       "      <td>Kathmandu</td>\n",
       "      <td>18890</td>\n",
       "      <td>Kathmandu Metropolitan City (KMC), in order to...</td>\n",
       "      <td>1975</td>\n",
       "      <td>199</td>\n",
       "      <td>203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87598</th>\n",
       "      <td>5735d259012e2f140011a0a1</td>\n",
       "      <td>What is KMC an initialism of?</td>\n",
       "      <td>Kathmandu</td>\n",
       "      <td>18890</td>\n",
       "      <td>Kathmandu Metropolitan City (KMC), in order to...</td>\n",
       "      <td>Kathmandu Metropolitan City</td>\n",
       "      <td>0</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>87599 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                          index  \\\n",
       "0      5733be284776f41900661182   \n",
       "1      5733be284776f4190066117f   \n",
       "2      5733be284776f41900661180   \n",
       "3      5733be284776f41900661181   \n",
       "4      5733be284776f4190066117e   \n",
       "...                         ...   \n",
       "87594  5735d259012e2f140011a09d   \n",
       "87595  5735d259012e2f140011a09e   \n",
       "87596  5735d259012e2f140011a09f   \n",
       "87597  5735d259012e2f140011a0a0   \n",
       "87598  5735d259012e2f140011a0a1   \n",
       "\n",
       "                                                question  \\\n",
       "0      To whom did the Virgin Mary allegedly appear i...   \n",
       "1      What is in front of the Notre Dame Main Building?   \n",
       "2      The Basilica of the Sacred heart at Notre Dame...   \n",
       "3                      What is the Grotto at Notre Dame?   \n",
       "4      What sits on top of the Main Building at Notre...   \n",
       "...                                                  ...   \n",
       "87594  In what US state did Kathmandu first establish...   \n",
       "87595               What was Yangon previously known as?   \n",
       "87596  With what Belorussian city does Kathmandu have...   \n",
       "87597  In what year did Kathmandu create its initial ...   \n",
       "87598                      What is KMC an initialism of?   \n",
       "\n",
       "                          title  context_id  \\\n",
       "0      University_of_Notre_Dame           0   \n",
       "1      University_of_Notre_Dame           0   \n",
       "2      University_of_Notre_Dame           0   \n",
       "3      University_of_Notre_Dame           0   \n",
       "4      University_of_Notre_Dame           0   \n",
       "...                         ...         ...   \n",
       "87594                 Kathmandu       18890   \n",
       "87595                 Kathmandu       18890   \n",
       "87596                 Kathmandu       18890   \n",
       "87597                 Kathmandu       18890   \n",
       "87598                 Kathmandu       18890   \n",
       "\n",
       "                                                 context  \\\n",
       "0      Architecturally, the school has a Catholic cha...   \n",
       "1      Architecturally, the school has a Catholic cha...   \n",
       "2      Architecturally, the school has a Catholic cha...   \n",
       "3      Architecturally, the school has a Catholic cha...   \n",
       "4      Architecturally, the school has a Catholic cha...   \n",
       "...                                                  ...   \n",
       "87594  Kathmandu Metropolitan City (KMC), in order to...   \n",
       "87595  Kathmandu Metropolitan City (KMC), in order to...   \n",
       "87596  Kathmandu Metropolitan City (KMC), in order to...   \n",
       "87597  Kathmandu Metropolitan City (KMC), in order to...   \n",
       "87598  Kathmandu Metropolitan City (KMC), in order to...   \n",
       "\n",
       "                                        answer  answer_start  answer_end  \n",
       "0                   Saint Bernadette Soubirous           515         541  \n",
       "1                    a copper statue of Christ           188         213  \n",
       "2                            the Main Building           279         296  \n",
       "3      a Marian place of prayer and reflection           381         420  \n",
       "4           a golden statue of the Virgin Mary            92         126  \n",
       "...                                        ...           ...         ...  \n",
       "87594                                   Oregon           229         235  \n",
       "87595                                  Rangoon           414         421  \n",
       "87596                                    Minsk           476         481  \n",
       "87597                                     1975           199         203  \n",
       "87598              Kathmandu Metropolitan City             0          27  \n",
       "\n",
       "[87599 rows x 8 columns]"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "squad_dataset = dataset.SquadDataset(\n",
    "    question_preprocessor=preprocess_question,\n",
    "    context_preprocessor=preprocess_context,\n",
    ")\n",
    "squad_dataset.dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-05T13:46:22.704816Z",
     "iopub.status.busy": "2021-01-05T13:46:22.704386Z",
     "iopub.status.idle": "2021-01-05T13:46:22.782750Z",
     "shell.execute_reply": "2021-01-05T13:46:22.781429Z",
     "shell.execute_reply.started": "2021-01-05T13:46:22.704771Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>question</th>\n",
       "      <th>title</th>\n",
       "      <th>context_id</th>\n",
       "      <th>context</th>\n",
       "      <th>answer</th>\n",
       "      <th>answer_start</th>\n",
       "      <th>answer_end</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5733be284776f41900661182</td>\n",
       "      <td>To whom did the Virgin Mary allegedly appear i...</td>\n",
       "      <td>University_of_Notre_Dame</td>\n",
       "      <td>0</td>\n",
       "      <td>Architecturally, the school has a Catholic cha...</td>\n",
       "      <td>Saint Bernadette Soubirous</td>\n",
       "      <td>515</td>\n",
       "      <td>541</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5733be284776f4190066117f</td>\n",
       "      <td>What is in front of the Notre Dame Main Building?</td>\n",
       "      <td>University_of_Notre_Dame</td>\n",
       "      <td>0</td>\n",
       "      <td>Architecturally, the school has a Catholic cha...</td>\n",
       "      <td>a copper statue of Christ</td>\n",
       "      <td>188</td>\n",
       "      <td>213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5733be284776f41900661180</td>\n",
       "      <td>The Basilica of the Sacred heart at Notre Dame...</td>\n",
       "      <td>University_of_Notre_Dame</td>\n",
       "      <td>0</td>\n",
       "      <td>Architecturally, the school has a Catholic cha...</td>\n",
       "      <td>the Main Building</td>\n",
       "      <td>279</td>\n",
       "      <td>296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5733be284776f41900661181</td>\n",
       "      <td>What is the Grotto at Notre Dame?</td>\n",
       "      <td>University_of_Notre_Dame</td>\n",
       "      <td>0</td>\n",
       "      <td>Architecturally, the school has a Catholic cha...</td>\n",
       "      <td>a Marian place of prayer and reflection</td>\n",
       "      <td>381</td>\n",
       "      <td>420</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5733be284776f4190066117e</td>\n",
       "      <td>What sits on top of the Main Building at Notre...</td>\n",
       "      <td>University_of_Notre_Dame</td>\n",
       "      <td>0</td>\n",
       "      <td>Architecturally, the school has a Catholic cha...</td>\n",
       "      <td>a golden statue of the Virgin Mary</td>\n",
       "      <td>92</td>\n",
       "      <td>126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70185</th>\n",
       "      <td>5735d259012e2f140011a09d</td>\n",
       "      <td>In what US state did Kathmandu first establish...</td>\n",
       "      <td>Kathmandu</td>\n",
       "      <td>18890</td>\n",
       "      <td>Kathmandu Metropolitan City (KMC), in order to...</td>\n",
       "      <td>Oregon</td>\n",
       "      <td>229</td>\n",
       "      <td>235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70186</th>\n",
       "      <td>5735d259012e2f140011a09e</td>\n",
       "      <td>What was Yangon previously known as?</td>\n",
       "      <td>Kathmandu</td>\n",
       "      <td>18890</td>\n",
       "      <td>Kathmandu Metropolitan City (KMC), in order to...</td>\n",
       "      <td>Rangoon</td>\n",
       "      <td>414</td>\n",
       "      <td>421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70187</th>\n",
       "      <td>5735d259012e2f140011a09f</td>\n",
       "      <td>With what Belorussian city does Kathmandu have...</td>\n",
       "      <td>Kathmandu</td>\n",
       "      <td>18890</td>\n",
       "      <td>Kathmandu Metropolitan City (KMC), in order to...</td>\n",
       "      <td>Minsk</td>\n",
       "      <td>476</td>\n",
       "      <td>481</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70188</th>\n",
       "      <td>5735d259012e2f140011a0a0</td>\n",
       "      <td>In what year did Kathmandu create its initial ...</td>\n",
       "      <td>Kathmandu</td>\n",
       "      <td>18890</td>\n",
       "      <td>Kathmandu Metropolitan City (KMC), in order to...</td>\n",
       "      <td>1975</td>\n",
       "      <td>199</td>\n",
       "      <td>203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70189</th>\n",
       "      <td>5735d259012e2f140011a0a1</td>\n",
       "      <td>What is KMC an initialism of?</td>\n",
       "      <td>Kathmandu</td>\n",
       "      <td>18890</td>\n",
       "      <td>Kathmandu Metropolitan City (KMC), in order to...</td>\n",
       "      <td>Kathmandu Metropolitan City</td>\n",
       "      <td>0</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>70190 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                          index  \\\n",
       "0      5733be284776f41900661182   \n",
       "1      5733be284776f4190066117f   \n",
       "2      5733be284776f41900661180   \n",
       "3      5733be284776f41900661181   \n",
       "4      5733be284776f4190066117e   \n",
       "...                         ...   \n",
       "70185  5735d259012e2f140011a09d   \n",
       "70186  5735d259012e2f140011a09e   \n",
       "70187  5735d259012e2f140011a09f   \n",
       "70188  5735d259012e2f140011a0a0   \n",
       "70189  5735d259012e2f140011a0a1   \n",
       "\n",
       "                                                question  \\\n",
       "0      To whom did the Virgin Mary allegedly appear i...   \n",
       "1      What is in front of the Notre Dame Main Building?   \n",
       "2      The Basilica of the Sacred heart at Notre Dame...   \n",
       "3                      What is the Grotto at Notre Dame?   \n",
       "4      What sits on top of the Main Building at Notre...   \n",
       "...                                                  ...   \n",
       "70185  In what US state did Kathmandu first establish...   \n",
       "70186               What was Yangon previously known as?   \n",
       "70187  With what Belorussian city does Kathmandu have...   \n",
       "70188  In what year did Kathmandu create its initial ...   \n",
       "70189                      What is KMC an initialism of?   \n",
       "\n",
       "                          title  context_id  \\\n",
       "0      University_of_Notre_Dame           0   \n",
       "1      University_of_Notre_Dame           0   \n",
       "2      University_of_Notre_Dame           0   \n",
       "3      University_of_Notre_Dame           0   \n",
       "4      University_of_Notre_Dame           0   \n",
       "...                         ...         ...   \n",
       "70185                 Kathmandu       18890   \n",
       "70186                 Kathmandu       18890   \n",
       "70187                 Kathmandu       18890   \n",
       "70188                 Kathmandu       18890   \n",
       "70189                 Kathmandu       18890   \n",
       "\n",
       "                                                 context  \\\n",
       "0      Architecturally, the school has a Catholic cha...   \n",
       "1      Architecturally, the school has a Catholic cha...   \n",
       "2      Architecturally, the school has a Catholic cha...   \n",
       "3      Architecturally, the school has a Catholic cha...   \n",
       "4      Architecturally, the school has a Catholic cha...   \n",
       "...                                                  ...   \n",
       "70185  Kathmandu Metropolitan City (KMC), in order to...   \n",
       "70186  Kathmandu Metropolitan City (KMC), in order to...   \n",
       "70187  Kathmandu Metropolitan City (KMC), in order to...   \n",
       "70188  Kathmandu Metropolitan City (KMC), in order to...   \n",
       "70189  Kathmandu Metropolitan City (KMC), in order to...   \n",
       "\n",
       "                                        answer  answer_start  answer_end  \n",
       "0                   Saint Bernadette Soubirous           515         541  \n",
       "1                    a copper statue of Christ           188         213  \n",
       "2                            the Main Building           279         296  \n",
       "3      a Marian place of prayer and reflection           381         420  \n",
       "4           a golden statue of the Virgin Mary            92         126  \n",
       "...                                        ...           ...         ...  \n",
       "70185                                   Oregon           229         235  \n",
       "70186                                  Rangoon           414         421  \n",
       "70187                                    Minsk           476         481  \n",
       "70188                                     1975           199         203  \n",
       "70189              Kathmandu Metropolitan City             0          27  \n",
       "\n",
       "[70190 rows x 8 columns]"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "squad_dataset.train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-05T13:46:26.214108Z",
     "iopub.status.busy": "2021-01-05T13:46:26.213713Z",
     "iopub.status.idle": "2021-01-05T13:46:26.290984Z",
     "shell.execute_reply": "2021-01-05T13:46:26.289554Z",
     "shell.execute_reply.started": "2021-01-05T13:46:26.214065Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>question</th>\n",
       "      <th>title</th>\n",
       "      <th>context_id</th>\n",
       "      <th>context</th>\n",
       "      <th>answer</th>\n",
       "      <th>answer_start</th>\n",
       "      <th>answer_end</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>56be85543aeaaa14008c9063</td>\n",
       "      <td>When did Beyonce start becoming popular?</td>\n",
       "      <td>Beyoncé</td>\n",
       "      <td>55</td>\n",
       "      <td>Beyoncé Giselle Knowles-Carter (/biːˈjɒnseɪ/ b...</td>\n",
       "      <td>in the late 1990s</td>\n",
       "      <td>269</td>\n",
       "      <td>286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>56be85543aeaaa14008c9065</td>\n",
       "      <td>What areas did Beyonce compete in when she was...</td>\n",
       "      <td>Beyoncé</td>\n",
       "      <td>55</td>\n",
       "      <td>Beyoncé Giselle Knowles-Carter (/biːˈjɒnseɪ/ b...</td>\n",
       "      <td>singing and dancing</td>\n",
       "      <td>207</td>\n",
       "      <td>226</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>56be85543aeaaa14008c9066</td>\n",
       "      <td>When did Beyonce leave Destiny's Child and bec...</td>\n",
       "      <td>Beyoncé</td>\n",
       "      <td>55</td>\n",
       "      <td>Beyoncé Giselle Knowles-Carter (/biːˈjɒnseɪ/ b...</td>\n",
       "      <td>2003</td>\n",
       "      <td>526</td>\n",
       "      <td>530</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>56bf6b0f3aeaaa14008c9601</td>\n",
       "      <td>In what city and state did Beyonce  grow up?</td>\n",
       "      <td>Beyoncé</td>\n",
       "      <td>55</td>\n",
       "      <td>Beyoncé Giselle Knowles-Carter (/biːˈjɒnseɪ/ b...</td>\n",
       "      <td>Houston, Texas</td>\n",
       "      <td>166</td>\n",
       "      <td>180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>56bf6b0f3aeaaa14008c9602</td>\n",
       "      <td>In which decade did Beyonce become famous?</td>\n",
       "      <td>Beyoncé</td>\n",
       "      <td>55</td>\n",
       "      <td>Beyoncé Giselle Knowles-Carter (/biːˈjɒnseɪ/ b...</td>\n",
       "      <td>late 1990s</td>\n",
       "      <td>276</td>\n",
       "      <td>286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17404</th>\n",
       "      <td>5732868bb3a91d1900202e0f</td>\n",
       "      <td>At what Augusta hole was the Eisenhower Pine l...</td>\n",
       "      <td>Dwight_D._Eisenhower</td>\n",
       "      <td>18592</td>\n",
       "      <td>A loblolly pine, known as the \"Eisenhower Pine...</td>\n",
       "      <td>17th</td>\n",
       "      <td>74</td>\n",
       "      <td>78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17405</th>\n",
       "      <td>5732868bb3a91d1900202e10</td>\n",
       "      <td>How many meters away from the Masters tee on A...</td>\n",
       "      <td>Dwight_D._Eisenhower</td>\n",
       "      <td>18592</td>\n",
       "      <td>A loblolly pine, known as the \"Eisenhower Pine...</td>\n",
       "      <td>192</td>\n",
       "      <td>110</td>\n",
       "      <td>113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17406</th>\n",
       "      <td>5732868bb3a91d1900202e11</td>\n",
       "      <td>What did Eisenhower want to be done to the Eis...</td>\n",
       "      <td>Dwight_D._Eisenhower</td>\n",
       "      <td>18592</td>\n",
       "      <td>A loblolly pine, known as the \"Eisenhower Pine...</td>\n",
       "      <td>cut down</td>\n",
       "      <td>279</td>\n",
       "      <td>287</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17407</th>\n",
       "      <td>5732868bb3a91d1900202e12</td>\n",
       "      <td>What damaged the Eisenhower Pine in February 2...</td>\n",
       "      <td>Dwight_D._Eisenhower</td>\n",
       "      <td>18592</td>\n",
       "      <td>A loblolly pine, known as the \"Eisenhower Pine...</td>\n",
       "      <td>ice storm</td>\n",
       "      <td>478</td>\n",
       "      <td>487</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17408</th>\n",
       "      <td>5732868bb3a91d1900202e13</td>\n",
       "      <td>In what year did Eisenhower propose that the p...</td>\n",
       "      <td>Dwight_D._Eisenhower</td>\n",
       "      <td>18592</td>\n",
       "      <td>A loblolly pine, known as the \"Eisenhower Pine...</td>\n",
       "      <td>1956</td>\n",
       "      <td>237</td>\n",
       "      <td>241</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>17409 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                          index  \\\n",
       "0      56be85543aeaaa14008c9063   \n",
       "1      56be85543aeaaa14008c9065   \n",
       "2      56be85543aeaaa14008c9066   \n",
       "3      56bf6b0f3aeaaa14008c9601   \n",
       "4      56bf6b0f3aeaaa14008c9602   \n",
       "...                         ...   \n",
       "17404  5732868bb3a91d1900202e0f   \n",
       "17405  5732868bb3a91d1900202e10   \n",
       "17406  5732868bb3a91d1900202e11   \n",
       "17407  5732868bb3a91d1900202e12   \n",
       "17408  5732868bb3a91d1900202e13   \n",
       "\n",
       "                                                question  \\\n",
       "0               When did Beyonce start becoming popular?   \n",
       "1      What areas did Beyonce compete in when she was...   \n",
       "2      When did Beyonce leave Destiny's Child and bec...   \n",
       "3          In what city and state did Beyonce  grow up?    \n",
       "4             In which decade did Beyonce become famous?   \n",
       "...                                                  ...   \n",
       "17404  At what Augusta hole was the Eisenhower Pine l...   \n",
       "17405  How many meters away from the Masters tee on A...   \n",
       "17406  What did Eisenhower want to be done to the Eis...   \n",
       "17407  What damaged the Eisenhower Pine in February 2...   \n",
       "17408  In what year did Eisenhower propose that the p...   \n",
       "\n",
       "                      title  context_id  \\\n",
       "0                   Beyoncé          55   \n",
       "1                   Beyoncé          55   \n",
       "2                   Beyoncé          55   \n",
       "3                   Beyoncé          55   \n",
       "4                   Beyoncé          55   \n",
       "...                     ...         ...   \n",
       "17404  Dwight_D._Eisenhower       18592   \n",
       "17405  Dwight_D._Eisenhower       18592   \n",
       "17406  Dwight_D._Eisenhower       18592   \n",
       "17407  Dwight_D._Eisenhower       18592   \n",
       "17408  Dwight_D._Eisenhower       18592   \n",
       "\n",
       "                                                 context               answer  \\\n",
       "0      Beyoncé Giselle Knowles-Carter (/biːˈjɒnseɪ/ b...    in the late 1990s   \n",
       "1      Beyoncé Giselle Knowles-Carter (/biːˈjɒnseɪ/ b...  singing and dancing   \n",
       "2      Beyoncé Giselle Knowles-Carter (/biːˈjɒnseɪ/ b...                 2003   \n",
       "3      Beyoncé Giselle Knowles-Carter (/biːˈjɒnseɪ/ b...       Houston, Texas   \n",
       "4      Beyoncé Giselle Knowles-Carter (/biːˈjɒnseɪ/ b...           late 1990s   \n",
       "...                                                  ...                  ...   \n",
       "17404  A loblolly pine, known as the \"Eisenhower Pine...                 17th   \n",
       "17405  A loblolly pine, known as the \"Eisenhower Pine...                  192   \n",
       "17406  A loblolly pine, known as the \"Eisenhower Pine...             cut down   \n",
       "17407  A loblolly pine, known as the \"Eisenhower Pine...            ice storm   \n",
       "17408  A loblolly pine, known as the \"Eisenhower Pine...                 1956   \n",
       "\n",
       "       answer_start  answer_end  \n",
       "0               269         286  \n",
       "1               207         226  \n",
       "2               526         530  \n",
       "3               166         180  \n",
       "4               276         286  \n",
       "...             ...         ...  \n",
       "17404            74          78  \n",
       "17405           110         113  \n",
       "17406           279         287  \n",
       "17407           478         487  \n",
       "17408           237         241  \n",
       "\n",
       "[17409 rows x 8 columns]"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "squad_dataset.val_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-05T13:46:28.692661Z",
     "iopub.status.busy": "2021-01-05T13:46:28.692254Z",
     "iopub.status.idle": "2021-01-05T13:46:28.753438Z",
     "shell.execute_reply": "2021-01-05T13:46:28.752266Z",
     "shell.execute_reply.started": "2021-01-05T13:46:28.692617Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('To whom did the Virgin Mary allegedly appear in 1858 in Lourdes France?',\n",
       " 'Architecturally, the school has a Catholic character. Atop the Main Building\\'s gold dome is a golden statue of the Virgin Mary. Immediately in front of the Main Building and facing it, is a copper statue of Christ with arms upraised with the legend \"Venite Ad Me Omnes\". Next to the Main Building is the Basilica of the Sacred Heart. Immediately behind the basilica is the Grotto, a Marian place of prayer and reflection. It is a replica of the grotto at Lourdes, France where the Virgin Mary reputedly appeared to Saint Bernadette Soubirous in 1858. At the end of the main drive (and in a direct line that connects through 3 statues and the Gold Dome), is a simple, modern stone statue of Mary.',\n",
       " 515,\n",
       " 541)"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "squad_dataset.train_dataset[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-05T16:08:06.960515Z",
     "iopub.status.busy": "2021-01-05T16:08:06.960094Z",
     "iopub.status.idle": "2021-01-05T16:08:07.014580Z",
     "shell.execute_reply": "2021-01-05T16:08:07.013480Z",
     "shell.execute_reply.started": "2021-01-05T16:08:06.960470Z"
    }
   },
   "outputs": [],
   "source": [
    "UNK_TOKEN = \"[UNK]\"\n",
    "PAD_TOKEN = \"[PAD]\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-05T16:08:07.926856Z",
     "iopub.status.busy": "2021-01-05T16:08:07.926466Z",
     "iopub.status.idle": "2021-01-05T16:08:58.886667Z",
     "shell.execute_reply": "2021-01-05T16:08:58.885138Z",
     "shell.execute_reply.started": "2021-01-05T16:08:07.926811Z"
    }
   },
   "outputs": [],
   "source": [
    "import gensim\n",
    "import gensim.downloader as gloader\n",
    "\n",
    "\n",
    "def load_embedding_model(model_type, embedding_dimension=50):\n",
    "    \"\"\"\n",
    "    Loads a pre-trained word embedding model via gensim library\n",
    "    \"\"\"\n",
    "    # Find the correct embedding model name\n",
    "    download_path = \"\"\n",
    "    if model_type.strip().lower() == \"word2vec\":\n",
    "        download_path = \"word2vec-google-news-300\"\n",
    "    elif model_type.strip().lower() == \"glove\":\n",
    "        download_path = f\"glove-wiki-gigaword-{embedding_dimension}\"\n",
    "    else:\n",
    "        raise AttributeError(\n",
    "            \"Unsupported embedding model type (choose from {word2vec, glove})\"\n",
    "        )\n",
    "\n",
    "    # Check download\n",
    "    try:\n",
    "        emb_model = gloader.load(download_path)\n",
    "    except ValueError as e:\n",
    "        print(\"Invalid embedding model name. Check the embedding dimension:\")\n",
    "        print(\"Word2Vec: {300}\")\n",
    "        print(\"GloVe: {50, 100, 200, 300}\")\n",
    "        raise e\n",
    "\n",
    "    return emb_model\n",
    "\n",
    "\n",
    "glove_embedding_dimension = 50\n",
    "glove_embedding_model = load_embedding_model(\"glove\", embedding_dimension=glove_embedding_dimension)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-05T14:55:35.692575Z",
     "iopub.status.busy": "2021-01-05T14:55:35.692119Z",
     "iopub.status.idle": "2021-01-05T14:55:35.794532Z",
     "shell.execute_reply": "2021-01-05T14:55:35.793347Z",
     "shell.execute_reply.started": "2021-01-05T14:55:35.692530Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.12920076, -0.28866628, -0.01224866, -0.05676644, -0.20210965,\n",
       "       -0.08389011,  0.33359843,  0.16045167,  0.03867431,  0.17833012,\n",
       "        0.04696583, -0.00285802,  0.29099807,  0.04613704, -0.20923874,\n",
       "       -0.06613114, -0.06822549,  0.07665912,  0.3134014 ,  0.17848536,\n",
       "       -0.1225775 , -0.09916984, -0.07495987,  0.06413227,  0.14441176,\n",
       "        0.60894334,  0.17463093,  0.05335403, -0.01273871,  0.03474107,\n",
       "       -0.8123879 , -0.04688699,  0.20193407,  0.2031118 , -0.03935686,\n",
       "        0.06967544, -0.01553638, -0.03405238, -0.06528071,  0.12250231,\n",
       "        0.13991883, -0.17446303, -0.08011883,  0.0849521 , -0.01041659,\n",
       "       -0.13705009,  0.20127155,  0.10069408,  0.00653003,  0.01685157],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "glove_unk = np.mean(glove_embedding_model.vectors, axis=0)\n",
    "glove_unk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-05T16:09:37.359360Z",
     "iopub.status.busy": "2021-01-05T16:09:37.358914Z",
     "iopub.status.idle": "2021-01-05T16:09:37.467574Z",
     "shell.execute_reply": "2021-01-05T16:09:37.466418Z",
     "shell.execute_reply.started": "2021-01-05T16:09:37.359315Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 233,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "any(np.all(glove_embedding_model.vectors == 0, axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-05T16:09:21.694729Z",
     "iopub.status.busy": "2021-01-05T16:09:21.694299Z",
     "iopub.status.idle": "2021-01-05T16:09:21.969475Z",
     "shell.execute_reply": "2021-01-05T16:09:21.967901Z",
     "shell.execute_reply.started": "2021-01-05T16:09:21.694684Z"
    }
   },
   "outputs": [],
   "source": [
    "glove_embedding_model.add(UNK_TOKEN, glove_unk)\n",
    "glove_embedding_model.add(PAD_TOKEN, np.zeros((1, glove_embedding_dimension)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-05T16:09:23.046100Z",
     "iopub.status.busy": "2021-01-05T16:09:23.045779Z",
     "iopub.status.idle": "2021-01-05T16:09:23.102105Z",
     "shell.execute_reply": "2021-01-05T16:09:23.100999Z",
     "shell.execute_reply.started": "2021-01-05T16:09:23.046059Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(400002, 50)"
      ]
     },
     "execution_count": 229,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "glove_embedding_model.vectors.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-05T16:09:24.693801Z",
     "iopub.status.busy": "2021-01-05T16:09:24.693403Z",
     "iopub.status.idle": "2021-01-05T16:09:24.752480Z",
     "shell.execute_reply": "2021-01-05T16:09:24.751288Z",
     "shell.execute_reply.started": "2021-01-05T16:09:24.693757Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.12920076, -0.28866628, -0.01224866, -0.05676644, -0.20210965,\n",
       "       -0.08389011,  0.33359843,  0.16045167,  0.03867431,  0.17833012,\n",
       "        0.04696583, -0.00285802,  0.29099807,  0.04613704, -0.20923874,\n",
       "       -0.06613114, -0.06822549,  0.07665912,  0.3134014 ,  0.17848536,\n",
       "       -0.1225775 , -0.09916984, -0.07495987,  0.06413227,  0.14441176,\n",
       "        0.60894334,  0.17463093,  0.05335403, -0.01273871,  0.03474107,\n",
       "       -0.8123879 , -0.04688699,  0.20193407,  0.2031118 , -0.03935686,\n",
       "        0.06967544, -0.01553638, -0.03405238, -0.06528071,  0.12250231,\n",
       "        0.13991883, -0.17446303, -0.08011883,  0.0849521 , -0.01041659,\n",
       "       -0.13705009,  0.20127155,  0.10069408,  0.00653003,  0.01685157],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 230,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "glove_embedding_model[UNK_TOKEN]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-05T16:09:31.299881Z",
     "iopub.status.busy": "2021-01-05T16:09:31.299457Z",
     "iopub.status.idle": "2021-01-05T16:09:31.357460Z",
     "shell.execute_reply": "2021-01-05T16:09:31.356270Z",
     "shell.execute_reply.started": "2021-01-05T16:09:31.299836Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 231,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "glove_embedding_model[PAD_TOKEN]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-05T16:09:35.164315Z",
     "iopub.status.busy": "2021-01-05T16:09:35.163884Z",
     "iopub.status.idle": "2021-01-05T16:09:35.248549Z",
     "shell.execute_reply": "2021-01-05T16:09:35.247385Z",
     "shell.execute_reply.started": "2021-01-05T16:09:35.164270Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[PAD]'"
      ]
     },
     "execution_count": 232,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(glove_embedding_model.vocab.keys())[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-05T16:10:20.773430Z",
     "iopub.status.busy": "2021-01-05T16:10:20.773006Z",
     "iopub.status.idle": "2021-01-05T16:10:21.003465Z",
     "shell.execute_reply": "2021-01-05T16:10:21.002132Z",
     "shell.execute_reply.started": "2021-01-05T16:10:20.773384Z"
    }
   },
   "outputs": [],
   "source": [
    "glove_vocab = dict(\n",
    "    zip(glove_embedding_model.index2word, range(len(glove_embedding_model.index2word)))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-05T16:10:47.346061Z",
     "iopub.status.busy": "2021-01-05T16:10:47.345636Z",
     "iopub.status.idle": "2021-01-05T16:10:48.208721Z",
     "shell.execute_reply": "2021-01-05T16:10:48.207435Z",
     "shell.execute_reply.started": "2021-01-05T16:10:47.346016Z"
    }
   },
   "outputs": [],
   "source": [
    "glove_embedding_layer = nn.Embedding(\n",
    "    glove_embedding_model.vectors.shape[0],\n",
    "    glove_embedding_dimension,\n",
    "    padding_idx=glove_vocab[PAD_TOKEN],\n",
    ")\n",
    "glove_embedding_layer.weight = nn.Parameter(\n",
    "    torch.from_numpy(glove_embedding_model.vectors)\n",
    ")\n",
    "glove_embedding_layer.weight.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-05T17:29:36.882101Z",
     "iopub.status.busy": "2021-01-05T17:29:36.881669Z",
     "iopub.status.idle": "2021-01-05T17:29:37.604837Z",
     "shell.execute_reply": "2021-01-05T17:29:37.603477Z",
     "shell.execute_reply.started": "2021-01-05T17:29:36.882056Z"
    }
   },
   "outputs": [],
   "source": [
    "import tokenizers\n",
    "from tokenizers import Tokenizer\n",
    "from tokenizers.models import WordLevel\n",
    "from tokenizers.normalizers import Sequence, StripAccents, Lowercase, Strip\n",
    "from tokenizers.pre_tokenizers import Whitespace\n",
    "\n",
    "baseline_tokenizer = Tokenizer(WordLevel(glove_vocab, unk_token=UNK_TOKEN))\n",
    "baseline_tokenizer.normalizer = Sequence([StripAccents(), Lowercase(), Strip()])\n",
    "baseline_tokenizer.pre_tokenizer = Whitespace()\n",
    "baseline_tokenizer.enable_padding(\n",
    "    direction=\"right\",\n",
    "    pad_id=glove_vocab[PAD_TOKEN],\n",
    "    pad_type_id=1,\n",
    "    pad_token=PAD_TOKEN,\n",
    "    length=None,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-05T17:47:44.391692Z",
     "iopub.status.busy": "2021-01-05T17:47:44.391265Z",
     "iopub.status.idle": "2021-01-05T17:47:44.449937Z",
     "shell.execute_reply": "2021-01-05T17:47:44.448742Z",
     "shell.execute_reply.started": "2021-01-05T17:47:44.391647Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 0, 1, 1]"
      ]
     },
     "execution_count": 311,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "baseline_tokenizer.encode_batch([(\"ciao ciao\", \"miao miao\"), (\"pmc\", \"mdmd\")])[1].special_tokens_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 363,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-05T18:09:26.058363Z",
     "iopub.status.busy": "2021-01-05T18:09:26.057902Z",
     "iopub.status.idle": "2021-01-05T18:09:26.129896Z",
     "shell.execute_reply": "2021-01-05T18:09:26.128908Z",
     "shell.execute_reply.started": "2021-01-05T18:09:26.058314Z"
    }
   },
   "outputs": [],
   "source": [
    "class BaselineDataCollatorWithPadding:\n",
    "    \"\"\"\n",
    "    Data collator that will dynamically pad the inputs received\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, tokenizer):\n",
    "        self.tokenizer = tokenizer\n",
    "\n",
    "    def __call__(self, inputs):\n",
    "        (questions, contexts, answers_start, answers_end) = zip(*inputs)\n",
    "        tokenized_questions = self.tokenizer.encode_batch(questions)\n",
    "        tokenized_contexts = self.tokenizer.encode_batch(contexts)\n",
    "        batch_size = len(tokenized_questions)\n",
    "        questions_shape = (batch_size, len(tokenized_questions[0].ids))\n",
    "        contexts_shape = (batch_size, len(tokenized_contexts[0].ids))\n",
    "        \n",
    "        batch = {\n",
    "            \"question_ids\": torch.empty(questions_shape, dtype=torch.long),\n",
    "            \"question_type_ids\": torch.empty(questions_shape, dtype=torch.long),\n",
    "            \"question_attention_mask\": torch.empty(questions_shape, dtype=torch.bool),\n",
    "            \"question_special_tokens_mask\": torch.empty(\n",
    "                questions_shape, dtype=torch.bool\n",
    "            ),\n",
    "            \"question_lenghts\": torch.empty((batch_size,), dtype=torch.long),\n",
    "            \"context_ids\": torch.empty(contexts_shape, dtype=torch.long),\n",
    "            \"context_type_ids\": torch.empty(contexts_shape, dtype=torch.long),\n",
    "            \"context_attention_mask\": torch.empty(contexts_shape, dtype=torch.bool),\n",
    "            \"context_special_tokens_mask\": torch.empty(\n",
    "                contexts_shape, dtype=torch.bool\n",
    "            ),\n",
    "            \"context_lenghts\": torch.empty((batch_size,), dtype=torch.long),\n",
    "            \"answers_start\": torch.tensor(answers_start, dtype=torch.long),\n",
    "            \"answers_end\": torch.tensor(answers_end, dtype=torch.long)\n",
    "        }\n",
    "        for i in range(batch_size):\n",
    "            batch[\"question_ids\"][i] = torch.tensor(tokenized_questions[i].ids)\n",
    "            batch[\"question_type_ids\"][i] = torch.tensor(tokenized_questions[i].type_ids)\n",
    "            batch[\"question_attention_mask\"][i] = torch.tensor(tokenized_questions[i].attention_mask)\n",
    "            batch[\"question_special_tokens_mask\"][i] = torch.tensor(tokenized_questions[i].special_tokens_mask)\n",
    "            batch[\"question_lenghts\"][i] = torch.count_nonzero(~batch[\"question_special_tokens_mask\"][i])\n",
    "            batch[\"context_ids\"][i] = torch.tensor(tokenized_contexts[i].ids)\n",
    "            batch[\"context_type_ids\"][i] = torch.tensor(tokenized_contexts[i].type_ids)\n",
    "            batch[\"context_attention_mask\"][i] = torch.tensor(tokenized_contexts[i].attention_mask)\n",
    "            batch[\"context_special_tokens_mask\"][i] = torch.tensor(tokenized_contexts[i].special_tokens_mask)\n",
    "            batch[\"context_lenghts\"][i] = torch.count_nonzero(~batch[\"context_special_tokens_mask\"][i])\n",
    "        \n",
    "        return batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 364,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-05T18:09:26.739136Z",
     "iopub.status.busy": "2021-01-05T18:09:26.738817Z",
     "iopub.status.idle": "2021-01-05T18:09:26.798862Z",
     "shell.execute_reply": "2021-01-05T18:09:26.797734Z",
     "shell.execute_reply.started": "2021-01-05T18:09:26.739095Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "41002"
      ]
     },
     "execution_count": 364,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "baseline_model = model.QABaselineModel(glove_embedding_layer)\n",
    "baseline_model.count_parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 365,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-05T18:09:27.393538Z",
     "iopub.status.busy": "2021-01-05T18:09:27.393220Z",
     "iopub.status.idle": "2021-01-05T18:09:27.449623Z",
     "shell.execute_reply": "2021-01-05T18:09:27.448565Z",
     "shell.execute_reply.started": "2021-01-05T18:09:27.393497Z"
    }
   },
   "outputs": [],
   "source": [
    "baseline_args = transformers.TrainingArguments(\n",
    "    output_dir=\"./checkpoints\",\n",
    "    logging_dir=\"./runs\",\n",
    "    overwrite_output_dir=True,\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    learning_rate=2e-5,\n",
    "    num_train_epochs=3,\n",
    "    remove_unused_columns=False,\n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=64,\n",
    "    label_names=[\"answer_start\", \"answer_end\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 366,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-05T18:09:27.452071Z",
     "iopub.status.busy": "2021-01-05T18:09:27.451772Z",
     "iopub.status.idle": "2021-01-05T18:09:27.505953Z",
     "shell.execute_reply": "2021-01-05T18:09:27.504772Z",
     "shell.execute_reply.started": "2021-01-05T18:09:27.452034Z"
    }
   },
   "outputs": [],
   "source": [
    "baseline_trainer = transformers.Trainer(\n",
    "    model=baseline_model,\n",
    "    args=baseline_args,\n",
    "    data_collator=BaselineDataCollatorWithPadding(baseline_tokenizer),\n",
    "    train_dataset=squad_dataset.train_dataset,\n",
    "    eval_dataset=squad_dataset.val_dataset\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 367,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-05T18:09:28.689966Z",
     "iopub.status.busy": "2021-01-05T18:09:28.689652Z",
     "iopub.status.idle": "2021-01-05T18:09:29.024783Z",
     "shell.execute_reply": "2021-01-05T18:09:29.023066Z",
     "shell.execute_reply.started": "2021-01-05T18:09:28.689924Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'question_ids': tensor([[   102,     14,      0,  12276,   1611, 400000,      4,  17407,    188,\n",
      "         400001, 400001, 400001, 400001, 400001, 400001, 400001, 400001, 400001],\n",
      "        [   102,   3374,      6,   3863,    149,   8296,   1692,    188, 400001,\n",
      "         400001, 400001, 400001, 400001, 400001, 400001, 400001, 400001, 400001],\n",
      "        [   197,    173,    119,      0,    899,     33,      4,    682,     13,\n",
      "              0,    607,    188, 400001, 400001, 400001, 400001, 400001, 400001],\n",
      "        [   102,    311,    119, 400000,    455,      4,      0,    583,     12,\n",
      "            414,     33,     51, 400000,    188, 400001, 400001, 400001, 400001],\n",
      "        [   102,     15,      0,    477, 115534,   9586,     10,      0,    939,\n",
      "            274,   1279,    164,     62,    188, 400001, 400001, 400001, 400001],\n",
      "        [   102, 400000,     32,  34796,      6,    188, 400001, 400001, 400001,\n",
      "         400001, 400001, 400001, 400001, 400001, 400001, 400001, 400001, 400001],\n",
      "        [    83,      0,    552,   6819,     32,   5067,      1,     15,      0,\n",
      "            552,      3,      0,   2654,   6914,     46,     56,   3502,    188],\n",
      "        [    38,   1298,      0,   2675,      3,      0,  50865,    188, 400001,\n",
      "         400001, 400001, 400001, 400001, 400001, 400001, 400001, 400001, 400001],\n",
      "        [   102,     14,  81338,     57,   1534,    311,    911,     10,    188,\n",
      "         400001, 400001, 400001, 400001, 400001, 400001, 400001, 400001, 400001],\n",
      "        [    61,    119,   3292,   2451,     44,  17483,     17,    331,   4137,\n",
      "             23,  31544, 400000, 400001, 400001, 400001, 400001, 400001, 400001],\n",
      "        [   102,     62,     35,   7618,     57,   1534,   5190,   2243,  10125,\n",
      "            188, 400001, 400001, 400001, 400001, 400001, 400001, 400001, 400001],\n",
      "        [    38,     15,      0,   1744,     38,    405,     44,   1281,     13,\n",
      "              0,     58,   1737,      3,      4,   1916,      7,  44131,    188],\n",
      "        [   102,     14,      0,    311,      3,      0,   3448,      7,  29433,\n",
      "            129,     22,    289,    221,    188, 400001, 400001, 400001, 400001],\n",
      "        [   507, 400000,   4151,   3802,      6,   4604,    105,      7,   1836,\n",
      "              5,   1297,      7,   1480,      6,  30971,    188, 400001, 400001],\n",
      "        [   102,    260, 400000,   4526,    188, 400001, 400001, 400001, 400001,\n",
      "         400001, 400001, 400001, 400001, 400001, 400001, 400001, 400001, 400001],\n",
      "        [   102,    539,  14517,      0,     50,   6528,      3,  88239,      6,\n",
      "             37,   2953,    188, 400001, 400001, 400001, 400001, 400001, 400001]]), 'question_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1],\n",
      "        [0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1],\n",
      "        [0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1]]), 'question_attention_mask': tensor([[ True,  True,  True,  True,  True,  True,  True,  True,  True, False,\n",
      "         False, False, False, False, False, False, False, False],\n",
      "        [ True,  True,  True,  True,  True,  True,  True,  True, False, False,\n",
      "         False, False, False, False, False, False, False, False],\n",
      "        [ True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
      "          True,  True, False, False, False, False, False, False],\n",
      "        [ True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
      "          True,  True,  True,  True, False, False, False, False],\n",
      "        [ True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
      "          True,  True,  True,  True, False, False, False, False],\n",
      "        [ True,  True,  True,  True,  True,  True, False, False, False, False,\n",
      "         False, False, False, False, False, False, False, False],\n",
      "        [ True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
      "          True,  True,  True,  True,  True,  True,  True,  True],\n",
      "        [ True,  True,  True,  True,  True,  True,  True,  True, False, False,\n",
      "         False, False, False, False, False, False, False, False],\n",
      "        [ True,  True,  True,  True,  True,  True,  True,  True,  True, False,\n",
      "         False, False, False, False, False, False, False, False],\n",
      "        [ True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
      "          True,  True, False, False, False, False, False, False],\n",
      "        [ True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
      "         False, False, False, False, False, False, False, False],\n",
      "        [ True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
      "          True,  True,  True,  True,  True,  True,  True,  True],\n",
      "        [ True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
      "          True,  True,  True,  True, False, False, False, False],\n",
      "        [ True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
      "          True,  True,  True,  True,  True,  True, False, False],\n",
      "        [ True,  True,  True,  True,  True, False, False, False, False, False,\n",
      "         False, False, False, False, False, False, False, False],\n",
      "        [ True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
      "          True,  True, False, False, False, False, False, False]]), 'question_special_tokens_mask': tensor([[False, False, False, False, False, False, False, False, False,  True,\n",
      "          True,  True,  True,  True,  True,  True,  True,  True],\n",
      "        [False, False, False, False, False, False, False, False,  True,  True,\n",
      "          True,  True,  True,  True,  True,  True,  True,  True],\n",
      "        [False, False, False, False, False, False, False, False, False, False,\n",
      "         False, False,  True,  True,  True,  True,  True,  True],\n",
      "        [False, False, False, False, False, False, False, False, False, False,\n",
      "         False, False, False, False,  True,  True,  True,  True],\n",
      "        [False, False, False, False, False, False, False, False, False, False,\n",
      "         False, False, False, False,  True,  True,  True,  True],\n",
      "        [False, False, False, False, False, False,  True,  True,  True,  True,\n",
      "          True,  True,  True,  True,  True,  True,  True,  True],\n",
      "        [False, False, False, False, False, False, False, False, False, False,\n",
      "         False, False, False, False, False, False, False, False],\n",
      "        [False, False, False, False, False, False, False, False,  True,  True,\n",
      "          True,  True,  True,  True,  True,  True,  True,  True],\n",
      "        [False, False, False, False, False, False, False, False, False,  True,\n",
      "          True,  True,  True,  True,  True,  True,  True,  True],\n",
      "        [False, False, False, False, False, False, False, False, False, False,\n",
      "         False, False,  True,  True,  True,  True,  True,  True],\n",
      "        [False, False, False, False, False, False, False, False, False, False,\n",
      "          True,  True,  True,  True,  True,  True,  True,  True],\n",
      "        [False, False, False, False, False, False, False, False, False, False,\n",
      "         False, False, False, False, False, False, False, False],\n",
      "        [False, False, False, False, False, False, False, False, False, False,\n",
      "         False, False, False, False,  True,  True,  True,  True],\n",
      "        [False, False, False, False, False, False, False, False, False, False,\n",
      "         False, False, False, False, False, False,  True,  True],\n",
      "        [False, False, False, False, False,  True,  True,  True,  True,  True,\n",
      "          True,  True,  True,  True,  True,  True,  True,  True],\n",
      "        [False, False, False, False, False, False, False, False, False, False,\n",
      "         False, False,  True,  True,  True,  True,  True,  True]]), 'question_lenghts': tensor([ 9,  8, 12, 14, 14,  6, 18,  8,  9, 12, 10, 18, 14, 16,  5, 12]), 'context_ids': tensor([[ 17407,   2345,     13,  ..., 400001, 400001, 400001],\n",
      "        [   504,      0,   1692,  ..., 400001, 400001, 400001],\n",
      "        [     4,    949,     10,  ..., 400001, 400001, 400001],\n",
      "        ...,\n",
      "        [    77,   2634,    733,  ..., 400001, 400001, 400001],\n",
      "        [400000,    127,  38077,  ..., 400001, 400001, 400001],\n",
      "        [     7,     50,   2953,  ..., 400001, 400001, 400001]]), 'context_type_ids': tensor([[0, 0, 0,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        ...,\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1]]), 'context_attention_mask': tensor([[ True,  True,  True,  ..., False, False, False],\n",
      "        [ True,  True,  True,  ..., False, False, False],\n",
      "        [ True,  True,  True,  ..., False, False, False],\n",
      "        ...,\n",
      "        [ True,  True,  True,  ..., False, False, False],\n",
      "        [ True,  True,  True,  ..., False, False, False],\n",
      "        [ True,  True,  True,  ..., False, False, False]]), 'context_special_tokens_mask': tensor([[False, False, False,  ...,  True,  True,  True],\n",
      "        [False, False, False,  ...,  True,  True,  True],\n",
      "        [False, False, False,  ...,  True,  True,  True],\n",
      "        ...,\n",
      "        [False, False, False,  ...,  True,  True,  True],\n",
      "        [False, False, False,  ...,  True,  True,  True],\n",
      "        [False, False, False,  ...,  True,  True,  True]]), 'context_lenghts': tensor([141, 166, 190, 108, 183, 214, 106,  84, 113, 127, 187, 148, 254,  98,\n",
      "        162, 133]), 'answers_start': tensor([308, 456, 240, 273,  54, 114, 210, 261, 544, 514, 375, 197, 123, 162,\n",
      "        661, 230]), 'answers_end': tensor([316, 479, 250, 285,  61, 127, 220, 279, 565, 600, 379, 207, 133, 177,\n",
      "        679, 255])}\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "grad can be implicitly created only for scalar outputs",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-367-a28822d33159>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mbaseline_trainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/transformers/trainer.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, model_path, trial)\u001b[0m\n\u001b[1;32m    797\u001b[0m                         \u001b[0mtr_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    798\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 799\u001b[0;31m                     \u001b[0mtr_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    800\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_total_flos\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloating_point_ops\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    801\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/transformers/trainer.py\u001b[0m in \u001b[0;36mtraining_step\u001b[0;34m(self, model, inputs)\u001b[0m\n\u001b[1;32m   1151\u001b[0m                 \u001b[0mscaled_loss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1152\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1153\u001b[0;31m             \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1154\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1155\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    219\u001b[0m                 \u001b[0mretain_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    220\u001b[0m                 create_graph=create_graph)\n\u001b[0;32m--> 221\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    222\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    223\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m    124\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    125\u001b[0m     \u001b[0mgrad_tensors_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_tensor_or_tensors_to_tuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 126\u001b[0;31m     \u001b[0mgrad_tensors_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_make_grads\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    127\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mretain_graph\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    128\u001b[0m         \u001b[0mretain_graph\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36m_make_grads\u001b[0;34m(outputs, grads)\u001b[0m\n\u001b[1;32m     48\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequires_grad\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 50\u001b[0;31m                     \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"grad can be implicitly created only for scalar outputs\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     51\u001b[0m                 \u001b[0mnew_grads\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mones_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmemory_format\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpreserve_format\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: grad can be implicitly created only for scalar outputs"
     ]
    }
   ],
   "source": [
    "baseline_trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-05T16:35:27.908837Z",
     "iopub.status.busy": "2021-01-05T16:35:27.908413Z",
     "iopub.status.idle": "2021-01-05T16:35:37.556426Z",
     "shell.execute_reply": "2021-01-05T16:35:37.555013Z",
     "shell.execute_reply.started": "2021-01-05T16:35:27.908792Z"
    }
   },
   "outputs": [],
   "source": [
    "import transformers\n",
    "\n",
    "tokenizer = transformers.BertTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "model = transformers.BertModel.from_pretrained(\"bert-base-uncased\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-05T16:35:38.148391Z",
     "iopub.status.busy": "2021-01-05T16:35:38.148076Z",
     "iopub.status.idle": "2021-01-05T16:35:38.205423Z",
     "shell.execute_reply": "2021-01-05T16:35:38.204045Z",
     "shell.execute_reply.started": "2021-01-05T16:35:38.148350Z"
    }
   },
   "outputs": [],
   "source": [
    "args = transformers.TrainingArguments(\n",
    "    output_dir=\"./checkpoints\",\n",
    "    logging_dir=\"./runs\",\n",
    "    overwrite_output_dir=True,\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    learning_rate=2e-5,\n",
    "    num_train_epochs=3,\n",
    "    remove_unused_columns=False,\n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=64,\n",
    "    label_names=[\"answer_start\", \"answer_end\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-05T16:37:08.769006Z",
     "iopub.status.busy": "2021-01-05T16:37:08.768562Z",
     "iopub.status.idle": "2021-01-05T16:37:08.828810Z",
     "shell.execute_reply": "2021-01-05T16:37:08.827727Z",
     "shell.execute_reply.started": "2021-01-05T16:37:08.768960Z"
    }
   },
   "outputs": [],
   "source": [
    "class DataCollatorWithPadding:\n",
    "    \"\"\"\n",
    "    Data collator that will dynamically pad the inputs received\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, tokenizer, padding=True, max_lenght=None):\n",
    "        self.tokenizer = tokenizer\n",
    "        self.padding = True\n",
    "        self.max_length = None\n",
    "\n",
    "    def __call__(self, inputs):\n",
    "        (questions, contexts, _, _) = zip(*inputs)\n",
    "        tokenized = self.tokenizer(questions, contexts)\n",
    "        batch = self.tokenizer.pad(\n",
    "            tokenized,\n",
    "            padding=self.padding,\n",
    "            max_length=self.max_length,\n",
    "            return_tensors=\"pt\",\n",
    "        )\n",
    "        return batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-05T16:37:09.528586Z",
     "iopub.status.busy": "2021-01-05T16:37:09.528262Z",
     "iopub.status.idle": "2021-01-05T16:37:09.581742Z",
     "shell.execute_reply": "2021-01-05T16:37:09.580817Z",
     "shell.execute_reply.started": "2021-01-05T16:37:09.528545Z"
    }
   },
   "outputs": [],
   "source": [
    "data_collator = DataCollatorWithPadding(tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-05T16:37:09.584330Z",
     "iopub.status.busy": "2021-01-05T16:37:09.584025Z",
     "iopub.status.idle": "2021-01-05T16:37:09.650137Z",
     "shell.execute_reply": "2021-01-05T16:37:09.649112Z",
     "shell.execute_reply.started": "2021-01-05T16:37:09.584292Z"
    }
   },
   "outputs": [],
   "source": [
    "trainer = transformers.Trainer(\n",
    "    model=model,\n",
    "    args=args,\n",
    "    data_collator=data_collator,\n",
    "    train_dataset=squad_dataset.train_dataset,\n",
    "    eval_dataset=squad_dataset.val_dataset\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-05T16:37:10.984314Z",
     "iopub.status.busy": "2021-01-05T16:37:10.983997Z",
     "iopub.status.idle": "2021-01-05T16:37:23.456420Z",
     "shell.execute_reply": "2021-01-05T16:37:23.454650Z",
     "shell.execute_reply.started": "2021-01-05T16:37:10.984273Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['input_ids', 'token_type_ids', 'attention_mask'])\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'loss'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-288-3435b262f1ae>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/transformers/trainer.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, model_path, trial)\u001b[0m\n\u001b[1;32m    797\u001b[0m                         \u001b[0mtr_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    798\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 799\u001b[0;31m                     \u001b[0mtr_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    800\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_total_flos\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloating_point_ops\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    801\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/transformers/trainer.py\u001b[0m in \u001b[0;36mtraining_step\u001b[0;34m(self, model, inputs)\u001b[0m\n\u001b[1;32m   1137\u001b[0m                 \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1138\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1139\u001b[0;31m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1140\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1141\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_gpu\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/transformers/trainer.py\u001b[0m in \u001b[0;36mcompute_loss\u001b[0;34m(self, model, inputs)\u001b[0m\n\u001b[1;32m   1167\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_past\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpast_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1168\u001b[0m         \u001b[0;31m# We don't use .loss here since the model may return tuples instead of ModelOutput.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1169\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"loss\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1170\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1171\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mis_local_process_zero\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mbool\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/transformers/file_utils.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, k)\u001b[0m\n\u001b[1;32m   1443\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1444\u001b[0m             \u001b[0minner_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1445\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0minner_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1446\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1447\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_tuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'loss'"
     ]
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
